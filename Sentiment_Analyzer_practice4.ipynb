{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 150)\n",
    "\n",
    "df = pd.read_csv(\"demonetization-tweets.csv\",encoding = 'Windows-1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>text</th>\n",
       "      <th>favorited</th>\n",
       "      <th>favoriteCount</th>\n",
       "      <th>replyToSN</th>\n",
       "      <th>created</th>\n",
       "      <th>truncated</th>\n",
       "      <th>replyToSID</th>\n",
       "      <th>id</th>\n",
       "      <th>replyToUID</th>\n",
       "      <th>statusSource</th>\n",
       "      <th>screenName</th>\n",
       "      <th>retweetCount</th>\n",
       "      <th>isRetweet</th>\n",
       "      <th>retweeted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM informed about #Demonetization edict by PM? It's clearly fishy and requires full disclosure &amp;amp;…</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-23 18:40:30</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.014957e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>HASHTAGFARZIWAL</td>\n",
       "      <td>331</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization on Modi survey app?</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-23 18:40:29</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.014957e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>PRAMODKAUSHIK9</td>\n",
       "      <td>66</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor, CBDT Chair + Harvard Professor lambaste #Demonetization.\\r\\n\\r\\nIf not for Aam Aadmi, listen to th…</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-23 18:40:03</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.014955e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>rahulja13034944</td>\n",
       "      <td>12</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office employees provide cash exchange to patients in hospitals #demonetization https://t.co/uGMxUP9…</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-23 18:39:59</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.014955e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://twitter.com/download/android\" rel=\"nofollow\"&gt;Twitter for Android&lt;/a&gt;</td>\n",
       "      <td>deeptiyvd</td>\n",
       "      <td>338</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today cartoon #demonetization #ReddyWedding https://t.co/u7gLNrq31F</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-11-23 18:39:39</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.014954e+17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;a href=\"http://cpimharyana.com\" rel=\"nofollow\"&gt;CPIMBadli&lt;/a&gt;</td>\n",
       "      <td>CPIMBadli</td>\n",
       "      <td>120</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  X  \\\n",
       "0           1  1   \n",
       "1           2  2   \n",
       "2           3  3   \n",
       "3           4  4   \n",
       "4           5  5   \n",
       "\n",
       "                                                                                                                                                 text  \\\n",
       "0    RT @rssurjewala: Critical question: Was PayTM informed about #Demonetization edict by PM? It's clearly fishy and requires full disclosure &amp;…   \n",
       "1                                                                                  RT @Hemant_80: Did you vote on #Demonetization on Modi survey app?   \n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor, CBDT Chair + Harvard Professor lambaste #Demonetization.\\r\\n\\r\\nIf not for Aam Aadmi, listen to th…   \n",
       "3        RT @ANI_news: Gurugram (Haryana): Post office employees provide cash exchange to patients in hospitals #demonetization https://t.co/uGMxUP9…   \n",
       "4                                         RT @satishacharya: Reddy Wedding! @mail_today cartoon #demonetization #ReddyWedding https://t.co/u7gLNrq31F   \n",
       "\n",
       "   favorited  favoriteCount replyToSN              created  truncated  \\\n",
       "0      False              0       NaN  2016-11-23 18:40:30      False   \n",
       "1      False              0       NaN  2016-11-23 18:40:29      False   \n",
       "2      False              0       NaN  2016-11-23 18:40:03      False   \n",
       "3      False              0       NaN  2016-11-23 18:39:59      False   \n",
       "4      False              0       NaN  2016-11-23 18:39:39      False   \n",
       "\n",
       "   replyToSID            id  replyToUID  \\\n",
       "0         NaN  8.014957e+17         NaN   \n",
       "1         NaN  8.014957e+17         NaN   \n",
       "2         NaN  8.014955e+17         NaN   \n",
       "3         NaN  8.014955e+17         NaN   \n",
       "4         NaN  8.014954e+17         NaN   \n",
       "\n",
       "                                                                           statusSource  \\\n",
       "0  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "1  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "2  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "3  <a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>   \n",
       "4                         <a href=\"http://cpimharyana.com\" rel=\"nofollow\">CPIMBadli</a>   \n",
       "\n",
       "        screenName  retweetCount  isRetweet  retweeted  \n",
       "0  HASHTAGFARZIWAL           331       True      False  \n",
       "1   PRAMODKAUSHIK9            66       True      False  \n",
       "2  rahulja13034944            12       True      False  \n",
       "3        deeptiyvd           338       True      False  \n",
       "4        CPIMBadli           120       True      False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14940, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM informed about #Demonetization edict by PM? It's clearly fishy and requires full disclosure &amp;amp;…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization on Modi survey app?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor, CBDT Chair + Harvard Professor lambaste #Demonetization.\\r\\n\\r\\nIf not for Aam Aadmi, listen to th…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office employees provide cash exchange to patients in hospitals #demonetization https://t.co/uGMxUP9…</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today cartoon #demonetization #ReddyWedding https://t.co/u7gLNrq31F</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                tweet\n",
       "0    RT @rssurjewala: Critical question: Was PayTM informed about #Demonetization edict by PM? It's clearly fishy and requires full disclosure &amp;…\n",
       "1                                                                                  RT @Hemant_80: Did you vote on #Demonetization on Modi survey app?\n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor, CBDT Chair + Harvard Professor lambaste #Demonetization.\\r\\n\\r\\nIf not for Aam Aadmi, listen to th…\n",
       "3        RT @ANI_news: Gurugram (Haryana): Post office employees provide cash exchange to patients in hospitals #demonetization https://t.co/uGMxUP9…\n",
       "4                                         RT @satishacharya: Reddy Wedding! @mail_today cartoon #demonetization #ReddyWedding https://t.co/u7gLNrq31F"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df['text']\n",
    "df = pd.DataFrame({'tweet':df})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the tweets    \n",
    "df['cleaned_tweet'] = df['tweet'].replace(r'\\'|\\\"|\\,|\\.|\\?|\\+|\\-|\\/|\\=|\\(|\\)|\\n|\"', '', regex=True)\n",
    "df['cleaned_tweet'] = df['cleaned_tweet'].replace(\"  \", \" \")\n",
    "\n",
    "words_remove = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\"lines\",\"re\",\"what\", \"there\",\"all\",\"we\",\n",
    "                \"one\",\"the\",\"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\"but\",\"is\",\"in\",\"a\",\"not\",\"with\",\"as\",\n",
    "                \"was\",\"if\",\"they\",\"are\",\"this\",\"and\",\"it\",\"have\",\"has\",\"from\",\"at\",\"my\",\"be\",\"by\",\"not\",\"that\",\"to\",\n",
    "                \"from\",\"com\",\"org\",\"like\",\"likes\",\"so\",\"said\",\"from\",\"what\",\"told\",\"over\",\"more\",\"other\",\n",
    "                \"have\",\"last\",\"with\",\"this\",\"that\",\"such\",\"when\",\"been\",\"says\",\"will\",\"also\",\"where\",\"why\",\n",
    "                \"would\",\"today\", \"in\", \"on\", \"you\", \"r\", \"d\", \"u\", \"hw\",\"wat\", \"oly\", \"s\", \"b\", \"ht\", \n",
    "                \"rt\", \"p\",\"the\",\"th\", \"n\", \"was\",\"demonetization\",\"demonetisation\"]\n",
    "\n",
    "\n",
    "def cleantext(df, words_to_remove = words_remove): \n",
    "    ### dont change the original tweet\n",
    "    # remove emoticons form the tweets\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'<ed>','', regex = True)\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'\\B<U+.*>|<U+.*>\\B|<U+.*>','', regex = True)\n",
    "    \n",
    "    # convert tweets to lowercase\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].str.lower()\n",
    "    \n",
    "    #remove user mentions\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^(@\\w+)',\"\", regex=True)            \n",
    "            \n",
    "        \n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^(@\\w+)',\"\", regex=True)\n",
    "    \n",
    "    #remove 'rt' in the beginning\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^(rt @)',\"\", regex=True)\n",
    "    \n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'[a-z]{14}',\"\", regex=True)\n",
    "    \n",
    "    #remove_symbols\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'[^a-zA-Z0-9]', \" \", regex=True)\n",
    "\n",
    "    #remove punctuations \n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'[[]!\"#$%\\'()\\*+,-./:;<=>?^_`{|}]+',\"\", regex = True)\n",
    "\n",
    "    #remove_URL(x):\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'https.*$', \"\", regex = True)\n",
    "\n",
    "    #remove 'amp' in the text\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'amp',\"\", regex = True)\n",
    "    \n",
    "    #remove words of length 1 or 2 \n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'\\b[a-zA-Z]{1,2}\\b','', regex=True)\n",
    "\n",
    "    #remove extra spaces in the tweet\n",
    "    df['cleaned_tweet'] = df['cleaned_tweet'].replace(r'^\\s+|\\s+$',\" \", regex=True)\n",
    "     \n",
    "    \n",
    "    #remove stopwords and words_to_remove\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    mystopwords = [stop_words, \"via\", words_to_remove]\n",
    "    \n",
    "    df['fully_cleaned_tweet'] = df['cleaned_tweet'].apply(lambda x: ' '.join([word for word in x.split() if word not in mystopwords]))\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "#get the processed tweets\n",
    "df = cleantext(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "def clean_data_round1(text):\n",
    "    \n",
    "    text = text.lower()    \n",
    "    text = re.sub('\\w*\\d\\w*','',text)\n",
    "    text = re.sub('https.*$','',text)\n",
    "    text = re.sub('.*\\:','',text)\n",
    "    #text = re.sub('#[a-zA-Z]*','',text)\n",
    "    return text\n",
    "\n",
    "\n",
    "round1 = lambda x: clean_data_round1(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pd.set_option('max_colwidth', 250)\n",
    "\n",
    "df['clean_tweet'] = df['tweet'].apply(round1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['clean_tweet'] = df['clean_tweet'].replace(r'(@\\w+)',\"\",regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df['clean_tweet'] = df['clean_tweet'].replace(r'(\\#)',\"\",regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "words_remove = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\"lines\",\"re\",\"what\", \"there\",\"all\",\"we\",\n",
    "                \"one\",\"the\",\"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\"but\",\"is\",\"in\",\"a\",\"not\",\"with\",\"as\",\n",
    "                \"was\",\"if\",\"they\",\"are\",\"this\",\"and\",\"it\",\"have\",\"has\",\"from\",\"at\",\"my\",\"be\",\"by\",\"not\",\"that\",\"to\",\n",
    "                \"from\",\"com\",\"org\",\"like\",\"likes\",\"so\",\"said\",\"afrom\",\"what\",\"told\",\"over\",\"more\",\"other\",\n",
    "                \"have\",\"last\",\"with\",\"this\",\"that\",\"such\",\"when\",\"been\",\"says\",\"will\",\"also\",\"where\",\"why\",\n",
    "                \"would\",\"today\", \"in\", \"on\", \"you\", \"r\", \"d\", \"u\", \"hw\",\"wat\", \"oly\", \"s\", \"b\", \"ht\", \n",
    "                \"rt\", \"p\",\"the\",\"th\", \"n\", \"was\",\"demonetization\", \"did\", \"it\",\"it's\", \"lol\", \"way\",\"did\",\"you\",\"on\",\"if\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(words_remove)\n",
    "\n",
    "df['fully_clean_tweets'] = df['clean_tweet'].apply(lambda x : ' '.join([word for word in x.split() if word not in stop_words]))\n",
    "df['fully_clean_tweets'] = df['clean_tweet'].replace(r'\\'|\\\"|\\,|\\.|\\?|\\+|\\-|\\/|\\=|\\(|\\)|\\n|\\r|\\\"','',regex = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rssurjewala  critical question  was paytm informed about   edict   its clearly fishy and requires full disclosure</td>\n",
       "      <td>rssurjewala critical question was paytm informed about edict its clearly fishy and requires full disclosure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hemant 80  did you vote     modi survey app</td>\n",
       "      <td>hemant 80 did you vote modi survey app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roshankar  former finsec rbi  governor cbdt chair  harvard professor lambaste     not for aam aadmi listen</td>\n",
       "      <td>roshankar former finsec rbi governor cbdt chair harvard professor lambaste not for aam aadmi listen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ani news  gurugram haryana  post office employees provide cash exchange  patients  hospitals</td>\n",
       "      <td>ani news gurugram haryana post office employees provide cash exchange patients hospitals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satishacharya  reddy wedding   mail today cartoon    reddywedding</td>\n",
       "      <td>satishacharya reddy wedding mail today cartoon reddywedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14935</th>\n",
       "      <td>ghost   returns with reports  cash crunch across the country</td>\n",
       "      <td>ghost returns with reports cash crunch across the country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14936</th>\n",
       "      <td>modi fansd true nationalists  the country stil think    bst way 2 curb black mony  fake</td>\n",
       "      <td>modi fansd true nationalists the country stil think bst way 2 curb black mony fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>bharat builder  lol  has fixed  lot like stone pelters corruption black money join crunch global warming racism</td>\n",
       "      <td>bharat builder lol has fixed lot like stone pelters corruption black money join crunch global warming racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14938</th>\n",
       "      <td>stupidosaur   vidyut  team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demonetizati</td>\n",
       "      <td>stupidosaur vidyut team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demonetizati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14939</th>\n",
       "      <td>team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demon</td>\n",
       "      <td>team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14940 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                     cleaned_tweet  \\\n",
       "0               rssurjewala  critical question  was paytm informed about   edict   its clearly fishy and requires full disclosure    \n",
       "1                                                                                      hemant 80  did you vote     modi survey app   \n",
       "2                      roshankar  former finsec rbi  governor cbdt chair  harvard professor lambaste     not for aam aadmi listen    \n",
       "3                                    ani news  gurugram haryana  post office employees provide cash exchange  patients  hospitals    \n",
       "4                                                               satishacharya  reddy wedding   mail today cartoon    reddywedding    \n",
       "...                                                                                                                            ...   \n",
       "14935                                                                ghost   returns with reports  cash crunch across the country    \n",
       "14936                                     modi fansd true nationalists  the country stil think    bst way 2 curb black mony  fake    \n",
       "14937             bharat builder  lol  has fixed  lot like stone pelters corruption black money join crunch global warming racism    \n",
       "14938  stupidosaur   vidyut  team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demonetizati    \n",
       "14939                               team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demon    \n",
       "\n",
       "                                                                                                         fully_cleaned_tweet  \n",
       "0                rssurjewala critical question was paytm informed about edict its clearly fishy and requires full disclosure  \n",
       "1                                                                                     hemant 80 did you vote modi survey app  \n",
       "2                        roshankar former finsec rbi governor cbdt chair harvard professor lambaste not for aam aadmi listen  \n",
       "3                                   ani news gurugram haryana post office employees provide cash exchange patients hospitals  \n",
       "4                                                                satishacharya reddy wedding mail today cartoon reddywedding  \n",
       "...                                                                                                                      ...  \n",
       "14935                                                              ghost returns with reports cash crunch across the country  \n",
       "14936                                     modi fansd true nationalists the country stil think bst way 2 curb black mony fake  \n",
       "14937           bharat builder lol has fixed lot like stone pelters corruption black money join crunch global warming racism  \n",
       "14938  stupidosaur vidyut team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demonetizati  \n",
       "14939                            team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demon  \n",
       "\n",
       "[14940 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:,'cleaned_tweet':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment calculation\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "df['sentiment'] = df['fully_cleaned_tweet'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM informed about #Demonetization edict by PM? It's clearly fishy and requires full disclosure &amp;amp;…</td>\n",
       "      <td>rssurjewala  critical question  was paytm informed about   edict   its clearly fishy and requires full disclosure</td>\n",
       "      <td>rssurjewala critical question was paytm informed about edict its clearly fishy and requires full disclosure</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization on Modi survey app?</td>\n",
       "      <td>hemant 80  did you vote     modi survey app</td>\n",
       "      <td>hemant 80 did you vote modi survey app</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor, CBDT Chair + Harvard Professor lambaste #Demonetization.\\r\\n\\r\\nIf not for Aam Aadmi, listen to th…</td>\n",
       "      <td>roshankar  former finsec rbi  governor cbdt chair  harvard professor lambaste     not for aam aadmi listen</td>\n",
       "      <td>roshankar former finsec rbi governor cbdt chair harvard professor lambaste not for aam aadmi listen</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office employees provide cash exchange to patients in hospitals #demonetization https://t.co/uGMxUP9…</td>\n",
       "      <td>ani news  gurugram haryana  post office employees provide cash exchange  patients  hospitals</td>\n",
       "      <td>ani news gurugram haryana post office employees provide cash exchange patients hospitals</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today cartoon #demonetization #ReddyWedding https://t.co/u7gLNrq31F</td>\n",
       "      <td>satishacharya  reddy wedding   mail today cartoon    reddywedding</td>\n",
       "      <td>satishacharya reddy wedding mail today cartoon reddywedding</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14935</th>\n",
       "      <td>RT @saxenavishakha: Ghost of demonetization returns with reports of cash crunch across the country https://t.co/kQsBesTIUs</td>\n",
       "      <td>ghost   returns with reports  cash crunch across the country</td>\n",
       "      <td>ghost returns with reports cash crunch across the country</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14936</th>\n",
       "      <td>N d modi fans-d true nationalists of the country stil think demonetization ws d bst way 2 curb black mony n fake no… https://t.co/9mgMEFu2sl</td>\n",
       "      <td>modi fansd true nationalists  the country stil think    bst way 2 curb black mony  fake</td>\n",
       "      <td>modi fansd true nationalists the country stil think bst way 2 curb black mony fake</td>\n",
       "      <td>-0.105556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>RT @bharat_builder: Lol. Demonetization has fixed a lot, like stone pelters, corruption, black money, join crunch, global warming, racism,…</td>\n",
       "      <td>bharat builder  lol  has fixed  lot like stone pelters corruption black money join crunch global warming racism</td>\n",
       "      <td>bharat builder lol has fixed lot like stone pelters corruption black money join crunch global warming racism</td>\n",
       "      <td>0.183333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14938</th>\n",
       "      <td>RT @Stupidosaur: @Vidyut B team of BJP. CIA baby. CCTV, EVM but with VVPAT, support 'surgical strikes', JNU drama, timepass in demonetizati…</td>\n",
       "      <td>stupidosaur   vidyut  team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demonetizati</td>\n",
       "      <td>stupidosaur vidyut team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demonetizati</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14939</th>\n",
       "      <td>@Vidyut B team of BJP. CIA baby. CCTV, EVM but with VVPAT, support 'surgical strikes', JNU drama, timepass in demon… https://t.co/hwgqjbqgvG</td>\n",
       "      <td>team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demon</td>\n",
       "      <td>team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demon</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14940 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    tweet  \\\n",
       "0        RT @rssurjewala: Critical question: Was PayTM informed about #Demonetization edict by PM? It's clearly fishy and requires full disclosure &amp;…   \n",
       "1                                                                                      RT @Hemant_80: Did you vote on #Demonetization on Modi survey app?   \n",
       "2      RT @roshankar: Former FinSec, RBI Dy Governor, CBDT Chair + Harvard Professor lambaste #Demonetization.\\r\\n\\r\\nIf not for Aam Aadmi, listen to th…   \n",
       "3            RT @ANI_news: Gurugram (Haryana): Post office employees provide cash exchange to patients in hospitals #demonetization https://t.co/uGMxUP9…   \n",
       "4                                             RT @satishacharya: Reddy Wedding! @mail_today cartoon #demonetization #ReddyWedding https://t.co/u7gLNrq31F   \n",
       "...                                                                                                                                                   ...   \n",
       "14935                          RT @saxenavishakha: Ghost of demonetization returns with reports of cash crunch across the country https://t.co/kQsBesTIUs   \n",
       "14936        N d modi fans-d true nationalists of the country stil think demonetization ws d bst way 2 curb black mony n fake no… https://t.co/9mgMEFu2sl   \n",
       "14937         RT @bharat_builder: Lol. Demonetization has fixed a lot, like stone pelters, corruption, black money, join crunch, global warming, racism,…   \n",
       "14938        RT @Stupidosaur: @Vidyut B team of BJP. CIA baby. CCTV, EVM but with VVPAT, support 'surgical strikes', JNU drama, timepass in demonetizati…   \n",
       "14939        @Vidyut B team of BJP. CIA baby. CCTV, EVM but with VVPAT, support 'surgical strikes', JNU drama, timepass in demon… https://t.co/hwgqjbqgvG   \n",
       "\n",
       "                                                                                                                     cleaned_tweet  \\\n",
       "0               rssurjewala  critical question  was paytm informed about   edict   its clearly fishy and requires full disclosure    \n",
       "1                                                                                      hemant 80  did you vote     modi survey app   \n",
       "2                      roshankar  former finsec rbi  governor cbdt chair  harvard professor lambaste     not for aam aadmi listen    \n",
       "3                                    ani news  gurugram haryana  post office employees provide cash exchange  patients  hospitals    \n",
       "4                                                               satishacharya  reddy wedding   mail today cartoon    reddywedding    \n",
       "...                                                                                                                            ...   \n",
       "14935                                                                ghost   returns with reports  cash crunch across the country    \n",
       "14936                                     modi fansd true nationalists  the country stil think    bst way 2 curb black mony  fake    \n",
       "14937             bharat builder  lol  has fixed  lot like stone pelters corruption black money join crunch global warming racism    \n",
       "14938  stupidosaur   vidyut  team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demonetizati    \n",
       "14939                               team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demon    \n",
       "\n",
       "                                                                                                         fully_cleaned_tweet  \\\n",
       "0                rssurjewala critical question was paytm informed about edict its clearly fishy and requires full disclosure   \n",
       "1                                                                                     hemant 80 did you vote modi survey app   \n",
       "2                        roshankar former finsec rbi governor cbdt chair harvard professor lambaste not for aam aadmi listen   \n",
       "3                                   ani news gurugram haryana post office employees provide cash exchange patients hospitals   \n",
       "4                                                                satishacharya reddy wedding mail today cartoon reddywedding   \n",
       "...                                                                                                                      ...   \n",
       "14935                                                              ghost returns with reports cash crunch across the country   \n",
       "14936                                     modi fansd true nationalists the country stil think bst way 2 curb black mony fake   \n",
       "14937           bharat builder lol has fixed lot like stone pelters corruption black money join crunch global warming racism   \n",
       "14938  stupidosaur vidyut team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demonetizati   \n",
       "14939                            team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demon   \n",
       "\n",
       "       sentiment  \n",
       "0       0.150000  \n",
       "1       0.000000  \n",
       "2       0.000000  \n",
       "3       0.000000  \n",
       "4       0.000000  \n",
       "...          ...  \n",
       "14935   0.000000  \n",
       "14936  -0.105556  \n",
       "14937   0.183333  \n",
       "14938   0.000000  \n",
       "14939   0.000000  \n",
       "\n",
       "[14940 rows x 4 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply data cleaning round3\n",
    "\n",
    "tweet_tokenizer = TweetTokenizer()\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "final_df = {}\n",
    "\n",
    "for i,j in enumerate(df['fully_cleaned_tweet']):\n",
    "    final_df[i] = tweet_tokenizer.tokenize(j)\n",
    "    \n",
    "final_df = {key: [i for i in value if len(i) > 2] for (key,value) in final_df.items()}    \n",
    "final_df = {key:[t for t in value if t not in stopwords.words('english')] for (key,value) in final_df.items()}\n",
    "final_df = {key:[lemma.lemmatize(t) for t in value] for (key,value) in final_df.items()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rssurjewala critical question paytm informed edict clearly fishy requires full disclosure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hemant vote modi survey app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roshankar former finsec rbi governor cbdt chair harvard professor lambaste aam aadmi listen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ani news gurugram haryana post office employee provide cash exchange patient hospital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>satishacharya reddy wedding mail today cartoon reddywedding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14935</th>\n",
       "      <td>ghost return report cash crunch across country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14936</th>\n",
       "      <td>modi fansd true nationalist country stil think bst way curb black mony fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>bharat builder lol fixed lot like stone pelter corruption black money join crunch global warming racism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14938</th>\n",
       "      <td>stupidosaur vidyut team bjp cia baby cctv evm vvpat support surgical strike jnu drama timepass demonetizati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14939</th>\n",
       "      <td>team bjp cia baby cctv evm vvpat support surgical strike jnu drama timepass demon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14940 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                 0\n",
       "0                        rssurjewala critical question paytm informed edict clearly fishy requires full disclosure\n",
       "1                                                                                      hemant vote modi survey app\n",
       "2                      roshankar former finsec rbi governor cbdt chair harvard professor lambaste aam aadmi listen\n",
       "3                            ani news gurugram haryana post office employee provide cash exchange patient hospital\n",
       "4                                                      satishacharya reddy wedding mail today cartoon reddywedding\n",
       "...                                                                                                            ...\n",
       "14935                                                               ghost return report cash crunch across country\n",
       "14936                                  modi fansd true nationalist country stil think bst way curb black mony fake\n",
       "14937      bharat builder lol fixed lot like stone pelter corruption black money join crunch global warming racism\n",
       "14938  stupidosaur vidyut team bjp cia baby cctv evm vvpat support surgical strike jnu drama timepass demonetizati\n",
       "14939                            team bjp cia baby cctv evm vvpat support surgical strike jnu drama timepass demon\n",
       "\n",
       "[14940 rows x 1 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_cleaned = {key: [' '.join(value)] for (key,value) in final_df.items()}\n",
    "data_cleaned = pd.DataFrame(data_cleaned.values())\n",
    "data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df,data_cleaned[0].apply(lambda x: tweet_tokenizer.tokenize(x))],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['tweet', 'cleaned_tweet', 'fully_cleaned_tweet', 'sentiment', 'tokenized_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dipendradipzo',\n",
       " 'effect',\n",
       " 'come',\n",
       " 'another',\n",
       " 'batch',\n",
       " 'maoist',\n",
       " 'keep',\n",
       " 'watching',\n",
       " 'come',\n",
       " 'nomoneyyaar']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[6878,'tokenized_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['india', 'blackmoney', 'symptom', 'disease']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[5,'tokenized_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM informed about #Demonetization edict by PM? It's clearly fishy and requires full disclosure &amp;amp;…</td>\n",
       "      <td>rssurjewala  critical question  was paytm informed about   edict   its clearly fishy and requires full disclosure</td>\n",
       "      <td>rssurjewala critical question was paytm informed about edict its clearly fishy and requires full disclosure</td>\n",
       "      <td>0.15</td>\n",
       "      <td>[rssurjewala, critical, question, paytm, informed, edict, clearly, fishy, requires, full, disclosure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization on Modi survey app?</td>\n",
       "      <td>hemant 80  did you vote     modi survey app</td>\n",
       "      <td>hemant 80 did you vote modi survey app</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[hemant, vote, modi, survey, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor, CBDT Chair + Harvard Professor lambaste #Demonetization.\\r\\n\\r\\nIf not for Aam Aadmi, listen to th…</td>\n",
       "      <td>roshankar  former finsec rbi  governor cbdt chair  harvard professor lambaste     not for aam aadmi listen</td>\n",
       "      <td>roshankar former finsec rbi governor cbdt chair harvard professor lambaste not for aam aadmi listen</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[roshankar, former, finsec, rbi, governor, cbdt, chair, harvard, professor, lambaste, aam, aadmi, listen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office employees provide cash exchange to patients in hospitals #demonetization https://t.co/uGMxUP9…</td>\n",
       "      <td>ani news  gurugram haryana  post office employees provide cash exchange  patients  hospitals</td>\n",
       "      <td>ani news gurugram haryana post office employees provide cash exchange patients hospitals</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[ani, news, gurugram, haryana, post, office, employee, provide, cash, exchange, patient, hospital]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today cartoon #demonetization #ReddyWedding https://t.co/u7gLNrq31F</td>\n",
       "      <td>satishacharya  reddy wedding   mail today cartoon    reddywedding</td>\n",
       "      <td>satishacharya reddy wedding mail today cartoon reddywedding</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[satishacharya, reddy, wedding, mail, today, cartoon, reddywedding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@DerekScissors1: India’s #demonetization: #Blackmoney a symptom, not the disease https://t.co/HSl6Ihj0Qe via @ambazaarmag</td>\n",
       "      <td>india      blackmoney  symptom not the disease</td>\n",
       "      <td>india blackmoney symptom not the disease</td>\n",
       "      <td>0.00</td>\n",
       "      <td>[india, blackmoney, symptom, disease]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                tweet  \\\n",
       "0    RT @rssurjewala: Critical question: Was PayTM informed about #Demonetization edict by PM? It's clearly fishy and requires full disclosure &amp;…   \n",
       "1                                                                                  RT @Hemant_80: Did you vote on #Demonetization on Modi survey app?   \n",
       "2  RT @roshankar: Former FinSec, RBI Dy Governor, CBDT Chair + Harvard Professor lambaste #Demonetization.\\r\\n\\r\\nIf not for Aam Aadmi, listen to th…   \n",
       "3        RT @ANI_news: Gurugram (Haryana): Post office employees provide cash exchange to patients in hospitals #demonetization https://t.co/uGMxUP9…   \n",
       "4                                         RT @satishacharya: Reddy Wedding! @mail_today cartoon #demonetization #ReddyWedding https://t.co/u7gLNrq31F   \n",
       "5                           @DerekScissors1: India’s #demonetization: #Blackmoney a symptom, not the disease https://t.co/HSl6Ihj0Qe via @ambazaarmag   \n",
       "\n",
       "                                                                                                        cleaned_tweet  \\\n",
       "0  rssurjewala  critical question  was paytm informed about   edict   its clearly fishy and requires full disclosure    \n",
       "1                                                                         hemant 80  did you vote     modi survey app   \n",
       "2         roshankar  former finsec rbi  governor cbdt chair  harvard professor lambaste     not for aam aadmi listen    \n",
       "3                       ani news  gurugram haryana  post office employees provide cash exchange  patients  hospitals    \n",
       "4                                                  satishacharya  reddy wedding   mail today cartoon    reddywedding    \n",
       "5                                                                     india      blackmoney  symptom not the disease    \n",
       "\n",
       "                                                                                           fully_cleaned_tweet  \\\n",
       "0  rssurjewala critical question was paytm informed about edict its clearly fishy and requires full disclosure   \n",
       "1                                                                       hemant 80 did you vote modi survey app   \n",
       "2          roshankar former finsec rbi governor cbdt chair harvard professor lambaste not for aam aadmi listen   \n",
       "3                     ani news gurugram haryana post office employees provide cash exchange patients hospitals   \n",
       "4                                                  satishacharya reddy wedding mail today cartoon reddywedding   \n",
       "5                                                                     india blackmoney symptom not the disease   \n",
       "\n",
       "   sentiment  \\\n",
       "0       0.15   \n",
       "1       0.00   \n",
       "2       0.00   \n",
       "3       0.00   \n",
       "4       0.00   \n",
       "5       0.00   \n",
       "\n",
       "                                                                                             tokenized_tweet  \n",
       "0      [rssurjewala, critical, question, paytm, informed, edict, clearly, fishy, requires, full, disclosure]  \n",
       "1                                                                          [hemant, vote, modi, survey, app]  \n",
       "2  [roshankar, former, finsec, rbi, governor, cbdt, chair, harvard, professor, lambaste, aam, aadmi, listen]  \n",
       "3         [ani, news, gurugram, haryana, post, office, employee, provide, cash, exchange, patient, hospital]  \n",
       "4                                        [satishacharya, reddy, wedding, mail, today, cartoon, reddywedding]  \n",
       "5                                                                      [india, blackmoney, symptom, disease]  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'actually']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[9997,'tokenized_tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_tweet'] = df['tokenized_tweet'].apply(lambda x: [y for y in x if not any(c.isdigit() for c in y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @rssurjewala: Critical question: Was PayTM informed about #Demonetization edict by PM? It's clearly fishy and requires full disclosure &amp;amp;…</td>\n",
       "      <td>rssurjewala  critical question  was paytm informed about   edict   its clearly fishy and requires full disclosure</td>\n",
       "      <td>rssurjewala critical question was paytm informed about edict its clearly fishy and requires full disclosure</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>[rssurjewala, critical, question, paytm, informed, edict, clearly, fishy, requires, full, disclosure]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @Hemant_80: Did you vote on #Demonetization on Modi survey app?</td>\n",
       "      <td>hemant 80  did you vote     modi survey app</td>\n",
       "      <td>hemant 80 did you vote modi survey app</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[hemant, vote, modi, survey, app]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @roshankar: Former FinSec, RBI Dy Governor, CBDT Chair + Harvard Professor lambaste #Demonetization.\\r\\n\\r\\nIf not for Aam Aadmi, listen to th…</td>\n",
       "      <td>roshankar  former finsec rbi  governor cbdt chair  harvard professor lambaste     not for aam aadmi listen</td>\n",
       "      <td>roshankar former finsec rbi governor cbdt chair harvard professor lambaste not for aam aadmi listen</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[roshankar, former, finsec, rbi, governor, cbdt, chair, harvard, professor, lambaste, aam, aadmi, listen]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @ANI_news: Gurugram (Haryana): Post office employees provide cash exchange to patients in hospitals #demonetization https://t.co/uGMxUP9…</td>\n",
       "      <td>ani news  gurugram haryana  post office employees provide cash exchange  patients  hospitals</td>\n",
       "      <td>ani news gurugram haryana post office employees provide cash exchange patients hospitals</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[ani, news, gurugram, haryana, post, office, employee, provide, cash, exchange, patient, hospital]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @satishacharya: Reddy Wedding! @mail_today cartoon #demonetization #ReddyWedding https://t.co/u7gLNrq31F</td>\n",
       "      <td>satishacharya  reddy wedding   mail today cartoon    reddywedding</td>\n",
       "      <td>satishacharya reddy wedding mail today cartoon reddywedding</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[satishacharya, reddy, wedding, mail, today, cartoon, reddywedding]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14935</th>\n",
       "      <td>RT @saxenavishakha: Ghost of demonetization returns with reports of cash crunch across the country https://t.co/kQsBesTIUs</td>\n",
       "      <td>ghost   returns with reports  cash crunch across the country</td>\n",
       "      <td>ghost returns with reports cash crunch across the country</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[ghost, return, report, cash, crunch, across, country]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14936</th>\n",
       "      <td>N d modi fans-d true nationalists of the country stil think demonetization ws d bst way 2 curb black mony n fake no… https://t.co/9mgMEFu2sl</td>\n",
       "      <td>modi fansd true nationalists  the country stil think    bst way 2 curb black mony  fake</td>\n",
       "      <td>modi fansd true nationalists the country stil think bst way 2 curb black mony fake</td>\n",
       "      <td>-0.105556</td>\n",
       "      <td>[modi, fansd, true, nationalist, country, stil, think, bst, way, curb, black, mony, fake]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>RT @bharat_builder: Lol. Demonetization has fixed a lot, like stone pelters, corruption, black money, join crunch, global warming, racism,…</td>\n",
       "      <td>bharat builder  lol  has fixed  lot like stone pelters corruption black money join crunch global warming racism</td>\n",
       "      <td>bharat builder lol has fixed lot like stone pelters corruption black money join crunch global warming racism</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>[bharat, builder, lol, fixed, lot, like, stone, pelter, corruption, black, money, join, crunch, global, warming, racism]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14938</th>\n",
       "      <td>RT @Stupidosaur: @Vidyut B team of BJP. CIA baby. CCTV, EVM but with VVPAT, support 'surgical strikes', JNU drama, timepass in demonetizati…</td>\n",
       "      <td>stupidosaur   vidyut  team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demonetizati</td>\n",
       "      <td>stupidosaur vidyut team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demonetizati</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[stupidosaur, vidyut, team, bjp, cia, baby, cctv, evm, vvpat, support, surgical, strike, jnu, drama, timepass, demonetizati]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14939</th>\n",
       "      <td>@Vidyut B team of BJP. CIA baby. CCTV, EVM but with VVPAT, support 'surgical strikes', JNU drama, timepass in demon… https://t.co/hwgqjbqgvG</td>\n",
       "      <td>team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demon</td>\n",
       "      <td>team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demon</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[team, bjp, cia, baby, cctv, evm, vvpat, support, surgical, strike, jnu, drama, timepass, demon]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14940 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    tweet  \\\n",
       "0        RT @rssurjewala: Critical question: Was PayTM informed about #Demonetization edict by PM? It's clearly fishy and requires full disclosure &amp;…   \n",
       "1                                                                                      RT @Hemant_80: Did you vote on #Demonetization on Modi survey app?   \n",
       "2      RT @roshankar: Former FinSec, RBI Dy Governor, CBDT Chair + Harvard Professor lambaste #Demonetization.\\r\\n\\r\\nIf not for Aam Aadmi, listen to th…   \n",
       "3            RT @ANI_news: Gurugram (Haryana): Post office employees provide cash exchange to patients in hospitals #demonetization https://t.co/uGMxUP9…   \n",
       "4                                             RT @satishacharya: Reddy Wedding! @mail_today cartoon #demonetization #ReddyWedding https://t.co/u7gLNrq31F   \n",
       "...                                                                                                                                                   ...   \n",
       "14935                          RT @saxenavishakha: Ghost of demonetization returns with reports of cash crunch across the country https://t.co/kQsBesTIUs   \n",
       "14936        N d modi fans-d true nationalists of the country stil think demonetization ws d bst way 2 curb black mony n fake no… https://t.co/9mgMEFu2sl   \n",
       "14937         RT @bharat_builder: Lol. Demonetization has fixed a lot, like stone pelters, corruption, black money, join crunch, global warming, racism,…   \n",
       "14938        RT @Stupidosaur: @Vidyut B team of BJP. CIA baby. CCTV, EVM but with VVPAT, support 'surgical strikes', JNU drama, timepass in demonetizati…   \n",
       "14939        @Vidyut B team of BJP. CIA baby. CCTV, EVM but with VVPAT, support 'surgical strikes', JNU drama, timepass in demon… https://t.co/hwgqjbqgvG   \n",
       "\n",
       "                                                                                                                     cleaned_tweet  \\\n",
       "0               rssurjewala  critical question  was paytm informed about   edict   its clearly fishy and requires full disclosure    \n",
       "1                                                                                      hemant 80  did you vote     modi survey app   \n",
       "2                      roshankar  former finsec rbi  governor cbdt chair  harvard professor lambaste     not for aam aadmi listen    \n",
       "3                                    ani news  gurugram haryana  post office employees provide cash exchange  patients  hospitals    \n",
       "4                                                               satishacharya  reddy wedding   mail today cartoon    reddywedding    \n",
       "...                                                                                                                            ...   \n",
       "14935                                                                ghost   returns with reports  cash crunch across the country    \n",
       "14936                                     modi fansd true nationalists  the country stil think    bst way 2 curb black mony  fake    \n",
       "14937             bharat builder  lol  has fixed  lot like stone pelters corruption black money join crunch global warming racism    \n",
       "14938  stupidosaur   vidyut  team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demonetizati    \n",
       "14939                               team  bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass  demon    \n",
       "\n",
       "                                                                                                         fully_cleaned_tweet  \\\n",
       "0                rssurjewala critical question was paytm informed about edict its clearly fishy and requires full disclosure   \n",
       "1                                                                                     hemant 80 did you vote modi survey app   \n",
       "2                        roshankar former finsec rbi governor cbdt chair harvard professor lambaste not for aam aadmi listen   \n",
       "3                                   ani news gurugram haryana post office employees provide cash exchange patients hospitals   \n",
       "4                                                                satishacharya reddy wedding mail today cartoon reddywedding   \n",
       "...                                                                                                                      ...   \n",
       "14935                                                              ghost returns with reports cash crunch across the country   \n",
       "14936                                     modi fansd true nationalists the country stil think bst way 2 curb black mony fake   \n",
       "14937           bharat builder lol has fixed lot like stone pelters corruption black money join crunch global warming racism   \n",
       "14938  stupidosaur vidyut team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demonetizati   \n",
       "14939                            team bjp cia baby cctv evm but with vvpat support surgical strikes jnu drama timepass demon   \n",
       "\n",
       "       sentiment  \\\n",
       "0       0.150000   \n",
       "1       0.000000   \n",
       "2       0.000000   \n",
       "3       0.000000   \n",
       "4       0.000000   \n",
       "...          ...   \n",
       "14935   0.000000   \n",
       "14936  -0.105556   \n",
       "14937   0.183333   \n",
       "14938   0.000000   \n",
       "14939   0.000000   \n",
       "\n",
       "                                                                                                                    tokenized_tweet  \n",
       "0                             [rssurjewala, critical, question, paytm, informed, edict, clearly, fishy, requires, full, disclosure]  \n",
       "1                                                                                                 [hemant, vote, modi, survey, app]  \n",
       "2                         [roshankar, former, finsec, rbi, governor, cbdt, chair, harvard, professor, lambaste, aam, aadmi, listen]  \n",
       "3                                [ani, news, gurugram, haryana, post, office, employee, provide, cash, exchange, patient, hospital]  \n",
       "4                                                               [satishacharya, reddy, wedding, mail, today, cartoon, reddywedding]  \n",
       "...                                                                                                                             ...  \n",
       "14935                                                                        [ghost, return, report, cash, crunch, across, country]  \n",
       "14936                                     [modi, fansd, true, nationalist, country, stil, think, bst, way, curb, black, mony, fake]  \n",
       "14937      [bharat, builder, lol, fixed, lot, like, stone, pelter, corruption, black, money, join, crunch, global, warming, racism]  \n",
       "14938  [stupidosaur, vidyut, team, bjp, cia, baby, cctv, evm, vvpat, support, surgical, strike, jnu, drama, timepass, demonetizati]  \n",
       "14939                              [team, bjp, cia, baby, cctv, evm, vvpat, support, surgical, strike, jnu, drama, timepass, demon]  \n",
       "\n",
       "[14940 rows x 5 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set value for various parameters\n",
    "\n",
    "num_features = 200    # Word vector dimensionality                      \n",
    "min_word_count = 1   # Minimum word count                        \n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size                                                                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model.....\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the model \n",
    "\n",
    "from gensim.models import word2vec\n",
    "\n",
    "print(\"Training model.....\")\n",
    "\n",
    "model = word2vec.Word2Vec(df['tokenized_tweet'], workers = num_workers, size = num_features, min_count = min_word_count, window = context)\n",
    "\n",
    "# If you don't plan to train the model any further, calling \n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking an average of all/total word vectors\n",
    "\n",
    "vocabulary = list(model.wv.vocab)\n",
    "\n",
    "def sentence_vector(sentence, model):\n",
    "    nwords = 0\n",
    "    featurev = np.zeros(200, dtype = \"float32\")\n",
    "    for word in sentence:\n",
    "        if word not in vocabulary:\n",
    "            continue\n",
    "        featurev = np.add(featurev, model[word])\n",
    "        nwords = nwords + 1\n",
    "    if nwords > 0:\n",
    "        featurev = np.divide(featurev, nwords)    # Avearge\n",
    "    return featurev\n",
    "\n",
    "tweet_vector = df['tokenized_tweet'].apply(lambda x: sentence_vector(x, model))\n",
    "\n",
    "tweet_vector = tweet_vector.apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing\n",
    "\n",
    "for x in range(len(tweet_vector)):\n",
    "    x_min = tweet_vector.iloc[x].min()\n",
    "    x_max = tweet_vector.iloc[x].max()\n",
    "    X = tweet_vector.iloc[x]\n",
    "    i = 0\n",
    "    if (x_max - x_min) == 0:\n",
    "        for y in X:\n",
    "            tweet_vector.iloc[x][i] = (1/len(tweet_vector.iloc[x]))\n",
    "            i += 1\n",
    "    else:\n",
    "        for y in X:\n",
    "            tweet_vector.iloc[x][i] = ((y-x_min)/(x_max - x_min))\n",
    "            i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale the sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sentiment varies from '-1' to '+1'\n",
    "\n",
    "def sentiment_scale(x):\n",
    "    if x < 0.02:\n",
    "        return -1\n",
    "    elif x > 0.02:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_vector[200] = df['sentiment'].apply(lambda x: sentiment_scale(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "      <th>200</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.469887</td>\n",
       "      <td>0.380007</td>\n",
       "      <td>0.837662</td>\n",
       "      <td>0.214978</td>\n",
       "      <td>0.590058</td>\n",
       "      <td>0.232306</td>\n",
       "      <td>0.624098</td>\n",
       "      <td>0.800620</td>\n",
       "      <td>0.189681</td>\n",
       "      <td>0.860948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360170</td>\n",
       "      <td>0.728793</td>\n",
       "      <td>0.530617</td>\n",
       "      <td>0.685926</td>\n",
       "      <td>0.544501</td>\n",
       "      <td>0.772273</td>\n",
       "      <td>0.625076</td>\n",
       "      <td>0.625003</td>\n",
       "      <td>0.844490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.325008</td>\n",
       "      <td>0.237455</td>\n",
       "      <td>0.845748</td>\n",
       "      <td>0.236687</td>\n",
       "      <td>0.563119</td>\n",
       "      <td>0.606286</td>\n",
       "      <td>0.479480</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.512879</td>\n",
       "      <td>0.730609</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577877</td>\n",
       "      <td>0.624010</td>\n",
       "      <td>0.502643</td>\n",
       "      <td>0.727371</td>\n",
       "      <td>0.536815</td>\n",
       "      <td>0.666105</td>\n",
       "      <td>0.611619</td>\n",
       "      <td>0.694737</td>\n",
       "      <td>0.485033</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.579798</td>\n",
       "      <td>0.333156</td>\n",
       "      <td>0.817072</td>\n",
       "      <td>0.425065</td>\n",
       "      <td>0.588356</td>\n",
       "      <td>0.652669</td>\n",
       "      <td>0.505379</td>\n",
       "      <td>0.846052</td>\n",
       "      <td>0.345582</td>\n",
       "      <td>0.804295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.681305</td>\n",
       "      <td>0.744385</td>\n",
       "      <td>0.438083</td>\n",
       "      <td>0.869020</td>\n",
       "      <td>0.647612</td>\n",
       "      <td>0.734882</td>\n",
       "      <td>0.717515</td>\n",
       "      <td>0.810521</td>\n",
       "      <td>0.680231</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.611462</td>\n",
       "      <td>0.382278</td>\n",
       "      <td>0.748222</td>\n",
       "      <td>0.469238</td>\n",
       "      <td>0.558684</td>\n",
       "      <td>0.626619</td>\n",
       "      <td>0.466037</td>\n",
       "      <td>0.841157</td>\n",
       "      <td>0.293151</td>\n",
       "      <td>0.789181</td>\n",
       "      <td>...</td>\n",
       "      <td>0.649204</td>\n",
       "      <td>0.767031</td>\n",
       "      <td>0.448001</td>\n",
       "      <td>0.877373</td>\n",
       "      <td>0.672183</td>\n",
       "      <td>0.717663</td>\n",
       "      <td>0.712881</td>\n",
       "      <td>0.771989</td>\n",
       "      <td>0.693383</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.518794</td>\n",
       "      <td>0.271648</td>\n",
       "      <td>0.884246</td>\n",
       "      <td>0.440363</td>\n",
       "      <td>0.540318</td>\n",
       "      <td>0.430667</td>\n",
       "      <td>0.490634</td>\n",
       "      <td>0.755385</td>\n",
       "      <td>0.295689</td>\n",
       "      <td>0.761431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268610</td>\n",
       "      <td>0.606325</td>\n",
       "      <td>0.439655</td>\n",
       "      <td>0.915486</td>\n",
       "      <td>0.637254</td>\n",
       "      <td>0.657952</td>\n",
       "      <td>0.728533</td>\n",
       "      <td>0.494194</td>\n",
       "      <td>0.502654</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14935</th>\n",
       "      <td>0.578509</td>\n",
       "      <td>0.377737</td>\n",
       "      <td>0.852440</td>\n",
       "      <td>0.514004</td>\n",
       "      <td>0.528003</td>\n",
       "      <td>0.641571</td>\n",
       "      <td>0.420554</td>\n",
       "      <td>0.888631</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.696923</td>\n",
       "      <td>...</td>\n",
       "      <td>0.478308</td>\n",
       "      <td>0.855978</td>\n",
       "      <td>0.607431</td>\n",
       "      <td>0.891804</td>\n",
       "      <td>0.687848</td>\n",
       "      <td>0.735070</td>\n",
       "      <td>0.719693</td>\n",
       "      <td>0.652130</td>\n",
       "      <td>0.651925</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14936</th>\n",
       "      <td>0.611937</td>\n",
       "      <td>0.290983</td>\n",
       "      <td>0.748001</td>\n",
       "      <td>0.496187</td>\n",
       "      <td>0.568816</td>\n",
       "      <td>0.670056</td>\n",
       "      <td>0.380258</td>\n",
       "      <td>0.753226</td>\n",
       "      <td>0.283437</td>\n",
       "      <td>0.707261</td>\n",
       "      <td>...</td>\n",
       "      <td>0.603519</td>\n",
       "      <td>0.683852</td>\n",
       "      <td>0.354068</td>\n",
       "      <td>0.917372</td>\n",
       "      <td>0.629176</td>\n",
       "      <td>0.683758</td>\n",
       "      <td>0.675764</td>\n",
       "      <td>0.736101</td>\n",
       "      <td>0.591465</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>0.580775</td>\n",
       "      <td>0.285160</td>\n",
       "      <td>0.743671</td>\n",
       "      <td>0.420304</td>\n",
       "      <td>0.472418</td>\n",
       "      <td>0.676171</td>\n",
       "      <td>0.415709</td>\n",
       "      <td>0.777813</td>\n",
       "      <td>0.120938</td>\n",
       "      <td>0.585728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695394</td>\n",
       "      <td>0.782300</td>\n",
       "      <td>0.380249</td>\n",
       "      <td>0.730235</td>\n",
       "      <td>0.503579</td>\n",
       "      <td>0.669203</td>\n",
       "      <td>0.582243</td>\n",
       "      <td>0.795267</td>\n",
       "      <td>0.687885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14938</th>\n",
       "      <td>0.549148</td>\n",
       "      <td>0.326082</td>\n",
       "      <td>0.805109</td>\n",
       "      <td>0.349689</td>\n",
       "      <td>0.537639</td>\n",
       "      <td>0.588398</td>\n",
       "      <td>0.508299</td>\n",
       "      <td>0.832419</td>\n",
       "      <td>0.279182</td>\n",
       "      <td>0.752649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.655326</td>\n",
       "      <td>0.745627</td>\n",
       "      <td>0.430265</td>\n",
       "      <td>0.788647</td>\n",
       "      <td>0.601260</td>\n",
       "      <td>0.693042</td>\n",
       "      <td>0.644653</td>\n",
       "      <td>0.775645</td>\n",
       "      <td>0.673381</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14939</th>\n",
       "      <td>0.543178</td>\n",
       "      <td>0.327548</td>\n",
       "      <td>0.806145</td>\n",
       "      <td>0.345227</td>\n",
       "      <td>0.532997</td>\n",
       "      <td>0.585713</td>\n",
       "      <td>0.507119</td>\n",
       "      <td>0.831935</td>\n",
       "      <td>0.267942</td>\n",
       "      <td>0.738210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.654519</td>\n",
       "      <td>0.750825</td>\n",
       "      <td>0.432986</td>\n",
       "      <td>0.775270</td>\n",
       "      <td>0.591107</td>\n",
       "      <td>0.690974</td>\n",
       "      <td>0.636748</td>\n",
       "      <td>0.775010</td>\n",
       "      <td>0.677776</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14940 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6    \\\n",
       "0      0.469887  0.380007  0.837662  0.214978  0.590058  0.232306  0.624098   \n",
       "1      0.325008  0.237455  0.845748  0.236687  0.563119  0.606286  0.479480   \n",
       "2      0.579798  0.333156  0.817072  0.425065  0.588356  0.652669  0.505379   \n",
       "3      0.611462  0.382278  0.748222  0.469238  0.558684  0.626619  0.466037   \n",
       "4      0.518794  0.271648  0.884246  0.440363  0.540318  0.430667  0.490634   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "14935  0.578509  0.377737  0.852440  0.514004  0.528003  0.641571  0.420554   \n",
       "14936  0.611937  0.290983  0.748001  0.496187  0.568816  0.670056  0.380258   \n",
       "14937  0.580775  0.285160  0.743671  0.420304  0.472418  0.676171  0.415709   \n",
       "14938  0.549148  0.326082  0.805109  0.349689  0.537639  0.588398  0.508299   \n",
       "14939  0.543178  0.327548  0.806145  0.345227  0.532997  0.585713  0.507119   \n",
       "\n",
       "            7         8         9    ...       191       192       193  \\\n",
       "0      0.800620  0.189681  0.860948  ...  0.360170  0.728793  0.530617   \n",
       "1      0.760563  0.512879  0.730609  ...  0.577877  0.624010  0.502643   \n",
       "2      0.846052  0.345582  0.804295  ...  0.681305  0.744385  0.438083   \n",
       "3      0.841157  0.293151  0.789181  ...  0.649204  0.767031  0.448001   \n",
       "4      0.755385  0.295689  0.761431  ...  0.268610  0.606325  0.439655   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "14935  0.888631  0.233700  0.696923  ...  0.478308  0.855978  0.607431   \n",
       "14936  0.753226  0.283437  0.707261  ...  0.603519  0.683852  0.354068   \n",
       "14937  0.777813  0.120938  0.585728  ...  0.695394  0.782300  0.380249   \n",
       "14938  0.832419  0.279182  0.752649  ...  0.655326  0.745627  0.430265   \n",
       "14939  0.831935  0.267942  0.738210  ...  0.654519  0.750825  0.432986   \n",
       "\n",
       "            194       195       196       197       198       199  200  \n",
       "0      0.685926  0.544501  0.772273  0.625076  0.625003  0.844490    1  \n",
       "1      0.727371  0.536815  0.666105  0.611619  0.694737  0.485033   -1  \n",
       "2      0.869020  0.647612  0.734882  0.717515  0.810521  0.680231   -1  \n",
       "3      0.877373  0.672183  0.717663  0.712881  0.771989  0.693383   -1  \n",
       "4      0.915486  0.637254  0.657952  0.728533  0.494194  0.502654   -1  \n",
       "...         ...       ...       ...       ...       ...       ...  ...  \n",
       "14935  0.891804  0.687848  0.735070  0.719693  0.652130  0.651925   -1  \n",
       "14936  0.917372  0.629176  0.683758  0.675764  0.736101  0.591465   -1  \n",
       "14937  0.730235  0.503579  0.669203  0.582243  0.795267  0.687885    1  \n",
       "14938  0.788647  0.601260  0.693042  0.644653  0.775645  0.673381   -1  \n",
       "14939  0.775270  0.591107  0.690974  0.636748  0.775010  0.677776   -1  \n",
       "\n",
       "[14940 rows x 201 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentiment'] = tweet_vector[200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster the Narratives[opinions + expressions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 30 The average silhouette score is : 0.4152498459032458\n",
      "For n_clusters = 40 The average silhouette score is : 0.4285573710489477\n",
      "For n_clusters = 50 The average silhouette score is : 0.43641379294728855\n",
      "For n_clusters = 60 The average silhouette score is : 0.4627501597807085\n",
      "For n_clusters = 70 The average silhouette score is : 0.47661497942483144\n",
      "For n_clusters = 80 The average silhouette score is : 0.4994855947010412\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "n_clusters = [30,40,50,60,70,80]\n",
    "\n",
    "X = tweet_vector\n",
    "\n",
    "best_clusters = 0\n",
    "silhouette_best = 0\n",
    "for n in n_clusters:\n",
    "    \n",
    "    cluster = KMeans(n_clusters = n, random_state = 40)\n",
    "    cluster_labels = cluster.fit_predict(X)\n",
    "    \n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    \n",
    "    print(\"For n_clusters =\", n,\"The average silhouette score is :\", silhouette_avg)\n",
    "    \n",
    "    if silhouette_avg > silhouette_best:\n",
    "        silhouette_best = silhouette_avg\n",
    "        best_clusters = n          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_label'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet', 'cleaned_tweet', 'fully_cleaned_tweet', 'sentiment',\n",
       "       'tokenized_tweet', 'cluster_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordered = pd.DataFrame(df)\n",
    "\n",
    "df_ordered['tokenized_tweet'] = df_ordered['tokenized_tweet'].apply(tuple)\n",
    "\n",
    "df_unique = df_ordered.groupby(['tweet', 'cleaned_tweet', 'fully_cleaned_tweet', 'sentiment','tokenized_tweet','cluster_label']).size().reset_index(name = 'frequency')\n",
    "\n",
    "df_unique = df_unique.sort_values(by = ['cluster_label'])\n",
    "\n",
    "df_unique['tokenized_tweet'] = df_unique['tokenized_tweet'].apply(list)\n",
    "\n",
    "df_ordered['tokenized_tweet'] = df_ordered['tokenized_tweet'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5147, 7)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14940, 6)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>fully_cleaned_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>@timesofindia Stone pelting and inflow of fake currency started again. From cash less to less cash. Moto of demonetization has changed</td>\n",
       "      <td>stone pelting and inflow  fake currency started again from cash less  less cash moto   has changed</td>\n",
       "      <td>stone pelting and inflow fake currency started again from cash less less cash moto has changed</td>\n",
       "      <td>-1</td>\n",
       "      <td>[stone, pelting, inflow, fake, currency, started, cash, le, le, cash, moto, changed]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>RT @coolfunnytshirt: Delhiites least affected by #demonetization &amp;amp; long queues at ATMs. They are doing online transactions with free wi-fi…</td>\n",
       "      <td>delhiites least affected       long queues  atms they are doing online transactions with free wifi</td>\n",
       "      <td>delhiites least affected long queues atms they are doing online transactions with free wifi</td>\n",
       "      <td>-1</td>\n",
       "      <td>[delhiites, least, affected, long, queue, atm, online, transaction, free, wifi]</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3791</th>\n",
       "      <td>RT @centerofright: #DeMonetization - the new 500 notes are not yet coming out of majority of the recalibrated ATMs. Ppl who had small amoun…</td>\n",
       "      <td>centerofright     the new 500 notes are not yet coming out  majority  the recalibrated atms ppl who had small amoun</td>\n",
       "      <td>centerofright the new 500 notes are not yet coming out majority the recalibrated atms ppl who had small amoun</td>\n",
       "      <td>-1</td>\n",
       "      <td>[centerofright, new, note, yet, coming, majority, recalibrated, atm, ppl, small, amoun]</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>RT @centerofright: #DeMonetization - ppl who hv hoarded the cash are still to start depositing in bank accts - Guess they expect an extn or…</td>\n",
       "      <td>centerofright     ppl who  hoarded the cash are still  start depositing  bank accts  guess they expect  extn</td>\n",
       "      <td>centerofright ppl who hoarded the cash are still start depositing bank accts guess they expect extn</td>\n",
       "      <td>-1</td>\n",
       "      <td>[centerofright, ppl, hoarded, cash, still, start, depositing, bank, accts, guess, expect, extn]</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3784</th>\n",
       "      <td>RT @centerofright: #DeMonetization - Some thoughts - 2 weeks over after that 8.00 PM speech. Lines hv reduced at banks for exchange. ATMs h…</td>\n",
       "      <td>centerofright     some thoughts  2 weeks over after that 800  speech lines  reduced  banks for exchange atms</td>\n",
       "      <td>centerofright some thoughts 2 weeks over after that 800 speech lines reduced banks for exchange atms</td>\n",
       "      <td>-1</td>\n",
       "      <td>[centerofright, thought, week, speech, line, reduced, bank, exchange, atm]</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>India’s “parallel” economy under attack with #demonetization\\r\\nKnow more: https://t.co/2W8EJlnd93\\r\\n#currency #liquidity https://t.co/iaX4MMZV2R</td>\n",
       "      <td>india   parallel  economy under attack with   know more</td>\n",
       "      <td>india parallel economy under attack with know more</td>\n",
       "      <td>1</td>\n",
       "      <td>[india, parallel, economy, attack, know]</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4015</th>\n",
       "      <td>RT @mostlyeconomics: Did India get the idea for its recent demonetization by watching old episodes of M*A*S*H? https://t.co/hlbME0xyDR</td>\n",
       "      <td>did india get the idea for its recent   watching old episodes</td>\n",
       "      <td>did india get the idea for its recent watching old episodes</td>\n",
       "      <td>1</td>\n",
       "      <td>[india, get, idea, recent, watching, old, episode]</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4359</th>\n",
       "      <td>Retweeted DNA (@dna):\\r\\n\\r\\n#Demonetization: 82,500 ATMs re-calibrated to dispense new notes https://t.co/5RacGMqzpd https://t.co/l8m9CYfUOl</td>\n",
       "      <td>retweeted dna  dna      82500 atms recalibrated  dispense new notes</td>\n",
       "      <td>retweeted dna dna 82500 atms recalibrated dispense new notes</td>\n",
       "      <td>1</td>\n",
       "      <td>[retweeted, dna, dna, atm, recalibrated, dispense, new, note]</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>@dna If inquiry post Demonetization moves on fast track,many joining hands today, may not be eligible to contest in 2019.</td>\n",
       "      <td>inquiry post  moves  fast trackmany joining hands today may not  eligible  contest  2019</td>\n",
       "      <td>inquiry post moves fast trackmany joining hands today may not eligible contest 2019</td>\n",
       "      <td>1</td>\n",
       "      <td>[inquiry, post, move, fast, trackmany, joining, hand, today, may, eligible, contest]</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3494</th>\n",
       "      <td>RT @Smita_Dutta_: &lt;U+20B9&gt;40 lakh looted from J&amp;amp;K Bank branch of Sarthal in Kishtwar, &lt;U+20B9&gt;20 lakh is in new denominations.\\r\\n#DeMonetization</td>\n",
       "      <td>smita dutta   20 lakh   new denominations</td>\n",
       "      <td>smita dutta 20 lakh new denominations</td>\n",
       "      <td>1</td>\n",
       "      <td>[smita, dutta, lakh, new, denomination]</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5147 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                      tweet  \\\n",
       "1593                 @timesofindia Stone pelting and inflow of fake currency started again. From cash less to less cash. Moto of demonetization has changed   \n",
       "3804        RT @coolfunnytshirt: Delhiites least affected by #demonetization &amp; long queues at ATMs. They are doing online transactions with free wi-fi…   \n",
       "3791           RT @centerofright: #DeMonetization - the new 500 notes are not yet coming out of majority of the recalibrated ATMs. Ppl who had small amoun…   \n",
       "3790           RT @centerofright: #DeMonetization - ppl who hv hoarded the cash are still to start depositing in bank accts - Guess they expect an extn or…   \n",
       "3784           RT @centerofright: #DeMonetization - Some thoughts - 2 weeks over after that 8.00 PM speech. Lines hv reduced at banks for exchange. ATMs h…   \n",
       "...                                                                                                                                                     ...   \n",
       "2600     India’s “parallel” economy under attack with #demonetization\\r\\nKnow more: https://t.co/2W8EJlnd93\\r\\n#currency #liquidity https://t.co/iaX4MMZV2R   \n",
       "4015                 RT @mostlyeconomics: Did India get the idea for its recent demonetization by watching old episodes of M*A*S*H? https://t.co/hlbME0xyDR   \n",
       "4359          Retweeted DNA (@dna):\\r\\n\\r\\n#Demonetization: 82,500 ATMs re-calibrated to dispense new notes https://t.co/5RacGMqzpd https://t.co/l8m9CYfUOl   \n",
       "1207                              @dna If inquiry post Demonetization moves on fast track,many joining hands today, may not be eligible to contest in 2019.   \n",
       "3494  RT @Smita_Dutta_: <U+20B9>40 lakh looted from J&amp;K Bank branch of Sarthal in Kishtwar, <U+20B9>20 lakh is in new denominations.\\r\\n#DeMonetization   \n",
       "\n",
       "                                                                                                             cleaned_tweet  \\\n",
       "1593                    stone pelting and inflow  fake currency started again from cash less  less cash moto   has changed   \n",
       "3804                   delhiites least affected       long queues  atms they are doing online transactions with free wifi    \n",
       "3791  centerofright     the new 500 notes are not yet coming out  majority  the recalibrated atms ppl who had small amoun    \n",
       "3790         centerofright     ppl who  hoarded the cash are still  start depositing  bank accts  guess they expect  extn    \n",
       "3784         centerofright     some thoughts  2 weeks over after that 800  speech lines  reduced  banks for exchange atms    \n",
       "...                                                                                                                    ...   \n",
       "2600                                                              india   parallel  economy under attack with   know more    \n",
       "4015                                                        did india get the idea for its recent   watching old episodes    \n",
       "4359                                                  retweeted dna  dna      82500 atms recalibrated  dispense new notes    \n",
       "1207                              inquiry post  moves  fast trackmany joining hands today may not  eligible  contest  2019   \n",
       "3494                                                                            smita dutta   20 lakh   new denominations    \n",
       "\n",
       "                                                                                                fully_cleaned_tweet  \\\n",
       "1593                 stone pelting and inflow fake currency started again from cash less less cash moto has changed   \n",
       "3804                    delhiites least affected long queues atms they are doing online transactions with free wifi   \n",
       "3791  centerofright the new 500 notes are not yet coming out majority the recalibrated atms ppl who had small amoun   \n",
       "3790            centerofright ppl who hoarded the cash are still start depositing bank accts guess they expect extn   \n",
       "3784           centerofright some thoughts 2 weeks over after that 800 speech lines reduced banks for exchange atms   \n",
       "...                                                                                                             ...   \n",
       "2600                                                             india parallel economy under attack with know more   \n",
       "4015                                                    did india get the idea for its recent watching old episodes   \n",
       "4359                                                   retweeted dna dna 82500 atms recalibrated dispense new notes   \n",
       "1207                            inquiry post moves fast trackmany joining hands today may not eligible contest 2019   \n",
       "3494                                                                          smita dutta 20 lakh new denominations   \n",
       "\n",
       "      sentiment  \\\n",
       "1593         -1   \n",
       "3804         -1   \n",
       "3791         -1   \n",
       "3790         -1   \n",
       "3784         -1   \n",
       "...         ...   \n",
       "2600          1   \n",
       "4015          1   \n",
       "4359          1   \n",
       "1207          1   \n",
       "3494          1   \n",
       "\n",
       "                                                                                      tokenized_tweet  \\\n",
       "1593             [stone, pelting, inflow, fake, currency, started, cash, le, le, cash, moto, changed]   \n",
       "3804                  [delhiites, least, affected, long, queue, atm, online, transaction, free, wifi]   \n",
       "3791          [centerofright, new, note, yet, coming, majority, recalibrated, atm, ppl, small, amoun]   \n",
       "3790  [centerofright, ppl, hoarded, cash, still, start, depositing, bank, accts, guess, expect, extn]   \n",
       "3784                       [centerofright, thought, week, speech, line, reduced, bank, exchange, atm]   \n",
       "...                                                                                               ...   \n",
       "2600                                                         [india, parallel, economy, attack, know]   \n",
       "4015                                               [india, get, idea, recent, watching, old, episode]   \n",
       "4359                                    [retweeted, dna, dna, atm, recalibrated, dispense, new, note]   \n",
       "1207             [inquiry, post, move, fast, trackmany, joining, hand, today, may, eligible, contest]   \n",
       "3494                                                          [smita, dutta, lakh, new, denomination]   \n",
       "\n",
       "      cluster_label  frequency  \n",
       "1593              0          1  \n",
       "3804              0          6  \n",
       "3791              0         11  \n",
       "3790              0         11  \n",
       "3784              0         32  \n",
       "...             ...        ...  \n",
       "2600             79          1  \n",
       "4015             79          1  \n",
       "4359             79          1  \n",
       "1207             79          1  \n",
       "3494             79          1  \n",
       "\n",
       "[5147 rows x 7 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discard poor silhouette scores clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0 : 0.23554826527771908\n",
      "Cluster 1 : 0.1257531970116142\n",
      "Cluster 2 : 1.0\n",
      "Cluster 3 : 0.7215250090386147\n",
      "Cluster 4 : 0.09783461331028755\n",
      "Cluster 5 : 0.1692022731101029\n",
      "Cluster 6 : 0.7870268989803425\n",
      "Cluster 7 : 0.9832921078478237\n",
      "Cluster 8 : 0.9596102575893116\n",
      "Cluster 9 : 0.40281108954221695\n",
      "Cluster 10 : 0.2876436709140271\n",
      "Cluster 11 : 0.1989078563012777\n",
      "Cluster 12 : 0.036942706785760594\n",
      "Cluster 13 : 0.6587160644114174\n",
      "Cluster 14 : 0.5907986467799319\n",
      "Cluster 15 : 0.7905467610398246\n",
      "Cluster 16 : 0.8419991560438136\n",
      "Cluster 17 : 0.8327499042264771\n",
      "Cluster 18 : 0.8988295763880083\n",
      "Cluster 19 : 0.9836905159412809\n",
      "Cluster 20 : 0.8598063113023324\n",
      "Cluster 21 : 0.11647686987056778\n",
      "Cluster 22 : 0.625046386985449\n",
      "Cluster 23 : 0.18750869050053093\n",
      "Cluster 24 : 0.2788753168408837\n",
      "Cluster 25 : 0.08604961955898298\n",
      "Cluster 26 : 0.47921162183977134\n",
      "Cluster 27 : 0.0836672858789735\n",
      "Cluster 28 : 0.5185889225290122\n",
      "Cluster 29 : 0.9007990551701148\n",
      "Cluster 30 : 0.9493315795504998\n",
      "Cluster 31 : 0.5403175357739626\n",
      "Cluster 32 : 0.3309759160021678\n",
      "Cluster 33 : 0.5216154979001177\n",
      "Cluster 34 : 0.605381933935531\n",
      "Cluster 35 : 0.15059619094148946\n",
      "Cluster 36 : 0.7004207741188012\n",
      "Cluster 37 : 0.9358145333651063\n",
      "Cluster 38 : 0.9625958136798853\n",
      "Cluster 39 : 0.8098024986648305\n",
      "Cluster 40 : 0.4674099579889659\n",
      "Cluster 41 : 0.08408263912108006\n",
      "Cluster 42 : 0.9936922706126037\n",
      "Cluster 43 : 0.0992096836622456\n",
      "Cluster 44 : 0.41150504323184783\n",
      "Cluster 45 : 0.9106211806089983\n",
      "Cluster 46 : 1.0\n",
      "Cluster 47 : 0.5792245284517552\n",
      "Cluster 48 : 0.20443490727864935\n",
      "Cluster 49 : 0.8825037255792995\n",
      "Cluster 50 : 0.763944472755204\n",
      "Cluster 51 : 0.9321873926682133\n",
      "Cluster 52 : 0.6833919399271724\n",
      "Cluster 53 : 0.10950331915820437\n",
      "Cluster 54 : 0.9776565009530391\n",
      "Cluster 55 : 0.9653818916790498\n",
      "Cluster 56 : 0.7486897710041618\n",
      "Cluster 57 : 0.9653286250536756\n",
      "Cluster 58 : 0.4965046761470038\n",
      "Cluster 59 : 0.5450439949899787\n",
      "Cluster 60 : 0.9943367235600661\n",
      "Cluster 61 : 0.9948327160123855\n",
      "Cluster 62 : 0.5730417620243773\n",
      "Cluster 63 : 0.07827242442984081\n",
      "Cluster 64 : 0.6945909185611071\n",
      "Cluster 65 : 0.8530328863937137\n",
      "Cluster 66 : 1.0\n",
      "Cluster 67 : 0.7660666512260061\n",
      "Cluster 68 : 1.0\n",
      "Cluster 69 : 0.26751764284243956\n"
     ]
    }
   ],
   "source": [
    "sample_slhouette_score = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "avg_cluster_sil_score = []\n",
    "poor_cluster_indices = []\n",
    "\n",
    "for i in range(70):  # No. of clusters used\n",
    "    ith_cluster_sil_score = sample_slhouette_score[cluster_labels == i]\n",
    "    avgscore = (np.mean(ith_cluster_sil_score))\n",
    "    avg_cluster_sil_score = np.append(avg_cluster_sil_score, avgscore)\n",
    "    print(\"Cluster\",i,\":\",avgscore)\n",
    "    \n",
    "    if avgscore < 0.30:\n",
    "        poor_cluster_indices = np.append(poor_cluster_indices, i)\n",
    "        \n",
    "    ith_cluster_sil_score.sort()\n",
    "    size_cluster_i = ith_cluster_sil_score.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  4.,  5., 10., 11., 12., 21., 23., 24., 25., 27., 35.,\n",
       "       41., 43., 48., 53., 63., 69.])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poor_cluster_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_avgscore_final = []\n",
    "\n",
    "cluster_name = np.unique(df_ordered['cluster_label'])\n",
    "\n",
    "if (len(poor_cluster_indices) != 0):\n",
    "    final_clusters = 70 - len(poor_cluster_indices)\n",
    "    for i in poor_cluster_indices:\n",
    "        df_unique = df_unique[df_unique['cluster_label'] != i]\n",
    "    for j in cluster_name:\n",
    "        if j not in poor_cluster_indices:\n",
    "            sil_avgscore_final = np.append(sil_avgscore_final,avg_cluster_sil_score)\n",
    "            \n",
    "    cluster_name = np.unique(df_unique['cluster_label'])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique['cluster_label']  = abs(df_unique['cluster_label'])\n",
    "df_unique = df_unique.sort_values(by = ['cluster_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2  3  6  7  8  9 13 14 15 16 17 18 19 20 22 26 28 29 30 31 32 33 34 36\n",
      " 37 38 39 40 42 44 45 46 47 49 50 51 52 54 55 56 57 58 59 60 61 62 64 65\n",
      " 66 67 68 70 71 72 73 74 75 76 77 78 79]\n"
     ]
    }
   ],
   "source": [
    "# Store all the tweets with clusters\n",
    "\n",
    "final_clusters = np.unique(df_unique['cluster_label'])\n",
    "\n",
    "print(final_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in final_clusters:\n",
    "    with open('./tweets_clusters_' + str(i) + '.txt' , 'w') as out:\n",
    "        y = ''\n",
    "        for x in df_unique['fully_cleaned_tweet'][df_unique.cluster_label == i]:\n",
    "            y = y + x + '. '\n",
    "        out.write(y)\n",
    "        out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\pearl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           extracted_phrases  cluster_num\n",
      "0                modibharosa          3.0\n",
      "1        modibharosa putting          3.0\n",
      "2               narendramodi          3.0\n",
      "3                   decision          3.0\n",
      "4     opposition parties are          3.0\n",
      "...                      ...          ...\n",
      "2250           millions wait         79.0\n",
      "2251           dna tweet dna         79.0\n",
      "2252     design noblackmoney         79.0\n",
      "2253    bhimaadhaar platform         79.0\n",
      "2254                   dutta         79.0\n",
      "\n",
      "[2255 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phrases = pd.DataFrame({'extracted_phrases': [], 'cluster_num': []})\n",
    "\n",
    "A = '(CD|JJ)/\\w+s'                      # CD and JJ\n",
    "B = '(NN|NNS|NNP|NNPS)/\\w+\\s'           # Nouns\n",
    "C = '(VB|VBD|VBG|VBN|VBP|VBZ)/\\w+\\s'    # Verbs\n",
    "D = 'FW\\w+\\s'                           # Foreign Words\n",
    "\n",
    "\n",
    "patterns = ['('+A+B+')+', '('+D+B+')+', '('+D+')+', '('+B+')+', '('+D+A+B+')+', '('+B+C+')+', '('+D+B+C+')+', '('+D+B+C+')+',\n",
    "            '('+B+A+B+')+', '('+B+B+C+')+']\n",
    "\n",
    "\n",
    "for i in cluster_name:\n",
    "    file = open('./tweets_clusters_'+str(i)+'.txt','r')  # open file\n",
    "    lines = file.read()  # read all lines\n",
    "    sentences = nltk.sent_tokenize(lines)  # Tokenizing sentences\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        f = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "        tag_seq = []\n",
    "        for word, pos in f:\n",
    "            tag_seq.append(pos+'/'+word)\n",
    "        X = \" \".join(tag_seq)\n",
    "        \n",
    "        phrase = []\n",
    "        for j in range(len(patterns)):\n",
    "            if re.search(patterns[j],X):\n",
    "                phrase.append(' '.join([word.split('/')[1] for word in re.search(patterns[j], X).group(0).split()]))\n",
    "                \n",
    "        k = pd.DataFrame({'extracted_phrases': np.unique(phrase),'cluster_num':int(i)})\n",
    "        \n",
    "        phrases = pd.concat([phrases,k],ignore_index = True)\n",
    "        \n",
    "        \n",
    "print(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_final = pd.DataFrame({'extracted_phrases':[],'cluster_num':[]})\n",
    "\n",
    "for i in cluster_name:\n",
    "    phrases_for_each_cluster = []\n",
    "    cluster_phrases = phrases['extracted_phrases'][phrases.cluster_num == i]\n",
    "    cluster_phrases = np.unique(np.array(cluster_phrases))\n",
    "    for j in range(len(cluster_phrases)):\n",
    "        phrase = cluster_phrases[j]\n",
    "        updated_cluster_phrases = np.delete((cluster_phrases),j)\n",
    "        if any(phrase in phr for phr in updated_cluster_phrases):\n",
    "            'y'\n",
    "        else:\n",
    "            # Considering length of the phrase more than 1\n",
    "            if (len(phrase.split(' '))) > 1:\n",
    "                phrases_for_each_cluster.append(phrase)\n",
    "    k = pd.DataFrame({'extracted_phrases':phrases_for_each_cluster,'cluster_num':int(i)})\n",
    "    phrases_final = pd.concat([phrases_final,k], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_final['term_freq'] = len(phrases_final)*[0]\n",
    "\n",
    "for i in cluster_name:\n",
    "    for phrase in phrases_final['extracted_phrases'][phrases_final.cluster_num ==i]:\n",
    "        tweets = df_unique['fully_cleaned_tweet'][df_unique.cluster_label ==i]\n",
    "        for tweet in tweets:\n",
    "            if phrase in tweet:\n",
    "                phrases_final['term_freq'][(phrases_final.extracted_phrases == phrase) & (phrases_final.cluster_num ==i)] = phrases_final['term_freq'][(phrases_final.extracted_phrases == phrase) & (phrases_final.cluster_num ==i)] + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating document frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each phrase in each cluster calucalting document frequency\n",
    "\n",
    "phrases_final['doc_freq'] = len(phrases_final)*[0]\n",
    "\n",
    "for phrase in phrases_final['extracted_phrases']:\n",
    "    for i in cluster_name:\n",
    "        all_tweets = ''\n",
    "        for tweet in df_unique['fully_cleaned_tweet'][df_unique.cluster_label == i]:\n",
    "            all_tweets = all_tweets + tweet + '. '\n",
    "        if phrase in all_tweets:\n",
    "            phrases_final['doc_freq'][(phrases_final.extracted_phrases == phrase) & (phrases_final.cluster_num == i)] = phrases_final['doc_freq'][(phrases_final.extracted_phrases == phrase) & (phrases_final.cluster_num ==i)] +1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_phrases</th>\n",
       "      <th>cluster_num</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>doc_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abhijit banerjee</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amilliff banerjee jpal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bjp4india manojtiwarimp chk</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elections were</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fruit vendor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>utility google does</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>videos isnt</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>whatsapp users fall</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>wonder govt received</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>world appreciating</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               extracted_phrases  cluster_num  term_freq  doc_freq\n",
       "0               abhijit banerjee          3.0          1         1\n",
       "1         amilliff banerjee jpal          3.0          1         1\n",
       "2    bjp4india manojtiwarimp chk          3.0          1         1\n",
       "3                 elections were          3.0          1         1\n",
       "4                   fruit vendor          3.0          2         1\n",
       "..                           ...          ...        ...       ...\n",
       "614          utility google does         79.0          1         1\n",
       "615                  videos isnt         79.0          1         1\n",
       "616          whatsapp users fall         79.0          1         1\n",
       "617         wonder govt received         79.0          1         1\n",
       "618           world appreciating         79.0          1         1\n",
       "\n",
       "[619 rows x 4 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    590\n",
       "2     26\n",
       "3      3\n",
       "Name: doc_freq, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_final.doc_freq.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "phrases_final['doc_freq'] = phrases_final['doc_freq'].apply(lambda x : math.log10(best_clusters/(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each phrase in each cluster, calculate tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases_final['tf-idf'] = phrases_final['term_freq'] * phrases_final['doc_freq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_phrases</th>\n",
       "      <th>cluster_num</th>\n",
       "      <th>term_freq</th>\n",
       "      <th>doc_freq</th>\n",
       "      <th>tf-idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abhijit banerjee</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>1.90309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amilliff banerjee jpal</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>1.90309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bjp4india manojtiwarimp chk</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>1.90309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>elections were</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>1.90309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fruit vendor</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>3.80618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>utility google does</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>1.90309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>videos isnt</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>1.90309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>whatsapp users fall</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>1.90309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>wonder govt received</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>1.90309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>world appreciating</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.90309</td>\n",
       "      <td>1.90309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               extracted_phrases  cluster_num  term_freq  doc_freq   tf-idf\n",
       "0               abhijit banerjee          3.0          1   1.90309  1.90309\n",
       "1         amilliff banerjee jpal          3.0          1   1.90309  1.90309\n",
       "2    bjp4india manojtiwarimp chk          3.0          1   1.90309  1.90309\n",
       "3                 elections were          3.0          1   1.90309  1.90309\n",
       "4                   fruit vendor          3.0          2   1.90309  3.80618\n",
       "..                           ...          ...        ...       ...      ...\n",
       "614          utility google does         79.0          1   1.90309  1.90309\n",
       "615                  videos isnt         79.0          1   1.90309  1.90309\n",
       "616          whatsapp users fall         79.0          1   1.90309  1.90309\n",
       "617         wonder govt received         79.0          1   1.90309  1.90309\n",
       "618           world appreciating         79.0          1   1.90309  1.90309\n",
       "\n",
       "[619 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrases_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phrases_final['diff_tf-idf'] = len(phrases_final)*[0]\n",
    "\n",
    "narrative = pd.DataFrame({'cl_num':[], 'abstraction':[]})\n",
    "\n",
    "for i in cluster_name:\n",
    "    phrases_final = phrases_final.sort_values(['cluster_num','tf-idf'], ascending = [1,0])\n",
    "    \n",
    "    #Break this distribution at a point where the difference between any consecutive phrases is maximum\n",
    "    #difference between consecutive values of tf-idf \n",
    "    \n",
    "    phrases_final['diff_tf-idf'][phrases_final.cluster_num == i] = abs(phrases_final['tf-idf'][phrases_final.cluster_num == i] - phrases_final['tf-idf'][phrases_final.cluster_num == i].shift(1))\n",
    "    \n",
    "    # Replace the last value from nan to 0\n",
    "    \n",
    "    phrases_final = phrases_final.fillna(0)\n",
    "    \n",
    "    phrases_final = phrases_final.reset_index(drop = True)\n",
    "    if len(phrases_final[phrases_final.cluster_num == i]) != 0:\n",
    "        \n",
    "        \n",
    "        # Index corresponding to the highest diff\n",
    "        ind = (phrases_final['diff_tf-idf'][phrases_final.cluster_num == i]).idxmax()\n",
    "        \n",
    "        abstract = phrases_final['extracted_phrases'].iloc[ind]\n",
    "        \n",
    "        \n",
    "        k = pd.DataFrame({'cl_num': int(i),'abstraction':[abstract]})\n",
    "        \n",
    "        narrative = pd.concat([narrative,k],ignore_index = True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cl_num</th>\n",
       "      <th>abstraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>abhijit banerjee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>feel vindicated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>evan spiegel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>oscar goes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>amitabh bachchan doesnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>13.0</td>\n",
       "      <td>bitcoin booming</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>results bypolls has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15.0</td>\n",
       "      <td>bypolls result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.0</td>\n",
       "      <td>currency operater are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>17.0</td>\n",
       "      <td>people get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>18.0</td>\n",
       "      <td>vijayshekhars paytm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19.0</td>\n",
       "      <td>ktrtrs minit telangana telangana govts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20.0</td>\n",
       "      <td>india running</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>22.0</td>\n",
       "      <td>money youtube were</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>26.0</td>\n",
       "      <td>ads appearing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>28.0</td>\n",
       "      <td>bank ques praising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>29.0</td>\n",
       "      <td>myvotetoday cjithakur says</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30.0</td>\n",
       "      <td>india watch briefing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>31.0</td>\n",
       "      <td>modi app</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32.0</td>\n",
       "      <td>bank effects have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>33.0</td>\n",
       "      <td>feel panicked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34.0</td>\n",
       "      <td>lingers iip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>36.0</td>\n",
       "      <td>msisodia detaiend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>37.0</td>\n",
       "      <td>pet dog ashoktanwar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>38.0</td>\n",
       "      <td>pappu opposition has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>39.0</td>\n",
       "      <td>india exports grow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>40.0</td>\n",
       "      <td>partners doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>42.0</td>\n",
       "      <td>impact going</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>44.0</td>\n",
       "      <td>stage protest jantar mantar tomorrow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>45.0</td>\n",
       "      <td>anmolsi86 vishalj99213001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>46.0</td>\n",
       "      <td>mens tobaccogutkha was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>47.0</td>\n",
       "      <td>ashu3page man shaved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>49.0</td>\n",
       "      <td>chidambaram congress doormats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>50.0</td>\n",
       "      <td>dipendradipzo effect said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>51.0</td>\n",
       "      <td>contemplation have</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>52.0</td>\n",
       "      <td>effect child</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>54.0</td>\n",
       "      <td>kanimozhi india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>55.0</td>\n",
       "      <td>punitspeaks survey result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>56.0</td>\n",
       "      <td>mps demonstrating solidarity demanding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>57.0</td>\n",
       "      <td>drshobha taught</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>58.0</td>\n",
       "      <td>cant believe narendramodi allowed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>59.0</td>\n",
       "      <td>arunjaitley people are</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>60.0</td>\n",
       "      <td>milkman asked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>61.0</td>\n",
       "      <td>hour think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>62.0</td>\n",
       "      <td>duplicate argument reminds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64.0</td>\n",
       "      <td>evan spiegel india</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>65.0</td>\n",
       "      <td>jay ambadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>67.0</td>\n",
       "      <td>modi wants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>70.0</td>\n",
       "      <td>time has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>71.0</td>\n",
       "      <td>bank notes discarded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>72.0</td>\n",
       "      <td>advantages article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>73.0</td>\n",
       "      <td>download paytm get</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>74.0</td>\n",
       "      <td>partners doing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>75.0</td>\n",
       "      <td>audience tweet using</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>76.0</td>\n",
       "      <td>app shared</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>77.0</td>\n",
       "      <td>pgurus1 cpim opposes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>78.0</td>\n",
       "      <td>debate parlmnt stalled</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>79.0</td>\n",
       "      <td>atms recalibrated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    cl_num                             abstraction\n",
       "0      3.0                        abhijit banerjee\n",
       "1      6.0                         feel vindicated\n",
       "2      7.0                            evan spiegel\n",
       "3      8.0                              oscar goes\n",
       "4      9.0                 amitabh bachchan doesnt\n",
       "5     13.0                         bitcoin booming\n",
       "6     14.0                     results bypolls has\n",
       "7     15.0                          bypolls result\n",
       "8     16.0                   currency operater are\n",
       "9     17.0                              people get\n",
       "10    18.0                     vijayshekhars paytm\n",
       "11    19.0  ktrtrs minit telangana telangana govts\n",
       "12    20.0                           india running\n",
       "13    22.0                      money youtube were\n",
       "14    26.0                           ads appearing\n",
       "15    28.0                      bank ques praising\n",
       "16    29.0              myvotetoday cjithakur says\n",
       "17    30.0                    india watch briefing\n",
       "18    31.0                                modi app\n",
       "19    32.0                       bank effects have\n",
       "20    33.0                           feel panicked\n",
       "21    34.0                             lingers iip\n",
       "22    36.0                       msisodia detaiend\n",
       "23    37.0                     pet dog ashoktanwar\n",
       "24    38.0                    pappu opposition has\n",
       "25    39.0                      india exports grow\n",
       "26    40.0                          partners doing\n",
       "27    42.0                            impact going\n",
       "28    44.0    stage protest jantar mantar tomorrow\n",
       "29    45.0               anmolsi86 vishalj99213001\n",
       "30    46.0                  mens tobaccogutkha was\n",
       "31    47.0                    ashu3page man shaved\n",
       "32    49.0           chidambaram congress doormats\n",
       "33    50.0               dipendradipzo effect said\n",
       "34    51.0                      contemplation have\n",
       "35    52.0                            effect child\n",
       "36    54.0                         kanimozhi india\n",
       "37    55.0               punitspeaks survey result\n",
       "38    56.0  mps demonstrating solidarity demanding\n",
       "39    57.0                         drshobha taught\n",
       "40    58.0       cant believe narendramodi allowed\n",
       "41    59.0                  arunjaitley people are\n",
       "42    60.0                           milkman asked\n",
       "43    61.0                              hour think\n",
       "44    62.0              duplicate argument reminds\n",
       "45    64.0                      evan spiegel india\n",
       "46    65.0                              jay ambadi\n",
       "47    67.0                              modi wants\n",
       "48    70.0                                time has\n",
       "49    71.0                    bank notes discarded\n",
       "50    72.0                      advantages article\n",
       "51    73.0                      download paytm get\n",
       "52    74.0                          partners doing\n",
       "53    75.0                    audience tweet using\n",
       "54    76.0                              app shared\n",
       "55    77.0                    pgurus1 cpim opposes\n",
       "56    78.0                  debate parlmnt stalled\n",
       "57    79.0                       atms recalibrated"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique['polarity'] = np.NaN\n",
    "df_unique['polarity'][df_unique.sentiment == 1] = '1'\n",
    "df_unique['polarity'][df_unique.sentiment == -1] = '2'\n",
    "df_unique['polarity'][df_unique.sentiment == 0] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Find the highest occuring sentiment corresponding to each tweet\n",
    "\n",
    "\n",
    "def find_mode(a):\n",
    "    b = Counter(a).most_common(3)\n",
    "    mode = []; c_max = 0\n",
    "    for a,c in b:\n",
    "        if c > c_max:\n",
    "            c_max = c\n",
    "        if c_max == c:\n",
    "            mode.append(a)\n",
    "    #print(mode)\n",
    "    mode.sort()\n",
    "    print(mode)\n",
    "    \n",
    "    if len(mode) == 1:\n",
    "        return mode[0]\n",
    "    \n",
    "    elif (len(mode)==2) & (mode[1] == '3'):\n",
    "        return mode[0]\n",
    "    \n",
    "    else:\n",
    "        return 3\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2']\n",
      "['1']\n",
      "['1']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['1']\n",
      "['2']\n",
      "['2']\n",
      "['1']\n",
      "['1']\n",
      "['2']\n",
      "['1']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['2']\n",
      "['1']\n",
      "['2']\n",
      "['1']\n",
      "['1']\n",
      "['2']\n",
      "['2']\n",
      "['1']\n",
      "['1']\n",
      "['2']\n",
      "['1']\n",
      "['2']\n",
      "['2']\n",
      "['1']\n",
      "['1']\n",
      "['2']\n",
      "['2']\n",
      "['1']\n",
      "['2']\n",
      "['1']\n",
      "['1']\n",
      "['2']\n",
      "['1']\n",
      "['1']\n",
      "['1']\n",
      "['2']\n",
      "['2']\n",
      "['1']\n",
      "['1']\n",
      "['2']\n",
      "['1']\n",
      "['2']\n",
      "['2']\n",
      "['1']\n",
      "['1']\n",
      "['2']\n",
      "['1']\n",
      "['1']\n"
     ]
    }
   ],
   "source": [
    "narrative['expression'] = -1\n",
    "\n",
    "df_unique = df_unique.reset_index(drop = True)\n",
    "\n",
    "for i in cluster_name:\n",
    "    tweets  = df_unique['fully_cleaned_tweet'][df_unique.cluster_label == i]\n",
    "    polar = df_unique['polarity'][df_unique.cluster_label == i]\n",
    "    abstracts = narrative['abstraction'][narrative['cl_num'] ==i]\n",
    "    \n",
    "    for abst in abstracts:\n",
    "        sent = []\n",
    "        for tweet, polarity in zip(tweets,polar):\n",
    "            if abst in tweet:\n",
    "                sent = np.append(sent,polarity)\n",
    "                \n",
    "        if len(sent) != 0:\n",
    "            senti = find_mode(sent)\n",
    "            \n",
    "            if senti == '2':\n",
    "                sent_value = 'Negative'\n",
    "            elif senti == '1':\n",
    "                sent_value = 'Positive'\n",
    "            else:\n",
    "                sent_value = 'Neutral'\n",
    "            \n",
    "            narrative['expression'][(narrative.abstraction == abst) & (narrative.cl_num == i)] = sent_value\n",
    "        \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the narratives into excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelWriter\n",
    "\n",
    "writer = ExcelWriter('narrative.xlsx')\n",
    "\n",
    "for i in cluster_name:\n",
    "    df1 = pd.DataFrame(df_unique[['tweet','frequency']][df_unique.cluster_label == i])\n",
    "    df1.sort_values(['frequency'], ascending = [0])\n",
    "    df1 = pd.DataFrame({'tweet': df_unique['tweet'][df_unique.cluster_label == i], \n",
    "                        'frequency': df_unique['frequency'][df_unique.cluster_label == i]}) \n",
    "    df1 = df1.sort_values(['frequency'], ascending = [0]) \n",
    "\n",
    "    df2 = pd.DataFrame({ 'abstraction': narrative['abstraction'][narrative.cl_num == i],\n",
    "                        'expression': narrative['expression'][narrative.cl_num == i]})\n",
    "    df3 = pd.DataFrame({'abstraction': (len(df1)-len(df2))*['-'], 'expression': (len(df1)-len(df2))*['-']})\n",
    "    df2 = df2.append(df3)\n",
    "\n",
    "    df1 = df1.reset_index(drop=True)\n",
    "    df2 = df2.reset_index(drop=True)\n",
    "    df1['abstraction'] = df2['abstraction']\n",
    "    df1['expression'] = df2['expression']\n",
    "\n",
    "    df1.to_excel(writer,'narrative_cluster'+str(i))\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries  \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re, random, os\n",
    "import string, pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# spacy for basic preprocessing, optional, can use nltk as well (lemmatisation etc.)\n",
    "import spacy\n",
    "\n",
    "# gensim for LDA \n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_df = df_unique[['tokenized_tweet','cluster_label','polarity']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet', 'cleaned_tweet', 'fully_cleaned_tweet', 'sentiment',\n",
       "       'tokenized_tweet', 'cluster_label', 'frequency', 'polarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_tweet</th>\n",
       "      <th>cluster_label</th>\n",
       "      <th>polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tokenized_tweet  cluster_label polarity\n",
       "0              []              2        2\n",
       "1              []              2        2\n",
       "2              []              2        2\n",
       "3              []              2        2\n",
       "4              []              2        2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = np.unique(topic_df['cluster_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  3,  6,  7,  8,  9, 13, 14, 15, 16, 17, 18, 19, 20, 22, 26, 28,\n",
       "       29, 30, 31, 32, 33, 34, 36, 37, 38, 39, 40, 42, 44, 45, 46, 47, 49,\n",
       "       50, 51, 52, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68,\n",
       "       70, 71, 72, 73, 74, 75, 76, 77, 78, 79], dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_tweets = [ [] for _ in range(len(cluster_labels))]\n",
    "    \n",
    "\n",
    "for i,j in zip(range(len(tokenized_tweets)),cluster_labels):\n",
    "    for tokens in topic_df['tokenized_tweet'][topic_df['cluster_label'] == j]:\n",
    "        for token in tokens:\n",
    "            tokenized_tweets[i].append(token)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nktpnd',\n",
       " 'one',\n",
       " 'better',\n",
       " 'reasoned',\n",
       " 'article',\n",
       " 'india',\n",
       " 'poor',\n",
       " 'really',\n",
       " 'suffering',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendramodi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'sanjeetbisht',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'actually',\n",
       " 'poo',\n",
       " 'dear',\n",
       " 'evan',\n",
       " 'spiegel',\n",
       " 'snapchat',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'actua',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'prime',\n",
       " 'minister',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'actua',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendramodi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'modi',\n",
       " 'like',\n",
       " 'surveymrs',\n",
       " 'clinton',\n",
       " 'also',\n",
       " 'winning',\n",
       " 'election',\n",
       " 'survey',\n",
       " 'dear',\n",
       " 'evan',\n",
       " 'spiegel',\n",
       " 'snapchat',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'deepjm',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'actually',\n",
       " 'rich',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'actually',\n",
       " 'swatisaxena',\n",
       " 'seemed',\n",
       " 'first',\n",
       " 'masterstroke',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'look',\n",
       " 'like',\n",
       " 'grave',\n",
       " 'dear',\n",
       " 'snapchat',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendramodi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'dear',\n",
       " 'evan',\n",
       " 'spiegel',\n",
       " 'snapchat',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'respected',\n",
       " 'narendramodi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'actual',\n",
       " 'aaanupriyaaa',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'actually',\n",
       " 'poo',\n",
       " 'dear',\n",
       " 'evan',\n",
       " 'spiegel',\n",
       " 'snapchat',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'dear',\n",
       " 'evanspiegel',\n",
       " 'india',\n",
       " 'rich',\n",
       " 'narendra',\n",
       " 'modi',\n",
       " 'implement',\n",
       " 'find',\n",
       " 'actually',\n",
       " 'rich',\n",
       " 'snapchatceo']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_tweets[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lemmatization_texts(texts, allowed_postags = ['NOUN','ADJ','VERB','ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(' '.join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "        \n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable = ['parser', 'ner'])\n",
    "\n",
    "data_lemmatized = lemmatization_texts(tokenized_tweets, allowed_postags = ['NOUN','ADJ','VERB','ADV'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['better', 'reason', 'article', 'really', 'suffer', 'dear', 'sanjeetbisht', 'modi', 'implement', 'find', 'actually', 'poo', 'dear', 'modi', 'implement', 'find', 'dear', 'modi', 'implement', 'implement', 'find', 'dear', 'modi', 'implement', 'implement', 'find', 'modi', 'also', 'win', 'election', 'survey', 'spiegel', 'modi', 'implement', 'find', 'dear', 'modi', 'implement', 'find', 'deepjm', 'dear', 'modi', 'implement', 'find', 'actually', 'rich', 'dear', 'modi', 'implement', 'find', 'actually', 'seem', 'modi', 'look', 'grave', 'dear', 'implement', 'find', 'dear', 'modi', 'implement', 'find', 'respect', 'implement', 'find', 'dear', 'modi', 'implement', 'find', 'dear', 'modi', 'implement', 'find', 'actual', 'modi', 'implement', 'find', 'actually', 'poo', 'dear', 'modi', 'implement', 'find', 'dear', 'modi', 'implement', 'find', 'actually', 'rich', 'snapchatceo']\n"
     ]
    }
   ],
   "source": [
    "print(data_lemmatized[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 2), (6, 3), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 3), (13, 1), (14, 2), (15, 2), (16, 1), (17, 1), (18, 2), (19, 2), (20, 1), (21, 1), (22, 1), (23, 1), (24, 2), (25, 1), (26, 3), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 3), (34, 4), (35, 5), (36, 1), (37, 1), (38, 3), (39, 2), (40, 7), (41, 2), (42, 2), (43, 7), (44, 1), (45, 2), (46, 1), (47, 1), (48, 2), (49, 18), (50, 1), (51, 1), (52, 2), (53, 1), (54, 3), (55, 1), (56, 1)], [(16, 1), (19, 1), (25, 1), (29, 3), (31, 11), (32, 3), (33, 9), (34, 1), (36, 1), (38, 2), (39, 10), (46, 2), (49, 13), (50, 5), (51, 1), (57, 4), (58, 1), (59, 7), (60, 1), (61, 2), (62, 1), (63, 1), (64, 1), (65, 1), (66, 2), (67, 1), (68, 1), (69, 1), (70, 1), (71, 2), (72, 4), (73, 1), (74, 1), (75, 1), (76, 3), (77, 2), (78, 11), (79, 4), (80, 1), (81, 1), (82, 2), (83, 2), (84, 1), (85, 2), (86, 1), (87, 1), (88, 1), (89, 1), (90, 1), (91, 1), (92, 1), (93, 1), (94, 5), (95, 4), (96, 1), (97, 1), (98, 1), (99, 2), (100, 1), (101, 1), (102, 2)], [(16, 1), (79, 18), (83, 16), (103, 1), (104, 5), (105, 1), (106, 1), (107, 1), (108, 13), (109, 1), (110, 16), (111, 1), (112, 1), (113, 2), (114, 1), (115, 1), (116, 1), (117, 2), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1)], [(125, 4), (126, 4), (127, 4), (128, 4), (129, 7), (130, 4), (131, 4)], [(11, 1), (26, 1), (34, 1), (39, 3), (65, 2), (70, 1), (93, 1), (131, 1), (132, 1), (133, 1), (134, 1), (135, 1), (136, 3), (137, 2), (138, 1), (139, 1), (140, 1), (141, 4), (142, 2), (143, 1), (144, 1), (145, 1), (146, 2), (147, 1), (148, 1), (149, 1), (150, 2), (151, 1), (152, 1), (153, 4), (154, 2), (155, 1), (156, 1), (157, 1), (158, 1), (159, 1), (160, 2), (161, 1), (162, 1), (163, 2), (164, 1), (165, 1), (166, 1), (167, 3), (168, 2), (169, 1), (170, 1), (171, 1), (172, 1), (173, 1), (174, 1), (175, 2), (176, 1), (177, 1), (178, 1), (179, 1), (180, 1), (181, 2), (182, 2), (183, 2), (184, 1), (185, 1), (186, 1), (187, 1), (188, 2), (189, 1)], [(8, 2), (31, 2), (81, 2), (83, 1), (98, 1), (125, 6), (146, 3), (190, 3), (191, 3), (192, 1), (193, 4), (194, 1), (195, 4), (196, 1), (197, 2), (198, 8), (199, 2), (200, 1), (201, 1), (202, 2), (203, 4), (204, 2), (205, 3), (206, 1)], [(16, 1), (50, 1), (83, 1), (94, 2), (104, 2), (105, 1), (123, 3), (125, 2), (187, 4), (207, 2), (208, 1), (209, 2), (210, 1), (211, 1), (212, 2), (213, 6), (214, 3), (215, 1), (216, 1), (217, 1), (218, 2), (219, 3), (220, 1), (221, 2), (222, 3), (223, 2), (224, 6), (225, 1), (226, 1), (227, 4), (228, 2)], [(42, 2), (83, 2), (123, 1), (183, 1), (213, 2), (222, 4), (223, 2), (224, 3), (228, 2), (229, 2), (230, 2), (231, 1), (232, 1), (233, 1), (234, 1), (235, 1), (236, 2), (237, 2), (238, 2), (239, 2)], [(2, 1), (37, 2), (206, 1), (217, 1), (228, 1), (240, 1), (241, 3), (242, 2), (243, 1), (244, 1), (245, 1), (246, 3), (247, 2), (248, 1), (249, 1), (250, 3), (251, 1), (252, 2), (253, 1), (254, 4), (255, 1)], [(39, 1), (153, 1), (160, 1), (256, 1), (257, 2), (258, 2), (259, 1), (260, 2)], [(72, 5), (81, 2), (153, 1), (233, 2), (261, 2), (262, 1), (263, 2), (264, 2), (265, 1), (266, 10), (267, 5), (268, 1), (269, 2), (270, 2), (271, 3), (272, 7), (273, 3), (274, 1), (275, 6), (276, 5), (277, 1), (278, 1), (279, 9), (280, 2), (281, 2), (282, 2), (283, 1), (284, 1), (285, 13), (286, 2), (287, 9), (288, 2), (289, 5), (290, 1), (291, 1), (292, 1), (293, 2), (294, 2), (295, 3), (296, 3)], [(133, 5), (146, 3), (297, 5), (298, 5), (299, 5), (300, 5), (301, 2), (302, 5), (303, 7)], [(56, 1), (79, 2), (83, 4), (126, 2), (160, 2), (252, 2), (304, 2), (305, 15), (306, 1), (307, 2), (308, 9), (309, 2), (310, 1), (311, 2), (312, 12), (313, 1), (314, 6), (315, 2), (316, 1), (317, 12), (318, 2), (319, 1), (320, 2), (321, 2), (322, 2), (323, 1), (324, 2)], [(2, 2), (8, 2), (39, 9), (53, 12), (95, 1), (115, 1), (124, 1), (129, 1), (135, 1), (148, 1), (153, 2), (154, 2), (168, 5), (211, 1), (236, 1), (276, 2), (296, 10), (325, 2), (326, 1), (327, 1), (328, 1), (329, 1), (330, 1), (331, 2), (332, 1), (333, 1), (334, 1), (335, 1), (336, 1), (337, 1), (338, 2), (339, 1), (340, 1), (341, 67), (342, 1), (343, 4), (344, 4), (345, 2), (346, 1), (347, 4), (348, 1), (349, 1), (350, 2), (351, 2), (352, 4), (353, 2), (354, 1), (355, 2), (356, 2), (357, 4)], [(53, 9), (71, 1), (296, 7), (358, 7), (359, 2), (360, 2), (361, 1), (362, 2), (363, 2), (364, 2), (365, 2), (366, 2), (367, 2), (368, 2)], [(69, 1), (106, 1), (130, 1), (159, 58), (164, 1), (195, 2), (260, 1), (355, 1), (366, 59), (369, 1), (370, 2), (371, 1), (372, 1), (373, 57), (374, 27), (375, 13), (376, 1), (377, 27), (378, 1), (379, 1), (380, 1), (381, 1), (382, 1), (383, 1), (384, 1), (385, 57), (386, 2), (387, 1), (388, 2), (389, 27), (390, 1), (391, 1), (392, 3), (393, 27), (394, 26), (395, 2), (396, 1), (397, 1), (398, 2), (399, 2)], [(94, 3), (130, 2), (146, 4), (400, 1), (401, 1), (402, 2), (403, 1), (404, 2), (405, 2), (406, 2), (407, 1), (408, 1)], [(355, 1), (409, 1)], [(6, 2), (18, 1), (29, 1), (38, 1), (39, 5), (48, 1), (49, 6), (50, 4), (94, 1), (123, 1), (187, 3), (213, 2), (224, 1), (287, 4), (319, 5), (410, 2), (411, 1), (412, 1), (413, 2), (414, 1), (415, 1), (416, 1), (417, 1), (418, 1), (419, 1), (420, 1), (421, 1), (422, 2), (423, 1), (424, 1), (425, 1), (426, 1), (427, 2), (428, 2)], [(2, 1), (14, 2), (93, 1), (94, 4), (126, 1), (128, 12), (129, 1), (131, 3), (146, 1), (147, 2), (153, 10), (181, 1), (183, 1), (189, 1), (223, 1), (257, 5), (260, 1), (296, 1), (344, 1), (369, 1), (378, 1), (429, 4), (430, 1), (431, 1), (432, 1), (433, 1), (434, 1), (435, 2), (436, 1), (437, 1), (438, 1), (439, 1), (440, 5), (441, 1), (442, 1), (443, 1), (444, 2), (445, 1), (446, 1), (447, 1), (448, 1), (449, 1), (450, 2), (451, 1), (452, 1), (453, 1), (454, 1), (455, 1), (456, 1), (457, 1), (458, 1), (459, 4), (460, 1), (461, 1), (462, 1), (463, 1), (464, 1), (465, 21), (466, 2), (467, 8), (468, 1), (469, 1), (470, 1), (471, 1), (472, 1), (473, 1), (474, 1), (475, 1), (476, 1), (477, 2), (478, 1), (479, 8), (480, 1), (481, 1), (482, 1), (483, 1), (484, 1), (485, 2), (486, 1), (487, 2), (488, 2)], [(41, 1), (70, 3), (71, 1), (83, 1), (99, 1), (104, 1), (115, 1), (117, 15), (119, 4), (135, 1), (141, 1), (168, 1), (173, 1), (187, 1), (296, 1), (305, 1), (382, 1), (416, 1), (481, 1), (489, 1), (490, 1), (491, 1), (492, 1), (493, 1), (494, 1), (495, 9), (496, 1), (497, 1), (498, 1), (499, 1), (500, 1), (501, 1), (502, 1)], [(11, 1), (19, 2), (20, 1), (39, 1), (48, 1), (55, 1), (59, 4), (70, 1), (93, 2), (94, 4), (128, 2), (131, 3), (153, 1), (159, 4), (164, 4), (167, 1), (169, 1), (281, 26), (293, 2), (305, 2), (321, 2), (344, 2), (403, 1), (419, 1), (429, 1), (440, 2), (459, 1), (465, 9), (466, 1), (481, 1), (488, 2), (493, 22), (503, 1), (504, 1), (505, 1), (506, 4), (507, 3), (508, 1), (509, 1), (510, 1), (511, 1), (512, 1), (513, 1), (514, 1), (515, 1), (516, 1), (517, 4), (518, 1), (519, 2), (520, 2)], [(37, 1), (159, 1), (287, 2), (521, 1), (522, 2), (523, 2)], [(50, 1), (72, 4), (83, 4), (123, 1), (153, 5), (154, 1), (209, 1), (234, 1), (329, 4), (424, 1), (524, 1), (525, 1), (526, 4), (527, 7), (528, 1), (529, 1), (530, 1), (531, 1), (532, 1), (533, 1), (534, 4)], [(36, 2), (69, 2), (83, 1), (86, 2), (481, 2), (506, 1), (528, 2), (535, 2), (536, 2)], [(5, 2), (41, 1), (50, 3), (70, 1), (74, 1), (81, 3), (83, 1), (93, 2), (104, 2), (114, 1), (131, 4), (147, 1), (168, 1), (188, 1), (196, 2), (213, 1), (261, 1), (270, 2), (297, 1), (299, 2), (330, 3), (378, 4), (392, 1), (438, 1), (465, 2), (466, 1), (469, 1), (483, 1), (484, 1), (490, 1), (510, 1), (513, 5), (529, 1), (537, 1), (538, 1), (539, 1), (540, 1), (541, 1), (542, 1), (543, 1), (544, 1), (545, 1), (546, 1), (547, 1), (548, 10), (549, 1), (550, 1), (551, 2), (552, 1), (553, 4), (554, 1), (555, 1), (556, 1), (557, 1), (558, 1), (559, 1), (560, 1), (561, 1), (562, 3), (563, 1), (564, 1), (565, 1), (566, 1), (567, 1), (568, 1), (569, 2), (570, 1), (571, 1), (572, 2), (573, 1), (574, 1), (575, 1), (576, 2), (577, 1), (578, 10), (579, 1), (580, 1), (581, 1), (582, 14), (583, 1), (584, 1), (585, 1), (586, 1), (587, 1), (588, 1), (589, 1), (590, 2), (591, 2), (592, 1), (593, 10), (594, 1), (595, 2), (596, 1), (597, 2), (598, 1), (599, 1), (600, 2), (601, 5), (602, 2), (603, 2), (604, 1), (605, 1), (606, 1), (607, 1), (608, 2), (609, 1), (610, 2), (611, 1), (612, 4)], [(1, 1), (5, 3), (8, 6), (12, 1), (26, 1), (41, 8), (42, 1), (56, 1), (59, 1), (64, 3), (70, 1), (81, 1), (83, 6), (93, 2), (95, 1), (98, 1), (104, 2), (110, 1), (112, 1), (119, 1), (126, 2), (129, 1), (131, 1), (147, 1), (153, 1), (159, 10), (169, 1), (173, 1), (185, 1), (190, 1), (202, 1), (238, 2), (239, 1), (269, 1), (293, 1), (299, 3), (356, 1), (359, 1), (366, 1), (370, 1), (376, 1), (392, 1), (397, 1), (398, 1), (419, 2), (450, 1), (461, 1), (469, 1), (540, 1), (576, 1), (586, 6), (599, 1), (608, 1), (613, 1), (614, 1), (615, 2), (616, 1), (617, 1), (618, 1), (619, 1), (620, 1), (621, 1), (622, 1), (623, 2), (624, 1), (625, 1), (626, 1), (627, 1), (628, 1), (629, 1), (630, 1), (631, 1), (632, 2), (633, 1), (634, 1), (635, 2), (636, 1), (637, 2), (638, 1), (639, 1), (640, 1), (641, 2), (642, 1), (643, 1), (644, 1), (645, 1), (646, 2), (647, 1), (648, 1), (649, 1), (650, 6), (651, 3), (652, 1), (653, 1), (654, 2), (655, 3), (656, 1), (657, 1), (658, 2), (659, 1), (660, 1), (661, 1), (662, 1), (663, 1), (664, 2), (665, 1), (666, 1), (667, 1), (668, 2), (669, 1), (670, 2), (671, 1), (672, 1), (673, 1), (674, 1), (675, 2), (676, 1), (677, 1), (678, 1), (679, 1), (680, 1), (681, 1), (682, 1), (683, 1)], [(14, 3), (129, 3), (159, 4), (516, 3), (517, 3), (684, 1), (685, 1), (686, 1), (687, 3), (688, 3), (689, 3)], [(25, 1), (26, 5), (39, 1), (53, 13), (110, 3), (129, 1), (203, 3), (209, 1), (249, 2), (264, 1), (339, 9), (344, 1), (355, 16), (382, 4), (387, 1), (392, 3), (690, 1), (691, 2), (692, 1), (693, 1), (694, 1), (695, 1), (696, 1), (697, 1), (698, 1), (699, 1), (700, 3), (701, 1), (702, 5), (703, 1)], [(19, 1), (26, 1), (39, 4), (59, 3), (64, 1), (81, 1), (95, 2), (147, 1), (168, 1), (183, 2), (184, 1), (257, 1), (296, 1), (342, 2), (378, 1), (529, 1), (704, 1), (705, 2), (706, 1), (707, 1), (708, 2), (709, 1), (710, 1), (711, 1), (712, 2), (713, 1), (714, 1), (715, 1)], [(27, 1), (41, 1), (506, 1), (608, 1), (646, 1), (716, 1), (717, 1), (718, 1)], [(28, 2), (112, 3), (135, 1), (153, 1), (168, 1), (405, 11), (451, 9), (461, 1), (507, 2), (529, 1), (554, 9), (623, 4), (719, 9), (720, 1), (721, 1), (722, 2), (723, 2), (724, 9), (725, 2), (726, 2), (727, 2), (728, 2), (729, 1), (730, 1), (731, 2), (732, 1), (733, 2), (734, 1), (735, 1), (736, 1), (737, 2)], [(39, 7), (141, 1), (153, 3), (187, 3), (189, 1), (494, 1), (506, 1), (550, 1), (738, 1), (739, 1), (740, 1), (741, 3), (742, 1), (743, 1)], [(94, 1), (257, 3), (355, 2), (507, 6), (716, 2), (744, 2), (745, 1), (746, 1), (747, 2), (748, 1), (749, 1), (750, 3), (751, 1)], [(94, 2), (169, 2), (234, 2), (274, 5), (437, 1), (507, 2), (649, 1), (752, 3), (753, 2), (754, 2), (755, 2), (756, 1), (757, 1)], [(147, 1), (188, 1), (257, 20), (273, 1), (389, 2), (392, 2), (393, 1), (440, 5), (476, 1), (603, 1), (749, 4), (751, 4), (758, 1), (759, 1), (760, 5), (761, 5), (762, 1), (763, 1), (764, 7), (765, 5), (766, 1), (767, 1), (768, 1), (769, 1), (770, 5), (771, 1), (772, 1)], [(39, 1), (119, 1), (141, 1), (146, 1), (153, 1), (249, 1), (491, 1), (528, 1), (773, 1), (774, 1)], [(49, 2), (123, 2), (224, 2), (465, 2), (687, 2), (775, 1)], [(36, 4), (153, 3), (195, 3), (241, 1), (251, 1), (458, 4), (518, 2), (548, 3), (776, 1), (777, 4), (778, 1), (779, 1), (780, 3), (781, 1), (782, 4)], [(99, 4), (236, 1), (424, 1), (783, 1), (784, 4), (785, 1), (786, 1), (787, 1), (788, 1), (789, 4), (790, 3)], [(5, 2), (6, 2), (7, 2), (12, 1), (14, 3), (16, 1), (18, 2), (19, 15), (26, 4), (31, 2), (32, 1), (38, 2), (39, 11), (43, 1), (49, 4), (53, 1), (59, 2), (69, 2), (78, 1), (80, 1), (83, 3), (94, 1), (115, 1), (117, 2), (123, 2), (133, 1), (135, 5), (141, 3), (144, 1), (146, 1), (168, 12), (174, 1), (178, 1), (183, 2), (195, 1), (209, 1), (249, 1), (252, 2), (317, 1), (342, 1), (344, 1), (356, 1), (424, 2), (437, 4), (481, 3), (490, 2), (494, 1), (495, 1), (507, 1), (537, 2), (622, 2), (626, 1), (637, 3), (757, 1), (791, 1), (792, 6), (793, 2), (794, 1), (795, 1), (796, 1), (797, 1), (798, 8), (799, 1), (800, 2), (801, 1), (802, 1), (803, 1), (804, 2), (805, 1), (806, 1), (807, 2), (808, 1), (809, 1), (810, 1), (811, 1), (812, 2), (813, 1), (814, 1), (815, 1), (816, 2), (817, 1), (818, 1), (819, 1), (820, 1), (821, 1), (822, 1), (823, 1), (824, 2), (825, 1), (826, 1), (827, 3), (828, 1), (829, 3), (830, 1), (831, 1), (832, 2), (833, 1), (834, 1), (835, 2), (836, 1), (837, 1), (838, 1), (839, 3), (840, 1), (841, 1), (842, 1)], [(7, 1), (12, 2), (31, 1), (33, 2), (38, 1), (39, 16), (40, 2), (41, 4), (42, 3), (48, 1), (49, 7), (59, 2), (70, 1), (125, 1), (135, 1), (146, 1), (153, 2), (154, 4), (168, 4), (170, 1), (183, 1), (213, 2), (225, 2), (294, 1), (407, 1), (418, 1), (507, 1), (537, 1), (544, 2), (727, 1), (819, 1), (843, 1), (844, 1), (845, 2), (846, 1), (847, 2), (848, 1), (849, 1), (850, 1), (851, 1), (852, 2), (853, 1), (854, 1), (855, 1), (856, 1), (857, 1), (858, 1), (859, 1), (860, 1), (861, 3), (862, 1), (863, 1), (864, 1)], [(209, 2), (321, 2), (544, 2)], [(34, 2), (183, 2), (233, 2), (456, 2), (719, 2), (865, 1), (866, 1), (867, 1), (868, 2)], [(125, 2), (141, 4), (465, 1), (535, 3), (538, 4), (629, 4), (648, 1), (869, 7), (870, 2), (871, 1), (872, 4), (873, 1), (874, 1), (875, 4), (876, 2), (877, 2), (878, 2), (879, 4), (880, 4), (881, 1), (882, 1)], [(41, 35), (49, 1), (70, 1), (79, 31), (83, 20), (94, 1), (95, 2), (104, 34), (108, 20), (110, 34), (117, 2), (120, 2), (121, 2), (131, 1), (160, 1), (496, 1), (561, 1), (639, 1), (883, 1), (884, 1), (885, 1), (886, 1), (887, 2), (888, 1), (889, 2), (890, 1), (891, 1), (892, 1), (893, 1), (894, 2), (895, 9), (896, 1)], [(70, 1), (110, 1), (496, 1), (884, 1), (892, 1), (893, 1), (896, 1)], [], [(39, 2), (41, 1), (50, 1), (114, 1), (153, 2), (156, 1), (187, 3), (206, 3), (208, 1), (213, 2), (714, 1), (782, 1), (897, 1), (898, 1), (899, 1), (900, 1), (901, 2), (902, 1), (903, 3), (904, 3), (905, 3), (906, 1), (907, 1), (908, 3)], [(909, 1)], [(43, 6), (321, 4), (399, 6), (507, 6), (792, 6)], [(8, 1), (11, 1), (50, 4), (81, 3), (83, 1), (94, 3), (95, 1), (103, 1), (106, 1), (133, 2), (147, 2), (168, 2), (187, 1), (224, 1), (228, 1), (257, 1), (261, 1), (330, 2), (369, 3), (378, 1), (382, 3), (397, 2), (399, 1), (407, 1), (431, 2), (433, 1), (437, 2), (448, 1), (449, 1), (457, 1), (465, 8), (493, 2), (540, 2), (588, 1), (610, 1), (649, 2), (662, 1), (667, 1), (712, 2), (716, 1), (910, 1), (911, 2), (912, 1), (913, 2), (914, 1), (915, 1), (916, 1), (917, 2), (918, 1), (919, 1), (920, 1), (921, 1), (922, 2), (923, 2), (924, 1), (925, 1), (926, 1), (927, 1), (928, 1), (929, 1), (930, 2), (931, 1), (932, 1), (933, 1), (934, 2), (935, 1), (936, 1), (937, 2), (938, 2), (939, 1), (940, 1), (941, 2), (942, 2), (943, 2)], [(1, 1), (14, 2), (106, 1), (159, 7), (164, 2), (293, 1), (305, 1), (344, 1), (386, 6), (465, 2), (479, 1), (483, 2), (506, 2), (517, 8), (626, 6), (634, 1), (667, 1), (820, 1), (944, 1), (945, 1), (946, 5), (947, 1), (948, 2), (949, 1), (950, 1), (951, 5), (952, 1), (953, 1), (954, 1), (955, 1), (956, 1), (957, 5), (958, 5), (959, 1), (960, 5)], [(153, 4), (249, 2), (285, 2), (358, 1), (525, 1), (961, 1), (962, 1), (963, 1)], [(7, 1), (14, 1), (16, 1), (18, 1), (21, 2), (26, 4), (28, 2), (34, 2), (48, 1), (81, 2), (86, 3), (106, 1), (125, 2), (128, 1), (129, 1), (135, 2), (147, 7), (159, 26), (160, 6), (164, 8), (169, 1), (170, 1), (176, 2), (180, 5), (191, 1), (214, 1), (218, 2), (257, 5), (258, 5), (269, 1), (286, 1), (299, 1), (305, 2), (312, 3), (366, 1), (370, 4), (373, 2), (374, 3), (376, 18), (382, 1), (383, 7), (385, 1), (386, 32), (394, 13), (395, 2), (397, 4), (403, 1), (431, 1), (444, 1), (448, 1), (449, 2), (455, 14), (458, 1), (469, 1), (483, 8), (490, 1), (513, 2), (516, 1), (517, 2), (528, 1), (529, 1), (532, 1), (534, 6), (540, 4), (543, 14), (544, 2), (548, 1), (575, 4), (578, 3), (582, 1), (594, 2), (597, 2), (599, 2), (606, 1), (620, 4), (626, 39), (632, 1), (640, 1), (650, 2), (655, 12), (678, 21), (681, 9), (682, 18), (764, 2), (770, 1), (782, 2), (819, 1), (826, 4), (833, 1), (838, 21), (846, 1), (865, 1), (881, 2), (893, 5), (912, 3), (915, 2), (951, 1), (953, 1), (956, 1), (964, 1), (965, 1), (966, 1), (967, 3), (968, 1), (969, 1), (970, 4), (971, 1), (972, 1), (973, 1), (974, 1), (975, 1), (976, 1), (977, 1), (978, 1), (979, 2), (980, 2), (981, 1), (982, 1), (983, 1), (984, 1), (985, 3), (986, 21), (987, 1), (988, 1), (989, 2), (990, 1), (991, 1), (992, 1), (993, 2), (994, 1), (995, 1), (996, 1), (997, 1), (998, 1), (999, 1), (1000, 1), (1001, 1), (1002, 2), (1003, 1), (1004, 2), (1005, 2), (1006, 1), (1007, 13), (1008, 1), (1009, 4), (1010, 1), (1011, 31), (1012, 1), (1013, 1), (1014, 1), (1015, 2), (1016, 2), (1017, 1), (1018, 1), (1019, 1), (1020, 1), (1021, 1), (1022, 1), (1023, 1), (1024, 1), (1025, 1), (1026, 1), (1027, 1), (1028, 1), (1029, 2), (1030, 1), (1031, 1), (1032, 1), (1033, 5), (1034, 2), (1035, 1), (1036, 1), (1037, 2), (1038, 2), (1039, 2), (1040, 3), (1041, 1), (1042, 2), (1043, 1), (1044, 1), (1045, 2), (1046, 2), (1047, 2), (1048, 1), (1049, 1), (1050, 1), (1051, 1), (1052, 1), (1053, 2), (1054, 1), (1055, 1), (1056, 3), (1057, 5), (1058, 1), (1059, 1), (1060, 2), (1061, 1), (1062, 1), (1063, 1), (1064, 2), (1065, 3), (1066, 2), (1067, 1), (1068, 2), (1069, 1), (1070, 1), (1071, 2), (1072, 2), (1073, 2), (1074, 1), (1075, 1), (1076, 5), (1077, 1), (1078, 2), (1079, 4), (1080, 1), (1081, 1), (1082, 2), (1083, 1), (1084, 1), (1085, 2), (1086, 1), (1087, 2)], [(7, 1), (12, 2), (33, 2), (39, 4), (48, 1), (49, 5), (50, 2), (72, 2), (75, 1), (77, 1), (83, 4), (95, 2), (99, 1), (105, 1), (123, 4), (124, 1), (153, 2), (154, 1), (168, 1), (186, 2), (187, 1), (193, 2), (206, 5), (211, 1), (222, 1), (223, 1), (224, 1), (237, 1), (238, 1), (239, 2), (252, 2), (261, 2), (287, 6), (299, 1), (357, 1), (358, 1), (374, 1), (397, 2), (417, 2), (418, 3), (490, 1), (532, 3), (688, 1), (776, 1), (816, 2), (959, 1), (996, 1), (1086, 1), (1088, 2), (1089, 1), (1090, 1), (1091, 1), (1092, 1), (1093, 1), (1094, 1), (1095, 1), (1096, 1), (1097, 1), (1098, 1), (1099, 1), (1100, 2), (1101, 1), (1102, 1), (1103, 1), (1104, 1), (1105, 2), (1106, 1), (1107, 1), (1108, 2), (1109, 1), (1110, 1), (1111, 1), (1112, 1)], [(14, 1), (50, 2), (72, 2), (83, 3), (94, 8), (95, 2), (123, 2), (124, 1), (133, 1), (167, 1), (169, 1), (186, 1), (222, 2), (224, 4), (226, 2), (228, 3), (237, 1), (238, 1), (249, 1), (266, 1), (281, 1), (293, 7), (299, 1), (344, 1), (389, 2), (402, 1), (403, 1), (465, 3), (466, 2), (469, 1), (473, 1), (506, 3), (610, 2), (616, 1), (623, 1), (632, 1), (656, 1), (840, 6), (908, 1), (927, 6), (928, 2), (942, 1), (959, 1), (971, 1), (981, 1), (1100, 1), (1102, 1), (1113, 1), (1114, 1), (1115, 1), (1116, 2), (1117, 1), (1118, 2), (1119, 1), (1120, 1), (1121, 1), (1122, 2), (1123, 1), (1124, 1), (1125, 1), (1126, 1), (1127, 1), (1128, 1), (1129, 2), (1130, 1), (1131, 1), (1132, 1), (1133, 1), (1134, 1), (1135, 2), (1136, 2), (1137, 1), (1138, 2), (1139, 1), (1140, 1), (1141, 1), (1142, 1), (1143, 2), (1144, 1), (1145, 1), (1146, 1), (1147, 1), (1148, 1), (1149, 2)], [(49, 4), (86, 2), (1150, 1)], [(27, 1), (116, 1), (146, 1), (206, 1), (228, 1), (250, 1), (276, 1), (691, 1), (840, 1), (1151, 1), (1152, 1), (1153, 1), (1154, 1), (1155, 1), (1156, 1)], [(4, 2), (8, 3), (11, 11), (17, 1), (19, 1), (25, 1), (28, 2), (31, 2), (34, 1), (37, 1), (39, 3), (43, 1), (49, 1), (50, 6), (53, 1), (56, 1), (70, 2), (71, 1), (72, 1), (74, 3), (75, 1), (81, 2), (82, 1), (83, 2), (93, 5), (94, 3), (95, 2), (96, 2), (99, 1), (106, 2), (107, 1), (110, 1), (112, 1), (115, 1), (122, 1), (126, 1), (129, 8), (131, 2), (137, 1), (141, 3), (144, 1), (146, 2), (147, 7), (153, 13), (154, 1), (159, 1), (160, 8), (164, 1), (168, 5), (169, 3), (176, 1), (178, 1), (183, 1), (186, 1), (188, 3), (195, 1), (202, 1), (226, 1), (228, 2), (232, 1), (233, 1), (236, 1), (243, 1), (249, 1), (252, 5), (257, 6), (258, 2), (261, 1), (269, 3), (270, 1), (276, 3), (281, 6), (285, 1), (287, 2), (293, 1), (294, 1), (296, 1), (297, 2), (299, 9), (305, 2), (313, 2), (320, 2), (330, 2), (342, 1), (344, 23), (355, 2), (356, 1), (366, 1), (369, 7), (370, 1), (374, 1), (375, 1), (382, 5), (386, 6), (389, 2), (392, 5), (393, 1), (399, 1), (403, 1), (405, 1), (406, 1), (407, 1), (415, 3), (419, 1), (424, 2), (437, 2), (438, 4), (444, 2), (450, 1), (455, 1), (458, 2), (461, 2), (464, 4), (465, 39), (466, 20), (469, 2), (472, 1), (473, 3), (475, 1), (476, 2), (488, 6), (490, 1), (493, 4), (499, 1), (506, 2), (507, 2), (512, 1), (513, 4), (517, 1), (518, 3), (524, 1), (532, 2), (535, 1), (537, 1), (540, 1), (550, 3), (552, 1), (555, 2), (559, 1), (562, 1), (567, 1), (571, 4), (572, 1), (575, 3), (578, 2), (580, 1), (594, 1), (599, 1), (606, 1), (608, 2), (610, 1), (612, 1), (622, 1), (627, 2), (640, 3), (644, 3), (650, 1), (662, 6), (674, 2), (692, 1), (704, 1), (716, 2), (722, 1), (728, 1), (749, 2), (757, 8), (782, 1), (811, 3), (814, 1), (816, 1), (819, 1), (820, 1), (830, 1), (831, 2), (840, 2), (851, 1), (858, 2), (869, 2), (879, 1), (881, 1), (890, 1), (920, 2), (945, 3), (951, 1), (956, 1), (971, 2), (981, 2), (994, 1), (998, 1), (1016, 1), (1017, 2), (1063, 2), (1065, 2), (1069, 1), (1092, 1), (1102, 1), (1129, 1), (1133, 1), (1136, 1), (1157, 4), (1158, 1), (1159, 2), (1160, 1), (1161, 1), (1162, 1), (1163, 1), (1164, 2), (1165, 1), (1166, 1), (1167, 1), (1168, 1), (1169, 1), (1170, 1), (1171, 1), (1172, 1), (1173, 1), (1174, 1), (1175, 1), (1176, 1), (1177, 1), (1178, 1), (1179, 1), (1180, 1), (1181, 1), (1182, 1), (1183, 1), (1184, 1), (1185, 2), (1186, 1), (1187, 2), (1188, 1), (1189, 2), (1190, 1), (1191, 1), (1192, 1), (1193, 2), (1194, 2), (1195, 1), (1196, 1), (1197, 1), (1198, 2), (1199, 1), (1200, 1), (1201, 2), (1202, 1), (1203, 1), (1204, 2), (1205, 3), (1206, 1), (1207, 1), (1208, 2), (1209, 1), (1210, 2), (1211, 1), (1212, 1), (1213, 1), (1214, 1), (1215, 1), (1216, 1), (1217, 1), (1218, 1), (1219, 1), (1220, 1), (1221, 1), (1222, 1), (1223, 1), (1224, 1), (1225, 1), (1226, 2), (1227, 6), (1228, 3), (1229, 1), (1230, 1), (1231, 1), (1232, 1), (1233, 1), (1234, 1), (1235, 1), (1236, 1), (1237, 5), (1238, 1), (1239, 1), (1240, 1), (1241, 1), (1242, 1), (1243, 1), (1244, 1), (1245, 1), (1246, 4), (1247, 2), (1248, 1), (1249, 2), (1250, 3), (1251, 1), (1252, 1), (1253, 2), (1254, 1), (1255, 1), (1256, 1), (1257, 2), (1258, 2), (1259, 3), (1260, 1), (1261, 1), (1262, 1), (1263, 1), (1264, 1), (1265, 1), (1266, 1), (1267, 1), (1268, 1), (1269, 1), (1270, 1), (1271, 2), (1272, 1), (1273, 1), (1274, 1), (1275, 1), (1276, 1), (1277, 2), (1278, 6), (1279, 4), (1280, 1), (1281, 1), (1282, 1), (1283, 1), (1284, 1), (1285, 1), (1286, 1), (1287, 1), (1288, 1), (1289, 1), (1290, 1), (1291, 2), (1292, 2), (1293, 2), (1294, 1), (1295, 1), (1296, 1), (1297, 1), (1298, 1), (1299, 1), (1300, 6), (1301, 1), (1302, 1), (1303, 1), (1304, 1), (1305, 1), (1306, 1), (1307, 2), (1308, 3), (1309, 1), (1310, 2), (1311, 1), (1312, 3), (1313, 2), (1314, 1), (1315, 1), (1316, 1), (1317, 1), (1318, 1), (1319, 1), (1320, 1), (1321, 1), (1322, 1), (1323, 1), (1324, 1), (1325, 1), (1326, 1), (1327, 1), (1328, 1), (1329, 1), (1330, 1), (1331, 1), (1332, 1), (1333, 1), (1334, 2), (1335, 2), (1336, 2), (1337, 2), (1338, 1), (1339, 1), (1340, 2), (1341, 1), (1342, 2), (1343, 1), (1344, 1), (1345, 1), (1346, 1), (1347, 2), (1348, 1), (1349, 1), (1350, 1), (1351, 1), (1352, 2), (1353, 1), (1354, 1), (1355, 1), (1356, 1), (1357, 1), (1358, 1), (1359, 1), (1360, 1), (1361, 1), (1362, 1), (1363, 1), (1364, 2), (1365, 1), (1366, 4)]]\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_lemmatized)   # Create Dictionary\n",
    "\n",
    "\n",
    "# Create Corpus\n",
    "\n",
    "corpus = [id2word.doc2bow(text) for text in data_lemmatized]\n",
    "\n",
    "print(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [('ackmoney', 1),\n",
       "  ('advantage', 1),\n",
       "  ('already', 1),\n",
       "  ('answerable', 1),\n",
       "  ('appreciate', 1),\n",
       "  ('bad', 2),\n",
       "  ('banerjee', 3),\n",
       "  ('bjp', 1),\n",
       "  ('call', 1),\n",
       "  ('compete', 1),\n",
       "  ('courage', 1),\n",
       "  ('currency', 1),\n",
       "  ('decision', 3),\n",
       "  ('drunk', 1),\n",
       "  ('economic', 2),\n",
       "  ('elect', 2),\n",
       "  ('election', 1),\n",
       "  ('fun', 1),\n",
       "  ('global', 2),\n",
       "  ('good', 2),\n",
       "  ('hold', 1),\n",
       "  ('however', 1),\n",
       "  ('iamsrk', 1),\n",
       "  ('immense', 1),\n",
       "  ('kapilsharmak', 2),\n",
       "  ('leader', 1),\n",
       "  ('make', 3),\n",
       "  ('man', 1),\n",
       "  ('may', 1),\n",
       "  ('modibharosa', 1),\n",
       "  ('momentous', 1),\n",
       "  ('move', 1),\n",
       "  ('narendramodi', 1),\n",
       "  ('nation', 3),\n",
       "  ('need', 4),\n",
       "  ('nitishkumar', 5),\n",
       "  ('opposition', 1),\n",
       "  ('parliament', 1),\n",
       "  ('party', 3),\n",
       "  ('people', 2),\n",
       "  ('politic', 7),\n",
       "  ('poor', 2),\n",
       "  ('prove', 2),\n",
       "  ('put', 7),\n",
       "  ('rakhisawant', 1),\n",
       "  ('revolutionary', 2),\n",
       "  ('ruption', 1),\n",
       "  ('shortly', 1),\n",
       "  ('show', 2),\n",
       "  ('support', 18),\n",
       "  ('take', 1),\n",
       "  ('thore', 1),\n",
       "  ('upelection', 2),\n",
       "  ('video', 1),\n",
       "  ('voice', 3),\n",
       "  ('word', 1),\n",
       "  ('work', 1)],\n",
       " [('election', 1),\n",
       "  ('good', 1),\n",
       "  ('leader', 1),\n",
       "  ('modibharosa', 3),\n",
       "  ('move', 11),\n",
       "  ('narendramodi', 3),\n",
       "  ('nation', 9),\n",
       "  ('need', 1),\n",
       "  ('opposition', 1),\n",
       "  ('party', 2),\n",
       "  ('people', 10),\n",
       "  ('ruption', 2),\n",
       "  ('support', 13),\n",
       "  ('take', 5),\n",
       "  ('thore', 1),\n",
       "  ('advice', 4),\n",
       "  ('aspect', 1),\n",
       "  ('back', 7),\n",
       "  ('bold', 1),\n",
       "  ('chandrababu', 2),\n",
       "  ('coin', 1),\n",
       "  ('complete', 1),\n",
       "  ('could', 1),\n",
       "  ('coverage', 1),\n",
       "  ('cvot', 2),\n",
       "  ('dem', 1),\n",
       "  ('different', 1),\n",
       "  ('do', 1),\n",
       "  ('even', 1),\n",
       "  ('feel', 2),\n",
       "  ('first', 4),\n",
       "  ('gitanjali', 1),\n",
       "  ('government', 1),\n",
       "  ('happy', 1),\n",
       "  ('historic', 3),\n",
       "  ('honest', 2),\n",
       "  ('huge', 11),\n",
       "  ('implement', 4),\n",
       "  ('incredible', 1),\n",
       "  ('issue', 1),\n",
       "  ('many', 2),\n",
       "  ('modi', 2),\n",
       "  ('myindmaker', 1),\n",
       "  ('narendramodii', 2),\n",
       "  ('oppose', 1),\n",
       "  ('oppositio', 1),\n",
       "  ('participation', 1),\n",
       "  ('programme', 1),\n",
       "  ('ratansharda', 1),\n",
       "  ('risk', 1),\n",
       "  ('rntata', 1),\n",
       "  ('s', 1),\n",
       "  ('say', 5),\n",
       "  ('see', 4),\n",
       "  ('step', 1),\n",
       "  ('sumitbhati', 1),\n",
       "  ('terrorism', 1),\n",
       "  ('thank', 2),\n",
       "  ('trump', 1),\n",
       "  ('unknown', 1),\n",
       "  ('vindicated', 2)],\n",
       " [('election', 1),\n",
       "  ('implement', 18),\n",
       "  ('modi', 16),\n",
       "  ('actual', 1),\n",
       "  ('actually', 5),\n",
       "  ('also', 1),\n",
       "  ('article', 1),\n",
       "  ('better', 1),\n",
       "  ('dear', 13),\n",
       "  ('deepjm', 1),\n",
       "  ('find', 16),\n",
       "  ('grave', 1),\n",
       "  ('look', 1),\n",
       "  ('poo', 2),\n",
       "  ('really', 1),\n",
       "  ('reason', 1),\n",
       "  ('respect', 1),\n",
       "  ('rich', 2),\n",
       "  ('sanjeetbisht', 1),\n",
       "  ('seem', 1),\n",
       "  ('snapchatceo', 1),\n",
       "  ('spiegel', 1),\n",
       "  ('suffer', 1),\n",
       "  ('survey', 1),\n",
       "  ('win', 1)],\n",
       " [('benefit', 4),\n",
       "  ('claim', 4),\n",
       "  ('ensure', 4),\n",
       "  ('fake', 4),\n",
       "  ('go', 7),\n",
       "  ('supply', 4),\n",
       "  ('terrorist', 4)],\n",
       " [('currency', 1),\n",
       "  ('make', 1),\n",
       "  ('need', 1),\n",
       "  ('people', 3),\n",
       "  ('coverage', 2),\n",
       "  ('even', 1),\n",
       "  ('s', 1),\n",
       "  ('terrorist', 1),\n",
       "  ('activity', 1),\n",
       "  ('affect', 1),\n",
       "  ('annai', 1),\n",
       "  ('black', 1),\n",
       "  ('blame', 3),\n",
       "  ('chopsyturvey', 2),\n",
       "  ('collector', 1),\n",
       "  ('column', 1),\n",
       "  ('crore', 1),\n",
       "  ('day', 4),\n",
       "  ('definitely', 2),\n",
       "  ('depress', 1),\n",
       "  ('die', 1),\n",
       "  ('drain', 1),\n",
       "  ('due', 2),\n",
       "  ('economy', 1),\n",
       "  ('enough', 1),\n",
       "  ('expose', 1),\n",
       "  ('flat', 2),\n",
       "  ('follower', 1),\n",
       "  ('fuss', 1),\n",
       "  ('get', 4),\n",
       "  ('give', 2),\n",
       "  ('guy', 1),\n",
       "  ('hard', 1),\n",
       "  ('haunt', 1),\n",
       "  ('holder', 1),\n",
       "  ('impact', 1),\n",
       "  ('indian', 2),\n",
       "  ('indore', 1),\n",
       "  ('introspect', 1),\n",
       "  ('life', 2),\n",
       "  ('long', 1),\n",
       "  ('longer', 1),\n",
       "  ('maven', 1),\n",
       "  ('medium', 3),\n",
       "  ('money', 2),\n",
       "  ('much', 1),\n",
       "  ('pay', 1),\n",
       "  ('penisgarlic', 1),\n",
       "  ('practice', 1),\n",
       "  ('problem', 1),\n",
       "  ('protest', 1),\n",
       "  ('queue', 2),\n",
       "  ('release', 1),\n",
       "  ('sanmistryious', 1),\n",
       "  ('save', 1),\n",
       "  ('seemamustafa', 1),\n",
       "  ('short', 1),\n",
       "  ('solve', 2),\n",
       "  ('sound', 2),\n",
       "  ('think', 2),\n",
       "  ('thought', 1),\n",
       "  ('ticket', 1),\n",
       "  ('tweet', 1),\n",
       "  ('vote', 1),\n",
       "  ('would', 2),\n",
       "  ('yet', 1)],\n",
       " [('call', 2),\n",
       "  ('move', 2),\n",
       "  ('issue', 2),\n",
       "  ('modi', 1),\n",
       "  ('terrorism', 1),\n",
       "  ('benefit', 6),\n",
       "  ('due', 3),\n",
       "  ('bitcoin', 3),\n",
       "  ('boom', 3),\n",
       "  ('btc', 1),\n",
       "  ('cgdtalk', 4),\n",
       "  ('disregard', 1),\n",
       "  ('join', 4),\n",
       "  ('kill', 1),\n",
       "  ('laud', 2),\n",
       "  ('moderate', 8),\n",
       "  ('nationalist', 2),\n",
       "  ('naxalism', 1),\n",
       "  ('pass', 1),\n",
       "  ('public', 2),\n",
       "  ('tomorrow', 4),\n",
       "  ('tue', 2),\n",
       "  ('underlying', 3),\n",
       "  ('want', 1)],\n",
       " [('election', 1),\n",
       "  ('take', 1),\n",
       "  ('modi', 1),\n",
       "  ('say', 2),\n",
       "  ('actually', 2),\n",
       "  ('also', 1),\n",
       "  ('survey', 3),\n",
       "  ('benefit', 2),\n",
       "  ('vote', 4),\n",
       "  ('absent', 2),\n",
       "  ('app', 1),\n",
       "  ('ask', 2),\n",
       "  ('attendance', 1),\n",
       "  ('blow', 1),\n",
       "  ('bright', 2),\n",
       "  ('bypoll', 6),\n",
       "  ('decide', 3),\n",
       "  ('demonetizat', 1),\n",
       "  ('donmu', 1),\n",
       "  ('fail', 1),\n",
       "  ('future', 2),\n",
       "  ('hemant', 3),\n",
       "  ('nowjust', 1),\n",
       "  ('official', 2),\n",
       "  ('opinion', 3),\n",
       "  ('response', 2),\n",
       "  ('result', 6),\n",
       "  ('seat', 1),\n",
       "  ('share', 1),\n",
       "  ('teacher', 4),\n",
       "  ('today', 2)],\n",
       " [('prove', 2),\n",
       "  ('modi', 2),\n",
       "  ('survey', 1),\n",
       "  ('think', 1),\n",
       "  ('bypoll', 2),\n",
       "  ('opinion', 4),\n",
       "  ('response', 2),\n",
       "  ('result', 3),\n",
       "  ('today', 2),\n",
       "  ('amazing', 2),\n",
       "  ('commitment', 2),\n",
       "  ('deduplication', 1),\n",
       "  ('fight', 1),\n",
       "  ('hour', 1),\n",
       "  ('part', 1),\n",
       "  ('powerful', 1),\n",
       "  ('retweete', 2),\n",
       "  ('successful', 2),\n",
       "  ('there', 2),\n",
       "  ('wave', 2)],\n",
       " [('already', 1),\n",
       "  ('parliament', 2),\n",
       "  ('want', 1),\n",
       "  ('fail', 1),\n",
       "  ('today', 1),\n",
       "  ('active', 1),\n",
       "  ('address', 3),\n",
       "  ('anandkamal', 2),\n",
       "  ('attack', 1),\n",
       "  ('battle', 1),\n",
       "  ('defuse', 1),\n",
       "  ('duty', 3),\n",
       "  ('frankly', 2),\n",
       "  ('function', 1),\n",
       "  ('know', 1),\n",
       "  ('parlmnt', 3),\n",
       "  ('shashitharoor', 1),\n",
       "  ('still', 2),\n",
       "  ('unacceptable', 1),\n",
       "  ('understand', 4),\n",
       "  ('wil', 1)],\n",
       " [('people', 1),\n",
       "  ('get', 1),\n",
       "  ('indian', 1),\n",
       "  ('atheist', 1),\n",
       "  ('effect', 2),\n",
       "  ('hear', 2),\n",
       "  ('relieve', 1),\n",
       "  ('stand', 2)],\n",
       " [('first', 5),\n",
       "  ('issue', 2),\n",
       "  ('get', 1),\n",
       "  ('hour', 2),\n",
       "  ('answer', 2),\n",
       "  ('bullshit', 1),\n",
       "  ('busy', 2),\n",
       "  ('celebrate', 2),\n",
       "  ('chairman', 1),\n",
       "  ('clearly', 10),\n",
       "  ('critical', 5),\n",
       "  ('current', 1),\n",
       "  ('cut', 2),\n",
       "  ('development', 2),\n",
       "  ('disclosure', 3),\n",
       "  ('edict', 7),\n",
       "  ('exclusive', 3),\n",
       "  ('explain', 1),\n",
       "  ('fishy', 6),\n",
       "  ('full', 5),\n",
       "  ('godavar', 1),\n",
       "  ('here', 1),\n",
       "  ('inform', 9),\n",
       "  ('inside', 2),\n",
       "  ('late', 2),\n",
       "  ('legal', 2),\n",
       "  ('listen', 1),\n",
       "  ('npa', 1),\n",
       "  ('paytm', 13),\n",
       "  ('phone', 2),\n",
       "  ('question', 9),\n",
       "  ('regard', 2),\n",
       "  ('require', 5),\n",
       "  ('sbi', 1),\n",
       "  ('smarket', 1),\n",
       "  ('steal', 1),\n",
       "  ('story', 2),\n",
       "  ('tell', 2),\n",
       "  ('vijayshekhar', 3),\n",
       "  ('youtube', 3)],\n",
       " [('affect', 5),\n",
       "  ('due', 3),\n",
       "  ('farmer', 5),\n",
       "  ('govts', 5),\n",
       "  ('help', 5),\n",
       "  ('innovative', 5),\n",
       "  ('minit', 2),\n",
       "  ('solution', 5),\n",
       "  ('telangana', 7)],\n",
       " [('work', 1),\n",
       "  ('implement', 2),\n",
       "  ('modi', 4),\n",
       "  ('claim', 2),\n",
       "  ('indian', 2),\n",
       "  ('still', 2),\n",
       "  ('acid', 2),\n",
       "  ('cash', 15),\n",
       "  ('chaos', 1),\n",
       "  ('civil', 2),\n",
       "  ('create', 9),\n",
       "  ('hit', 2),\n",
       "  ('isharmapuneet', 1),\n",
       "  ('loosen', 2),\n",
       "  ('mode', 12),\n",
       "  ('otherwise', 1),\n",
       "  ('panic', 6),\n",
       "  ('restriction', 2),\n",
       "  ('ronsnewsfee', 1),\n",
       "  ('run', 12),\n",
       "  ('running', 2),\n",
       "  ('store', 1),\n",
       "  ('test', 2),\n",
       "  ('time', 2),\n",
       "  ('unrest', 2),\n",
       "  ('victory', 1),\n",
       "  ('withdrawal', 2)],\n",
       " [('already', 2),\n",
       "  ('call', 2),\n",
       "  ('people', 9),\n",
       "  ('video', 12),\n",
       "  ('see', 1),\n",
       "  ('reason', 1),\n",
       "  ('win', 1),\n",
       "  ('go', 1),\n",
       "  ('black', 1),\n",
       "  ('enough', 1),\n",
       "  ('get', 2),\n",
       "  ('give', 2),\n",
       "  ('money', 5),\n",
       "  ('blow', 1),\n",
       "  ('retweete', 1),\n",
       "  ('full', 2),\n",
       "  ('youtube', 10),\n",
       "  ('ad', 2),\n",
       "  ('advertiser', 1),\n",
       "  ('appeal', 1),\n",
       "  ('askdheeraj', 1),\n",
       "  ('bail', 1),\n",
       "  ('become', 1),\n",
       "  ('bot', 2),\n",
       "  ('case', 1),\n",
       "  ('censorship', 1),\n",
       "  ('channel', 1),\n",
       "  ('close', 1),\n",
       "  ('completely', 1),\n",
       "  ('corporate', 1),\n",
       "  ('flag', 2),\n",
       "  ('hilarious', 1),\n",
       "  ('interaction', 1),\n",
       "  ('like', 67),\n",
       "  ('lose', 1),\n",
       "  ('maintain', 4),\n",
       "  ('new', 4),\n",
       "  ('reinstate', 2),\n",
       "  ('rohinisgh', 1),\n",
       "  ('silence', 4),\n",
       "  ('sleep', 1),\n",
       "  ('sonce', 1),\n",
       "  ('thus', 2),\n",
       "  ('tool', 2),\n",
       "  ('turk', 4),\n",
       "  ('twitch', 2),\n",
       "  ('unfriendly', 1),\n",
       "  ('watch', 2),\n",
       "  ('way', 2),\n",
       "  ('young', 4)],\n",
       " [('video', 9),\n",
       "  ('feel', 1),\n",
       "  ('youtube', 7),\n",
       "  ('add', 7),\n",
       "  ('appear', 2),\n",
       "  ('censor', 2),\n",
       "  ('dramatize', 1),\n",
       "  ('offensive', 2),\n",
       "  ('percent', 2),\n",
       "  ('playlist', 2),\n",
       "  ('slip', 2),\n",
       "  ('system', 2),\n",
       "  ('truth', 2),\n",
       "  ('youtubeisdead', 2)],\n",
       " [('do', 1),\n",
       "  ('article', 1),\n",
       "  ('supply', 1),\n",
       "  ('impact', 58),\n",
       "  ('long', 1),\n",
       "  ('join', 2),\n",
       "  ('stand', 1),\n",
       "  ('watch', 1),\n",
       "  ('system', 59),\n",
       "  ('bank', 1),\n",
       "  ('banking', 2),\n",
       "  ('curse', 1),\n",
       "  ('delhitie', 1),\n",
       "  ('education', 57),\n",
       "  ('fall', 27),\n",
       "  ('financial', 13),\n",
       "  ('food', 1),\n",
       "  ('gold', 27),\n",
       "  ('grow', 1),\n",
       "  ('kushtrance', 1),\n",
       "  ('link', 1),\n",
       "  ('meity', 1),\n",
       "  ('must', 1),\n",
       "  ('online', 1),\n",
       "  ('order', 1),\n",
       "  ('overall', 57),\n",
       "  ('payment', 2),\n",
       "  ('praise', 1),\n",
       "  ('pratim', 2),\n",
       "  ('price', 27),\n",
       "  ('que', 1),\n",
       "  ('ranjan', 1),\n",
       "  ('read', 3),\n",
       "  ('rise', 27),\n",
       "  ('service', 26),\n",
       "  ('set', 2),\n",
       "  ('threefold', 1),\n",
       "  ('use', 1),\n",
       "  ('worker', 2),\n",
       "  ('write', 2)],\n",
       " [('say', 3),\n",
       "  ('supply', 2),\n",
       "  ('due', 4),\n",
       "  ('citizen', 1),\n",
       "  ('closing', 1),\n",
       "  ('lack', 2),\n",
       "  ('report', 1),\n",
       "  ('riot', 2),\n",
       "  ('shortage', 2),\n",
       "  ('staff', 2),\n",
       "  ('wait', 1),\n",
       "  ('yearend', 1)],\n",
       " [('watch', 1), ('morning', 1)],\n",
       " [('banerjee', 2),\n",
       "  ('global', 1),\n",
       "  ('modibharosa', 1),\n",
       "  ('party', 1),\n",
       "  ('people', 5),\n",
       "  ('show', 1),\n",
       "  ('support', 6),\n",
       "  ('take', 4),\n",
       "  ('say', 1),\n",
       "  ('survey', 1),\n",
       "  ('vote', 3),\n",
       "  ('bypoll', 2),\n",
       "  ('result', 1),\n",
       "  ('question', 4),\n",
       "  ('store', 5),\n",
       "  ('abhijit', 2),\n",
       "  ('basically', 1),\n",
       "  ('currencyban', 1),\n",
       "  ('feedback', 2),\n",
       "  ('gadget', 1),\n",
       "  ('let', 1),\n",
       "  ('never', 1),\n",
       "  ('participate', 1),\n",
       "  ('poll', 1),\n",
       "  ('rule', 1),\n",
       "  ('search', 1),\n",
       "  ('shock', 1),\n",
       "  ('strategy', 2),\n",
       "  ('tend', 1),\n",
       "  ('thing', 1),\n",
       "  ('trending', 1),\n",
       "  ('urge', 1),\n",
       "  ('viewer', 2),\n",
       "  ('webcast', 2)],\n",
       " [('already', 1),\n",
       "  ('economic', 2),\n",
       "  ('s', 1),\n",
       "  ('say', 4),\n",
       "  ('claim', 1),\n",
       "  ('fake', 12),\n",
       "  ('go', 1),\n",
       "  ('terrorist', 3),\n",
       "  ('due', 1),\n",
       "  ('economy', 2),\n",
       "  ('get', 10),\n",
       "  ('solve', 1),\n",
       "  ('think', 1),\n",
       "  ('yet', 1),\n",
       "  ('response', 1),\n",
       "  ('effect', 5),\n",
       "  ('stand', 1),\n",
       "  ('youtube', 1),\n",
       "  ('new', 1),\n",
       "  ('bank', 1),\n",
       "  ('grow', 1),\n",
       "  ('ahmedabad', 4),\n",
       "  ('andor', 1),\n",
       "  ('announce', 1),\n",
       "  ('antinational', 1),\n",
       "  ('askanshul', 1),\n",
       "  ('bandiporaj', 1),\n",
       "  ('begin', 2),\n",
       "  ('border', 1),\n",
       "  ('can', 1),\n",
       "  ('change', 1),\n",
       "  ('complaint', 1),\n",
       "  ('contract', 5),\n",
       "  ('crap', 1),\n",
       "  ('creativity', 1),\n",
       "  ('cripple', 1),\n",
       "  ('datum', 2),\n",
       "  ('debunk', 1),\n",
       "  ('difficult', 1),\n",
       "  ('dpurkayastha', 1),\n",
       "  ('finance', 1),\n",
       "  ('follow', 1),\n",
       "  ('force', 2),\n",
       "  ('fund', 1),\n",
       "  ('grey', 1),\n",
       "  ('gun', 1),\n",
       "  ('iamshivanaidu', 1),\n",
       "  ('increase', 1),\n",
       "  ('indeed', 1),\n",
       "  ('launch', 1),\n",
       "  ('line', 1),\n",
       "  ('linger', 4),\n",
       "  ('lity', 1),\n",
       "  ('mean', 1),\n",
       "  ('mess', 1),\n",
       "  ('musician', 1),\n",
       "  ('night', 1),\n",
       "  ('note', 21),\n",
       "  ('old', 2),\n",
       "  ('owner', 8),\n",
       "  ('pink', 1),\n",
       "  ('post', 1),\n",
       "  ('productivity', 1),\n",
       "  ('raid', 1),\n",
       "  ('reach', 1),\n",
       "  ('recover', 1),\n",
       "  ('refusing', 1),\n",
       "  ('rupee', 1),\n",
       "  ('security', 1),\n",
       "  ('seize', 2),\n",
       "  ('shatter', 1),\n",
       "  ('shop', 8),\n",
       "  ('squeeze', 1),\n",
       "  ('stop', 1),\n",
       "  ('streetbuzzapp', 1),\n",
       "  ('term', 1),\n",
       "  ('tight', 1),\n",
       "  ('tion', 2),\n",
       "  ('turboelectric', 1),\n",
       "  ('wane', 2),\n",
       "  ('worth', 2)],\n",
       " [('poor', 1),\n",
       "  ('even', 3),\n",
       "  ('feel', 1),\n",
       "  ('modi', 1),\n",
       "  ('thank', 1),\n",
       "  ('actually', 1),\n",
       "  ('reason', 1),\n",
       "  ('rich', 15),\n",
       "  ('seem', 4),\n",
       "  ('black', 1),\n",
       "  ('day', 1),\n",
       "  ('money', 1),\n",
       "  ('problem', 1),\n",
       "  ('vote', 1),\n",
       "  ('youtube', 1),\n",
       "  ('cash', 1),\n",
       "  ('must', 1),\n",
       "  ('never', 1),\n",
       "  ('stop', 1),\n",
       "  ('basis', 1),\n",
       "  ('corruption', 1),\n",
       "  ('crime', 1),\n",
       "  ('crunchthink', 1),\n",
       "  ('daily', 1),\n",
       "  ('face', 1),\n",
       "  ('hate', 9),\n",
       "  ('necessary', 1),\n",
       "  ('panicked', 1),\n",
       "  ('philosophy', 1),\n",
       "  ('rate', 1),\n",
       "  ('reduction', 1),\n",
       "  ('richest', 1),\n",
       "  ('sole', 1)],\n",
       " [('currency', 1),\n",
       "  ('good', 2),\n",
       "  ('hold', 1),\n",
       "  ('people', 1),\n",
       "  ('show', 1),\n",
       "  ('word', 1),\n",
       "  ('back', 4),\n",
       "  ('even', 1),\n",
       "  ('s', 2),\n",
       "  ('say', 4),\n",
       "  ('fake', 2),\n",
       "  ('terrorist', 3),\n",
       "  ('get', 1),\n",
       "  ('impact', 4),\n",
       "  ('long', 4),\n",
       "  ('medium', 1),\n",
       "  ('much', 1),\n",
       "  ('late', 26),\n",
       "  ('story', 2),\n",
       "  ('cash', 2),\n",
       "  ('time', 2),\n",
       "  ('new', 2),\n",
       "  ('report', 1),\n",
       "  ('rule', 1),\n",
       "  ('ahmedabad', 1),\n",
       "  ('contract', 2),\n",
       "  ('linger', 1),\n",
       "  ('note', 9),\n",
       "  ('old', 1),\n",
       "  ('stop', 1),\n",
       "  ('worth', 2),\n",
       "  ('daily', 22),\n",
       "  ('aim', 1),\n",
       "  ('akhara', 1),\n",
       "  ('ating', 1),\n",
       "  ('ban', 4),\n",
       "  ('come', 3),\n",
       "  ('discontinue', 1),\n",
       "  ('eliminate', 1),\n",
       "  ('governor', 1),\n",
       "  ('job', 1),\n",
       "  ('marriage', 1),\n",
       "  ('news', 1),\n",
       "  ('noteba', 1),\n",
       "  ('police', 1),\n",
       "  ('political', 1),\n",
       "  ('positive', 4),\n",
       "  ('rbi', 1),\n",
       "  ('sanju', 2),\n",
       "  ('waste', 2)],\n",
       " [('parliament', 1),\n",
       "  ('impact', 1),\n",
       "  ('question', 2),\n",
       "  ('chillifl', 1),\n",
       "  ('detaiend', 2),\n",
       "  ('station', 2)],\n",
       " [('take', 1),\n",
       "  ('first', 4),\n",
       "  ('modi', 4),\n",
       "  ('survey', 1),\n",
       "  ('get', 5),\n",
       "  ('give', 1),\n",
       "  ('ask', 1),\n",
       "  ('part', 1),\n",
       "  ('bail', 4),\n",
       "  ('thing', 1),\n",
       "  ('hand', 1),\n",
       "  ('input', 1),\n",
       "  ('loan', 4),\n",
       "  ('mallyas', 7),\n",
       "  ('none', 1),\n",
       "  ('purpose', 1),\n",
       "  ('trip', 1),\n",
       "  ('valuable', 1),\n",
       "  ('view', 1),\n",
       "  ('vijaymallya', 1),\n",
       "  ('waive', 4)],\n",
       " [('opposition', 2),\n",
       "  ('do', 2),\n",
       "  ('modi', 1),\n",
       "  ('oppose', 2),\n",
       "  ('stop', 2),\n",
       "  ('ban', 1),\n",
       "  ('none', 2),\n",
       "  ('exactly', 2),\n",
       "  ('pappu', 2)],\n",
       " [('bad', 2),\n",
       "  ('poor', 1),\n",
       "  ('take', 3),\n",
       "  ('even', 1),\n",
       "  ('government', 1),\n",
       "  ('issue', 3),\n",
       "  ('modi', 1),\n",
       "  ('s', 2),\n",
       "  ('actually', 2),\n",
       "  ('really', 1),\n",
       "  ('terrorist', 4),\n",
       "  ('economy', 1),\n",
       "  ('money', 1),\n",
       "  ('would', 1),\n",
       "  ('kill', 2),\n",
       "  ('bypoll', 1),\n",
       "  ('answer', 1),\n",
       "  ('development', 2),\n",
       "  ('farmer', 1),\n",
       "  ('help', 2),\n",
       "  ('become', 3),\n",
       "  ('grow', 4),\n",
       "  ('read', 1),\n",
       "  ('change', 1),\n",
       "  ('note', 2),\n",
       "  ('old', 1),\n",
       "  ('post', 1),\n",
       "  ('term', 1),\n",
       "  ('tight', 1),\n",
       "  ('corruption', 1),\n",
       "  ('governor', 1),\n",
       "  ('news', 5),\n",
       "  ('purpose', 1),\n",
       "  ('accept', 1),\n",
       "  ('argument', 1),\n",
       "  ('assure', 1),\n",
       "  ('big', 1),\n",
       "  ('biggest', 1),\n",
       "  ('cashier', 1),\n",
       "  ('charge', 1),\n",
       "  ('check', 1),\n",
       "  ('clarification', 1),\n",
       "  ('count', 1),\n",
       "  ('coward', 1),\n",
       "  ('demand', 10),\n",
       "  ('democracy', 1),\n",
       "  ('deposit', 1),\n",
       "  ('devinder', 2),\n",
       "  ('doubt', 1),\n",
       "  ('drag', 4),\n",
       "  ('end', 1),\n",
       "  ('ever', 1),\n",
       "  ('exe', 1),\n",
       "  ('exemption', 1),\n",
       "  ('expect', 1),\n",
       "  ('export', 1),\n",
       "  ('fact', 1),\n",
       "  ('failure', 1),\n",
       "  ('fast', 3),\n",
       "  ('fastest', 1),\n",
       "  ('formal', 1),\n",
       "  ('formation', 1),\n",
       "  ('gauravcsawant', 1),\n",
       "  ('geetv', 1),\n",
       "  ('graver', 1),\n",
       "  ('gujaratmodel', 2),\n",
       "  ('hide', 1),\n",
       "  ('high', 1),\n",
       "  ('industry', 2),\n",
       "  ('initiate', 1),\n",
       "  ('laluprasadrjd', 1),\n",
       "  ('last', 1),\n",
       "  ('loot', 2),\n",
       "  ('mehtadarshan', 1),\n",
       "  ('month', 10),\n",
       "  ('nabard', 1),\n",
       "  ('name', 1),\n",
       "  ('nut', 1),\n",
       "  ('oil', 14),\n",
       "  ('outsider', 1),\n",
       "  ('pea', 1),\n",
       "  ('pmoindia', 1),\n",
       "  ('policy', 1),\n",
       "  ('profnkpandey', 1),\n",
       "  ('replace', 1),\n",
       "  ('ruin', 1),\n",
       "  ('scam', 2),\n",
       "  ('selling', 2),\n",
       "  ('shopping', 1),\n",
       "  ('shrink', 10),\n",
       "  ('speak', 1),\n",
       "  ('stonepelte', 2),\n",
       "  ('subverting', 1),\n",
       "  ('summary', 2),\n",
       "  ('tainted', 1),\n",
       "  ('tax', 1),\n",
       "  ('tea', 2),\n",
       "  ('third', 5),\n",
       "  ('title', 2),\n",
       "  ('trustbjp', 2),\n",
       "  ('unethically', 1),\n",
       "  ('water', 1),\n",
       "  ('week', 1),\n",
       "  ('weep', 1),\n",
       "  ('will', 2),\n",
       "  ('windfall', 1),\n",
       "  ('world', 2),\n",
       "  ('worthless', 1),\n",
       "  ('year', 4)],\n",
       " [('advantage', 1),\n",
       "  ('bad', 3),\n",
       "  ('call', 6),\n",
       "  ('decision', 1),\n",
       "  ('make', 1),\n",
       "  ('poor', 8),\n",
       "  ('prove', 1),\n",
       "  ('work', 1),\n",
       "  ('back', 1),\n",
       "  ('could', 3),\n",
       "  ('even', 1),\n",
       "  ('issue', 1),\n",
       "  ('modi', 6),\n",
       "  ('s', 2),\n",
       "  ('see', 1),\n",
       "  ('terrorism', 1),\n",
       "  ('actually', 2),\n",
       "  ('find', 1),\n",
       "  ('look', 1),\n",
       "  ('seem', 1),\n",
       "  ('claim', 2),\n",
       "  ('go', 1),\n",
       "  ('terrorist', 1),\n",
       "  ('economy', 1),\n",
       "  ('get', 1),\n",
       "  ('impact', 10),\n",
       "  ('much', 1),\n",
       "  ('problem', 1),\n",
       "  ('ticket', 1),\n",
       "  ('bitcoin', 1),\n",
       "  ('public', 1),\n",
       "  ('there', 2),\n",
       "  ('wave', 1),\n",
       "  ('cut', 1),\n",
       "  ('story', 1),\n",
       "  ('help', 3),\n",
       "  ('way', 1),\n",
       "  ('appear', 1),\n",
       "  ('system', 1),\n",
       "  ('banking', 1),\n",
       "  ('food', 1),\n",
       "  ('read', 1),\n",
       "  ('use', 1),\n",
       "  ('worker', 1),\n",
       "  ('rule', 2),\n",
       "  ('force', 1),\n",
       "  ('mean', 1),\n",
       "  ('post', 1),\n",
       "  ('big', 1),\n",
       "  ('loot', 1),\n",
       "  ('policy', 6),\n",
       "  ('tax', 1),\n",
       "  ('will', 1),\n",
       "  ('accelerate', 1),\n",
       "  ('adverse', 1),\n",
       "  ('atrout', 2),\n",
       "  ('baddebt', 1),\n",
       "  ('beat', 1),\n",
       "  ('callo', 1),\n",
       "  ('circumvent', 1),\n",
       "  ('cite', 1),\n",
       "  ('coat', 1),\n",
       "  ('country', 1),\n",
       "  ('crisis', 2),\n",
       "  ('deal', 1),\n",
       "  ('dictate', 1),\n",
       "  ('digital', 1),\n",
       "  ('digitization', 1),\n",
       "  ('earn', 1),\n",
       "  ('evident', 1),\n",
       "  ('execution', 1),\n",
       "  ('exercise', 1),\n",
       "  ('expand', 2),\n",
       "  ('fintech', 1),\n",
       "  ('fire', 1),\n",
       "  ('foreign', 2),\n",
       "  ('funding', 1),\n",
       "  ('happen', 2),\n",
       "  ('historically', 1),\n",
       "  ('homework', 1),\n",
       "  ('idea', 1),\n",
       "  ('impunity', 2),\n",
       "  ('ingenuity', 1),\n",
       "  ('jewellery', 1),\n",
       "  ('license', 1),\n",
       "  ('literate', 1),\n",
       "  ('love', 2),\n",
       "  ('mashable', 1),\n",
       "  ('memeghnad', 1),\n",
       "  ('modis', 1),\n",
       "  ('negative', 6),\n",
       "  ('net', 3),\n",
       "  ('ntvtelugu', 1),\n",
       "  ('number', 1),\n",
       "  ('outflow', 2),\n",
       "  ('partner', 3),\n",
       "  ('planning', 1),\n",
       "  ('pokhran', 1),\n",
       "  ('poortrade', 2),\n",
       "  ('popularity', 1),\n",
       "  ('pravchak', 1),\n",
       "  ('pricey', 1),\n",
       "  ('print', 1),\n",
       "  ('propaganda', 1),\n",
       "  ('puppet', 2),\n",
       "  ('quality', 1),\n",
       "  ('remonetize', 1),\n",
       "  ('return', 1),\n",
       "  ('rig', 2),\n",
       "  ('seriously', 1),\n",
       "  ('stocksbond', 2),\n",
       "  ('stupidosaur', 1),\n",
       "  ('sudden', 1),\n",
       "  ('suppose', 1),\n",
       "  ('terror', 1),\n",
       "  ('thereal', 2),\n",
       "  ('timeline', 1),\n",
       "  ('tragic', 1),\n",
       "  ('turn', 1),\n",
       "  ('unicornisland', 1),\n",
       "  ('vikramreuter', 1),\n",
       "  ('vision', 1),\n",
       "  ('voucher', 1),\n",
       "  ('wake', 1)],\n",
       " [('economic', 3),\n",
       "  ('go', 3),\n",
       "  ('impact', 4),\n",
       "  ('political', 3),\n",
       "  ('positive', 3),\n",
       "  ('elec', 1),\n",
       "  ('electora', 1),\n",
       "  ('electoral', 1),\n",
       "  ('far', 3),\n",
       "  ('overwhelming', 3),\n",
       "  ('suspect', 3)],\n",
       " [('leader', 1),\n",
       "  ('make', 5),\n",
       "  ('people', 1),\n",
       "  ('video', 13),\n",
       "  ('find', 3),\n",
       "  ('go', 1),\n",
       "  ('tomorrow', 3),\n",
       "  ('ask', 1),\n",
       "  ('know', 2),\n",
       "  ('celebrate', 1),\n",
       "  ('hilarious', 9),\n",
       "  ('new', 1),\n",
       "  ('watch', 16),\n",
       "  ('must', 4),\n",
       "  ('praise', 1),\n",
       "  ('read', 3),\n",
       "  ('cgdev', 1),\n",
       "  ('debate', 2),\n",
       "  ('dna', 1),\n",
       "  ('epic', 1),\n",
       "  ('excite', 1),\n",
       "  ('interview', 1),\n",
       "  ('punch', 1),\n",
       "  ('react', 1),\n",
       "  ('snatch', 1),\n",
       "  ('stage', 1),\n",
       "  ('subtitle', 3),\n",
       "  ('themehulpatel', 1),\n",
       "  ('trailer', 5),\n",
       "  ('undoomed', 1)],\n",
       " [('good', 1),\n",
       "  ('make', 1),\n",
       "  ('people', 4),\n",
       "  ('back', 3),\n",
       "  ('could', 1),\n",
       "  ('issue', 1),\n",
       "  ('see', 2),\n",
       "  ('economy', 1),\n",
       "  ('money', 1),\n",
       "  ('think', 2),\n",
       "  ('thought', 1),\n",
       "  ('effect', 1),\n",
       "  ('youtube', 1),\n",
       "  ('lose', 2),\n",
       "  ('grow', 1),\n",
       "  ('purpose', 1),\n",
       "  ('achieve', 1),\n",
       "  ('age', 2),\n",
       "  ('cooperatio', 1),\n",
       "  ('gajeraakshay', 1),\n",
       "  ('glvmi', 2),\n",
       "  ('msem', 1),\n",
       "  ('power', 1),\n",
       "  ('powerbut', 1),\n",
       "  ('purchase', 2),\n",
       "  ('roflgandhi', 1),\n",
       "  ('try', 1),\n",
       "  ('withmeaa', 1)],\n",
       " [('man', 1),\n",
       "  ('poor', 1),\n",
       "  ('ban', 1),\n",
       "  ('will', 1),\n",
       "  ('love', 1),\n",
       "  ('keep', 1),\n",
       "  ('prohibition', 1),\n",
       "  ('quiet', 1)],\n",
       " [('may', 2),\n",
       "  ('look', 3),\n",
       "  ('black', 1),\n",
       "  ('get', 1),\n",
       "  ('money', 1),\n",
       "  ('shortage', 11),\n",
       "  ('fund', 9),\n",
       "  ('mean', 1),\n",
       "  ('come', 2),\n",
       "  ('purpose', 1),\n",
       "  ('end', 9),\n",
       "  ('crisis', 4),\n",
       "  ('ahead', 9),\n",
       "  ('barbarindian', 1),\n",
       "  ('bark', 1),\n",
       "  ('continue', 2),\n",
       "  ('cross', 2),\n",
       "  ('daughter', 9),\n",
       "  ('dire', 2),\n",
       "  ('finger', 2),\n",
       "  ('gujarat', 2),\n",
       "  ('liquidity', 2),\n",
       "  ('lzylion', 1),\n",
       "  ('moron', 1),\n",
       "  ('reconfigure', 2),\n",
       "  ('serve', 1),\n",
       "  ('severe', 2),\n",
       "  ('shave', 1),\n",
       "  ('terro', 1),\n",
       "  ('useless', 1),\n",
       "  ('wedding', 2)],\n",
       " [('people', 7),\n",
       "  ('day', 1),\n",
       "  ('get', 3),\n",
       "  ('vote', 3),\n",
       "  ('yet', 1),\n",
       "  ('face', 1),\n",
       "  ('ban', 1),\n",
       "  ('deposit', 1),\n",
       "  ('behave', 1),\n",
       "  ('hari', 1),\n",
       "  ('pig', 1),\n",
       "  ('stunt', 3),\n",
       "  ('tribal', 1),\n",
       "  ('ugly', 1)],\n",
       " [('say', 1),\n",
       "  ('effect', 3),\n",
       "  ('watch', 2),\n",
       "  ('come', 6),\n",
       "  ('keep', 2),\n",
       "  ('batch', 2),\n",
       "  ('dipendradipzo', 1),\n",
       "  ('early', 1),\n",
       "  ('maoist', 2),\n",
       "  ('mass', 1),\n",
       "  ('naxal', 1),\n",
       "  ('nomoneyyaar', 3),\n",
       "  ('surrender', 1)],\n",
       " [('say', 2),\n",
       "  ('much', 2),\n",
       "  ('part', 2),\n",
       "  ('explain', 5),\n",
       "  ('can', 1),\n",
       "  ('come', 2),\n",
       "  ('modis', 1),\n",
       "  ('bibi', 3),\n",
       "  ('conclusion', 2),\n",
       "  ('contemplation', 2),\n",
       "  ('monumental', 2),\n",
       "  ('stupidity', 1),\n",
       "  ('well', 1)],\n",
       " [('economy', 1),\n",
       "  ('would', 1),\n",
       "  ('effect', 20),\n",
       "  ('exclusive', 1),\n",
       "  ('price', 2),\n",
       "  ('read', 2),\n",
       "  ('rise', 1),\n",
       "  ('contract', 5),\n",
       "  ('security', 1),\n",
       "  ('trustbjp', 1),\n",
       "  ('naxal', 4),\n",
       "  ('surrender', 4),\n",
       "  ('child', 1),\n",
       "  ('compromise', 1),\n",
       "  ('consumer', 5),\n",
       "  ('double', 5),\n",
       "  ('gather', 1),\n",
       "  ('ill', 1),\n",
       "  ('index', 7),\n",
       "  ('industrial', 5),\n",
       "  ('intelligence', 1),\n",
       "  ('mahcongress', 1),\n",
       "  ('modimagic', 1),\n",
       "  ('national', 1),\n",
       "  ('production', 5),\n",
       "  ('realeste', 1),\n",
       "  ('talk', 1)],\n",
       " [('people', 1),\n",
       "  ('seem', 1),\n",
       "  ('day', 1),\n",
       "  ('due', 1),\n",
       "  ('get', 1),\n",
       "  ('know', 1),\n",
       "  ('crime', 1),\n",
       "  ('none', 1),\n",
       "  ('commit', 1),\n",
       "  ('profit', 1)],\n",
       " [('support', 2),\n",
       "  ('survey', 2),\n",
       "  ('result', 2),\n",
       "  ('note', 2),\n",
       "  ('far', 2),\n",
       "  ('aha', 1)],\n",
       " [('opposition', 4),\n",
       "  ('get', 3),\n",
       "  ('join', 3),\n",
       "  ('address', 1),\n",
       "  ('shashitharoor', 1),\n",
       "  ('line', 4),\n",
       "  ('rbi', 2),\n",
       "  ('demand', 3),\n",
       "  ('consider', 1),\n",
       "  ('demonstrate', 4),\n",
       "  ('joined', 1),\n",
       "  ('parliame', 1),\n",
       "  ('solidarity', 3),\n",
       "  ('uid', 1),\n",
       "  ('update', 4)],\n",
       " [('thank', 4),\n",
       "  ('retweete', 1),\n",
       "  ('thing', 1),\n",
       "  ('drshobha', 1),\n",
       "  ('happiness', 4),\n",
       "  ('lesson', 1),\n",
       "  ('minimalism', 1),\n",
       "  ('needful', 1),\n",
       "  ('shobha', 1),\n",
       "  ('stuff', 4),\n",
       "  ('teach', 3)],\n",
       " [('bad', 2),\n",
       "  ('banerjee', 2),\n",
       "  ('bjp', 2),\n",
       "  ('decision', 1),\n",
       "  ('economic', 3),\n",
       "  ('election', 1),\n",
       "  ('global', 2),\n",
       "  ('good', 15),\n",
       "  ('make', 4),\n",
       "  ('move', 2),\n",
       "  ('narendramodi', 1),\n",
       "  ('party', 2),\n",
       "  ('people', 11),\n",
       "  ('put', 1),\n",
       "  ('support', 4),\n",
       "  ('video', 1),\n",
       "  ('back', 2),\n",
       "  ('do', 2),\n",
       "  ('huge', 1),\n",
       "  ('incredible', 1),\n",
       "  ('modi', 3),\n",
       "  ('say', 1),\n",
       "  ('reason', 1),\n",
       "  ('rich', 2),\n",
       "  ('survey', 2),\n",
       "  ('affect', 1),\n",
       "  ('black', 5),\n",
       "  ('day', 3),\n",
       "  ('die', 1),\n",
       "  ('due', 1),\n",
       "  ('money', 12),\n",
       "  ('protest', 1),\n",
       "  ('save', 1),\n",
       "  ('think', 2),\n",
       "  ('join', 1),\n",
       "  ('ask', 1),\n",
       "  ('know', 1),\n",
       "  ('still', 2),\n",
       "  ('run', 1),\n",
       "  ('lose', 1),\n",
       "  ('new', 1),\n",
       "  ('way', 1),\n",
       "  ('thing', 2),\n",
       "  ('can', 4),\n",
       "  ('stop', 3),\n",
       "  ('corruption', 2),\n",
       "  ('face', 1),\n",
       "  ('hate', 1),\n",
       "  ('come', 1),\n",
       "  ('accept', 2),\n",
       "  ('country', 2),\n",
       "  ('digital', 1),\n",
       "  ('happen', 3),\n",
       "  ('well', 1),\n",
       "  ('absolutely', 1),\n",
       "  ('action', 6),\n",
       "  ('allow', 2),\n",
       "  ('anilkohli', 1),\n",
       "  ('away', 1),\n",
       "  ('bae', 1),\n",
       "  ('be', 1),\n",
       "  ('believe', 8),\n",
       "  ('builder', 1),\n",
       "  ('comment', 2),\n",
       "  ('common', 1),\n",
       "  ('confident', 1),\n",
       "  ('demoralize', 1),\n",
       "  ('dust', 2),\n",
       "  ('eauct', 1),\n",
       "  ('eauction', 1),\n",
       "  ('elite', 2),\n",
       "  ('execut', 1),\n",
       "  ('fellow', 1),\n",
       "  ('fix', 1),\n",
       "  ('great', 1),\n",
       "  ('home', 2),\n",
       "  ('iamyudhvir', 1),\n",
       "  ('important', 1),\n",
       "  ('incur', 1),\n",
       "  ('live', 2),\n",
       "  ('lol', 1),\n",
       "  ('lolwa', 1),\n",
       "  ('loss', 1),\n",
       "  ('lot', 1),\n",
       "  ('massacre', 1),\n",
       "  ('naidu', 1),\n",
       "  ('northeastern', 1),\n",
       "  ('openly', 2),\n",
       "  ('piyushgoyal', 1),\n",
       "  ('plan', 1),\n",
       "  ('politicsit', 3),\n",
       "  ('racism', 1),\n",
       "  ('reflect', 3),\n",
       "  ('scheme', 1),\n",
       "  ('sir', 1),\n",
       "  ('sorry', 2),\n",
       "  ('source', 1),\n",
       "  ('stone', 1),\n",
       "  ('supported', 2),\n",
       "  ('tjain', 1),\n",
       "  ('training', 1),\n",
       "  ('transaction', 1),\n",
       "  ('transparent', 3),\n",
       "  ('true', 1),\n",
       "  ('upcome', 1),\n",
       "  ('warming', 1)],\n",
       " [('bjp', 1),\n",
       "  ('decision', 2),\n",
       "  ('move', 1),\n",
       "  ('nation', 2),\n",
       "  ('party', 1),\n",
       "  ('people', 16),\n",
       "  ('politic', 2),\n",
       "  ('poor', 4),\n",
       "  ('prove', 3),\n",
       "  ('show', 1),\n",
       "  ('support', 7),\n",
       "  ('back', 2),\n",
       "  ('even', 1),\n",
       "  ('benefit', 1),\n",
       "  ('black', 1),\n",
       "  ('due', 1),\n",
       "  ('get', 2),\n",
       "  ('give', 4),\n",
       "  ('money', 4),\n",
       "  ('pay', 1),\n",
       "  ('think', 1),\n",
       "  ('bypoll', 2),\n",
       "  ('seat', 2),\n",
       "  ('tell', 1),\n",
       "  ('wait', 1),\n",
       "  ('poll', 1),\n",
       "  ('come', 1),\n",
       "  ('accept', 1),\n",
       "  ('check', 2),\n",
       "  ('gujarat', 1),\n",
       "  ('loss', 1),\n",
       "  ('building', 1),\n",
       "  ('business', 1),\n",
       "  ('byelection', 2),\n",
       "  ('cost', 1),\n",
       "  ('death', 2),\n",
       "  ('eagerly', 1),\n",
       "  ('equal', 1),\n",
       "  ('farmhouse', 1),\n",
       "  ('have', 1),\n",
       "  ('insist', 2),\n",
       "  ('ippatel', 1),\n",
       "  ('itsbollylive', 1),\n",
       "  ('knowcommon', 1),\n",
       "  ('neutralized', 1),\n",
       "  ('overlook', 1),\n",
       "  ('receive', 1),\n",
       "  ('regional', 1),\n",
       "  ('rescue', 1),\n",
       "  ('retain', 3),\n",
       "  ('shortsighted', 1),\n",
       "  ('state', 1),\n",
       "  ('unbiase', 1)],\n",
       " [('ask', 2), ('time', 2), ('check', 2)],\n",
       " [('need', 2),\n",
       "  ('think', 2),\n",
       "  ('hour', 2),\n",
       "  ('indeed', 2),\n",
       "  ('ahead', 2),\n",
       "  ('initiative', 1),\n",
       "  ('lifeinsurance', 1),\n",
       "  ('secure', 1),\n",
       "  ('wise', 2)],\n",
       " [('benefit', 2),\n",
       "  ('day', 4),\n",
       "  ('note', 1),\n",
       "  ('exactly', 3),\n",
       "  ('argument', 4),\n",
       "  ('evident', 4),\n",
       "  ('memeghnad', 1),\n",
       "  ('announcement', 7),\n",
       "  ('bury', 2),\n",
       "  ('convenientl', 1),\n",
       "  ('heritage', 4),\n",
       "  ('jamewil', 1),\n",
       "  ('knowledge', 1),\n",
       "  ('ncbn', 4),\n",
       "  ('potential', 2),\n",
       "  ('prior', 2),\n",
       "  ('remind', 2),\n",
       "  ('sell', 4),\n",
       "  ('sharesclearly', 4),\n",
       "  ('withdraw', 1),\n",
       "  ('ysrcpfriend', 1)],\n",
       " [('poor', 35),\n",
       "  ('support', 1),\n",
       "  ('even', 1),\n",
       "  ('implement', 31),\n",
       "  ('modi', 20),\n",
       "  ('say', 1),\n",
       "  ('see', 2),\n",
       "  ('actually', 34),\n",
       "  ('dear', 20),\n",
       "  ('find', 34),\n",
       "  ('rich', 2),\n",
       "  ('snapchatceo', 2),\n",
       "  ('spiegel', 2),\n",
       "  ('terrorist', 1),\n",
       "  ('indian', 1),\n",
       "  ('necessary', 1),\n",
       "  ('failure', 1),\n",
       "  ('homework', 1),\n",
       "  ('apply', 1),\n",
       "  ('awkward', 1),\n",
       "  ('boy', 1),\n",
       "  ('copy', 1),\n",
       "  ('evanspiegal', 2),\n",
       "  ('evanspiegel', 1),\n",
       "  ('gareeb', 2),\n",
       "  ('hat', 1),\n",
       "  ('local', 1),\n",
       "  ('moment', 1),\n",
       "  ('point', 1),\n",
       "  ('sign', 2),\n",
       "  ('snapchat', 9),\n",
       "  ('swarajya', 1)],\n",
       " [('even', 1),\n",
       "  ('find', 1),\n",
       "  ('necessary', 1),\n",
       "  ('awkward', 1),\n",
       "  ('moment', 1),\n",
       "  ('point', 1),\n",
       "  ('swarajya', 1)],\n",
       " [],\n",
       " [('people', 2),\n",
       "  ('poor', 1),\n",
       "  ('take', 1),\n",
       "  ('really', 1),\n",
       "  ('get', 2),\n",
       "  ('hard', 1),\n",
       "  ('vote', 3),\n",
       "  ('want', 3),\n",
       "  ('app', 1),\n",
       "  ('bypoll', 2),\n",
       "  ('try', 1),\n",
       "  ('update', 1),\n",
       "  ('avoid', 1),\n",
       "  ('boldly', 1),\n",
       "  ('cashcrunch', 1),\n",
       "  ('cpiml', 1),\n",
       "  ('hardship', 2),\n",
       "  ('hurt', 1),\n",
       "  ('indifferent', 3),\n",
       "  ('misery', 3),\n",
       "  ('mount', 3),\n",
       "  ('pleasantly', 1),\n",
       "  ('surprise', 1),\n",
       "  ('totally', 3)],\n",
       " [('goldenarcher', 1)],\n",
       " [('put', 6), ('time', 4), ('write', 6), ('come', 6), ('action', 6)],\n",
       " [('call', 1),\n",
       "  ('currency', 1),\n",
       "  ('take', 4),\n",
       "  ('issue', 3),\n",
       "  ('modi', 1),\n",
       "  ('say', 3),\n",
       "  ('see', 1),\n",
       "  ('actual', 1),\n",
       "  ('article', 1),\n",
       "  ('affect', 2),\n",
       "  ('economy', 2),\n",
       "  ('money', 2),\n",
       "  ('vote', 1),\n",
       "  ('result', 1),\n",
       "  ('today', 1),\n",
       "  ('effect', 1),\n",
       "  ('answer', 1),\n",
       "  ('become', 2),\n",
       "  ('bank', 3),\n",
       "  ('grow', 1),\n",
       "  ('must', 3),\n",
       "  ('use', 2),\n",
       "  ('write', 1),\n",
       "  ('wait', 1),\n",
       "  ('announce', 2),\n",
       "  ('askanshul', 1),\n",
       "  ('can', 2),\n",
       "  ('finance', 1),\n",
       "  ('follow', 1),\n",
       "  ('launch', 1),\n",
       "  ('note', 8),\n",
       "  ('daily', 2),\n",
       "  ('big', 2),\n",
       "  ('replace', 1),\n",
       "  ('world', 1),\n",
       "  ('modis', 2),\n",
       "  ('print', 1),\n",
       "  ('return', 1),\n",
       "  ('purchase', 2),\n",
       "  ('keep', 1),\n",
       "  ('anymore', 1),\n",
       "  ('bag', 2),\n",
       "  ('card', 1),\n",
       "  ('cheat', 2),\n",
       "  ('confronted', 1),\n",
       "  ('credit', 1),\n",
       "  ('discard', 1),\n",
       "  ('engineering', 2),\n",
       "  ('escalation', 1),\n",
       "  ('exempt', 1),\n",
       "  ('focus', 1),\n",
       "  ('frustindian', 1),\n",
       "  ('governance', 2),\n",
       "  ('grand', 2),\n",
       "  ('gsailaja', 1),\n",
       "  ('impose', 1),\n",
       "  ('indusind', 1),\n",
       "  ('inspire', 1),\n",
       "  ('involve', 1),\n",
       "  ('involved', 1),\n",
       "  ('living', 2),\n",
       "  ('mahikainfra', 1),\n",
       "  ('minister', 1),\n",
       "  ('nifty', 1),\n",
       "  ('pathetic', 2),\n",
       "  ('quarterly', 1),\n",
       "  ('rat', 1),\n",
       "  ('responsible', 2),\n",
       "  ('reward', 2),\n",
       "  ('routine', 1),\n",
       "  ('sanghis', 1),\n",
       "  ('side', 2),\n",
       "  ('success', 2),\n",
       "  ('traveler', 2)],\n",
       " [('advantage', 1),\n",
       "  ('economic', 2),\n",
       "  ('article', 1),\n",
       "  ('impact', 7),\n",
       "  ('long', 2),\n",
       "  ('story', 1),\n",
       "  ('cash', 1),\n",
       "  ('new', 1),\n",
       "  ('payment', 6),\n",
       "  ('note', 2),\n",
       "  ('shop', 1),\n",
       "  ('term', 2),\n",
       "  ('ban', 2),\n",
       "  ('positive', 8),\n",
       "  ('digital', 6),\n",
       "  ('fire', 1),\n",
       "  ('return', 1),\n",
       "  ('lot', 1),\n",
       "  ('adopter', 1),\n",
       "  ('analysis', 1),\n",
       "  ('deployment', 5),\n",
       "  ('discover', 1),\n",
       "  ('dmonetisation', 2),\n",
       "  ('executive', 1),\n",
       "  ('http', 1),\n",
       "  ('lead', 5),\n",
       "  ('quietly', 1),\n",
       "  ('sale', 1),\n",
       "  ('showroom', 1),\n",
       "  ('small', 1),\n",
       "  ('start', 1),\n",
       "  ('swift', 5),\n",
       "  ('technology', 5),\n",
       "  ('top', 1),\n",
       "  ('worldbank', 5)],\n",
       " [('get', 4),\n",
       "  ('know', 2),\n",
       "  ('paytm', 2),\n",
       "  ('add', 1),\n",
       "  ('input', 1),\n",
       "  ('aartic', 1),\n",
       "  ('goodness', 1),\n",
       "  ('yiayhaiku', 1)],\n",
       " [('bjp', 1),\n",
       "  ('economic', 1),\n",
       "  ('election', 1),\n",
       "  ('global', 1),\n",
       "  ('however', 2),\n",
       "  ('make', 4),\n",
       "  ('may', 2),\n",
       "  ('need', 2),\n",
       "  ('show', 1),\n",
       "  ('issue', 2),\n",
       "  ('oppose', 3),\n",
       "  ('article', 1),\n",
       "  ('benefit', 2),\n",
       "  ('fake', 1),\n",
       "  ('go', 1),\n",
       "  ('black', 2),\n",
       "  ('economy', 7),\n",
       "  ('impact', 26),\n",
       "  ('indian', 6),\n",
       "  ('long', 8),\n",
       "  ('much', 1),\n",
       "  ('pay', 1),\n",
       "  ('release', 2),\n",
       "  ('short', 5),\n",
       "  ('boom', 1),\n",
       "  ('decide', 1),\n",
       "  ('future', 2),\n",
       "  ('effect', 5),\n",
       "  ('hear', 5),\n",
       "  ('cut', 1),\n",
       "  ('phone', 1),\n",
       "  ('help', 1),\n",
       "  ('cash', 2),\n",
       "  ('mode', 3),\n",
       "  ('system', 1),\n",
       "  ('banking', 4),\n",
       "  ('education', 2),\n",
       "  ('fall', 3),\n",
       "  ('food', 18),\n",
       "  ('must', 1),\n",
       "  ('online', 7),\n",
       "  ('overall', 1),\n",
       "  ('payment', 32),\n",
       "  ('service', 13),\n",
       "  ('set', 2),\n",
       "  ('use', 4),\n",
       "  ('report', 1),\n",
       "  ('announce', 1),\n",
       "  ('datum', 1),\n",
       "  ('finance', 1),\n",
       "  ('follow', 2),\n",
       "  ('increase', 14),\n",
       "  ('line', 1),\n",
       "  ('post', 1),\n",
       "  ('term', 8),\n",
       "  ('corruption', 1),\n",
       "  ('news', 2),\n",
       "  ('political', 1),\n",
       "  ('positive', 2),\n",
       "  ('none', 1),\n",
       "  ('purpose', 1),\n",
       "  ('view', 1),\n",
       "  ('waive', 6),\n",
       "  ('big', 4),\n",
       "  ('charge', 14),\n",
       "  ('check', 2),\n",
       "  ('demand', 1),\n",
       "  ('last', 4),\n",
       "  ('month', 3),\n",
       "  ('oil', 1),\n",
       "  ('speak', 2),\n",
       "  ('summary', 2),\n",
       "  ('tax', 2),\n",
       "  ('week', 1),\n",
       "  ('cite', 4),\n",
       "  ('digital', 39),\n",
       "  ('expand', 1),\n",
       "  ('idea', 1),\n",
       "  ('negative', 2),\n",
       "  ('partner', 12),\n",
       "  ('turn', 21),\n",
       "  ('vision', 9),\n",
       "  ('voucher', 18),\n",
       "  ('index', 2),\n",
       "  ('production', 1),\n",
       "  ('update', 2),\n",
       "  ('loss', 1),\n",
       "  ('plan', 4),\n",
       "  ('source', 1),\n",
       "  ('transaction', 21),\n",
       "  ('cost', 1),\n",
       "  ('initiative', 1),\n",
       "  ('withdraw', 2),\n",
       "  ('point', 5),\n",
       "  ('card', 3),\n",
       "  ('credit', 2),\n",
       "  ('lead', 1),\n",
       "  ('sale', 1),\n",
       "  ('start', 1),\n",
       "  ('aamaadmiparty', 1),\n",
       "  ('abhishantpant', 1),\n",
       "  ('adversely', 1),\n",
       "  ('advise', 3),\n",
       "  ('agriculture', 1),\n",
       "  ('aka', 1),\n",
       "  ('annual', 4),\n",
       "  ('arrest', 1),\n",
       "  ('ashokepandit', 1),\n",
       "  ('ass', 1),\n",
       "  ('assetclasse', 1),\n",
       "  ('audit', 1),\n",
       "  ('base', 1),\n",
       "  ('beinghindu', 1),\n",
       "  ('bijonmehta', 1),\n",
       "  ('bitcoinagile', 2),\n",
       "  ('booking', 2),\n",
       "  ('bring', 1),\n",
       "  ('broking', 1),\n",
       "  ('cag', 1),\n",
       "  ('calc', 1),\n",
       "  ('cashless', 3),\n",
       "  ('catalyze', 21),\n",
       "  ('chargesis', 1),\n",
       "  ('cnnnew', 1),\n",
       "  ('compliance', 2),\n",
       "  ('corruptio', 1),\n",
       "  ('decline', 1),\n",
       "  ('deduct', 1),\n",
       "  ('dent', 2),\n",
       "  ('design', 1),\n",
       "  ('dramatic', 1),\n",
       "  ('drive', 1),\n",
       "  ('earning', 1),\n",
       "  ('ease', 1),\n",
       "  ('electronic', 1),\n",
       "  ('encourage', 1),\n",
       "  ('engine', 1),\n",
       "  ('event', 2),\n",
       "  ('expansion', 1),\n",
       "  ('experience', 2),\n",
       "  ('expert', 2),\n",
       "  ('fitch', 1),\n",
       "  ('fold', 13),\n",
       "  ('footprint', 1),\n",
       "  ('forecast', 4),\n",
       "  ('gdp', 1),\n",
       "  ('growth', 31),\n",
       "  ('guise', 1),\n",
       "  ('half', 1),\n",
       "  ('hav', 1),\n",
       "  ('hypermarket', 2),\n",
       "  ('improve', 2),\n",
       "  ('incentivize', 1),\n",
       "  ('incl', 1),\n",
       "  ('incompetent', 1),\n",
       "  ('inflation', 1),\n",
       "  ('insurance', 1),\n",
       "  ('investment', 1),\n",
       "  ('jump', 1),\n",
       "  ('ldrs', 1),\n",
       "  ('lie', 1),\n",
       "  ('manufacturing', 1),\n",
       "  ('meaning', 1),\n",
       "  ('measure', 1),\n",
       "  ('merely', 2),\n",
       "  ('method', 1),\n",
       "  ('miracle', 1),\n",
       "  ('misadventure', 1),\n",
       "  ('mobile', 5),\n",
       "  ('mobilebanke', 2),\n",
       "  ('mobilebanking', 1),\n",
       "  ('monetary', 1),\n",
       "  ('monie', 2),\n",
       "  ('offer', 2),\n",
       "  ('opportunity', 2),\n",
       "  ('organize', 3),\n",
       "  ('overcome', 1),\n",
       "  ('own', 2),\n",
       "  ('pain', 1),\n",
       "  ('percentage', 1),\n",
       "  ('period', 2),\n",
       "  ('perspective', 2),\n",
       "  ('pick', 2),\n",
       "  ('pmi', 1),\n",
       "  ('pocket', 1),\n",
       "  ('pocketing', 1),\n",
       "  ('pritheworld', 1),\n",
       "  ('profile', 1),\n",
       "  ('railway', 2),\n",
       "  ('reduce', 1),\n",
       "  ('request', 1),\n",
       "  ('retail', 3),\n",
       "  ('round', 5),\n",
       "  ('rsprasad', 1),\n",
       "  ('seasonal', 1),\n",
       "  ('sffe', 2),\n",
       "  ('shortlive', 1),\n",
       "  ('shr', 1),\n",
       "  ('slay', 1),\n",
       "  ('slide', 2),\n",
       "  ('slow', 3),\n",
       "  ('soon', 2),\n",
       "  ('sponge', 1),\n",
       "  ('steeply', 2),\n",
       "  ('stock', 1),\n",
       "  ('strengthen', 1),\n",
       "  ('summer', 2),\n",
       "  ('supermarket', 2),\n",
       "  ('surjitbhalla', 2),\n",
       "  ('swapout', 1),\n",
       "  ('swrpa', 1),\n",
       "  ('table', 5),\n",
       "  ('tata', 1),\n",
       "  ('travel', 2),\n",
       "  ('trim', 4),\n",
       "  ('trrst', 1),\n",
       "  ('truethen', 1),\n",
       "  ('unedited', 2),\n",
       "  ('unplanned', 1),\n",
       "  ('usage', 1),\n",
       "  ('vacation', 2),\n",
       "  ('various', 1),\n",
       "  ('vast', 2)],\n",
       " [('bjp', 1),\n",
       "  ('decision', 2),\n",
       "  ('nation', 2),\n",
       "  ('people', 4),\n",
       "  ('show', 1),\n",
       "  ('support', 5),\n",
       "  ('take', 2),\n",
       "  ('first', 2),\n",
       "  ('happy', 1),\n",
       "  ('honest', 1),\n",
       "  ('modi', 4),\n",
       "  ('see', 2),\n",
       "  ('thank', 1),\n",
       "  ('also', 1),\n",
       "  ('survey', 4),\n",
       "  ('win', 1),\n",
       "  ('get', 2),\n",
       "  ('give', 1),\n",
       "  ('money', 1),\n",
       "  ('tweet', 2),\n",
       "  ('vote', 1),\n",
       "  ('cgdtalk', 2),\n",
       "  ('want', 5),\n",
       "  ('blow', 1),\n",
       "  ('opinion', 1),\n",
       "  ('response', 1),\n",
       "  ('result', 1),\n",
       "  ('successful', 1),\n",
       "  ('there', 1),\n",
       "  ('wave', 2),\n",
       "  ('still', 2),\n",
       "  ('answer', 2),\n",
       "  ('question', 6),\n",
       "  ('help', 1),\n",
       "  ('young', 1),\n",
       "  ('add', 1),\n",
       "  ('fall', 1),\n",
       "  ('use', 2),\n",
       "  ('participate', 2),\n",
       "  ('poll', 3),\n",
       "  ('corruption', 1),\n",
       "  ('view', 3),\n",
       "  ('overwhelming', 1),\n",
       "  ('consider', 1),\n",
       "  ('live', 2),\n",
       "  ('top', 1),\n",
       "  ('drive', 1),\n",
       "  ('various', 1),\n",
       "  ('audience', 2),\n",
       "  ('bootlicker', 1),\n",
       "  ('centerofright', 1),\n",
       "  ('conduct', 1),\n",
       "  ('corrupt', 1),\n",
       "  ('declare', 1),\n",
       "  ('disagree', 1),\n",
       "  ('element', 1),\n",
       "  ('exceptional', 1),\n",
       "  ('fantastic', 1),\n",
       "  ('glance', 1),\n",
       "  ('interest', 1),\n",
       "  ('interesting', 2),\n",
       "  ('loksabha', 1),\n",
       "  ('major', 1),\n",
       "  ('narednramodi', 1),\n",
       "  ('neveraever', 1),\n",
       "  ('open', 2),\n",
       "  ('option', 1),\n",
       "  ('perpetrator', 1),\n",
       "  ('pose', 2),\n",
       "  ('raise', 1),\n",
       "  ('recede', 1),\n",
       "  ('reveal', 1),\n",
       "  ('rliament', 1)],\n",
       " [('economic', 1),\n",
       "  ('take', 2),\n",
       "  ('first', 2),\n",
       "  ('modi', 3),\n",
       "  ('say', 8),\n",
       "  ('see', 2),\n",
       "  ('survey', 2),\n",
       "  ('win', 1),\n",
       "  ('affect', 1),\n",
       "  ('medium', 1),\n",
       "  ('much', 1),\n",
       "  ('tweet', 1),\n",
       "  ('opinion', 2),\n",
       "  ('result', 4),\n",
       "  ('share', 2),\n",
       "  ('today', 3),\n",
       "  ('successful', 1),\n",
       "  ('there', 1),\n",
       "  ('know', 1),\n",
       "  ('clearly', 1),\n",
       "  ('late', 1),\n",
       "  ('story', 7),\n",
       "  ('help', 1),\n",
       "  ('new', 1),\n",
       "  ('price', 2),\n",
       "  ('lack', 1),\n",
       "  ('report', 1),\n",
       "  ('note', 3),\n",
       "  ('old', 2),\n",
       "  ('post', 1),\n",
       "  ('recover', 1),\n",
       "  ('ban', 3),\n",
       "  ('world', 2),\n",
       "  ('baddebt', 1),\n",
       "  ('crisis', 1),\n",
       "  ('expand', 1),\n",
       "  ('planning', 1),\n",
       "  ('true', 6),\n",
       "  ('totally', 1),\n",
       "  ('inspire', 6),\n",
       "  ('involve', 2),\n",
       "  ('success', 1),\n",
       "  ('top', 1),\n",
       "  ('arrest', 1),\n",
       "  ('bring', 1),\n",
       "  ('interesting', 1),\n",
       "  ('major', 1),\n",
       "  ('admit', 1),\n",
       "  ('aruproytweet', 1),\n",
       "  ('await', 1),\n",
       "  ('blackmoney', 2),\n",
       "  ('cohesive', 1),\n",
       "  ('crash', 2),\n",
       "  ('differentthe', 1),\n",
       "  ('dmonetization', 1),\n",
       "  ('drama', 1),\n",
       "  ('estate', 2),\n",
       "  ('express', 1),\n",
       "  ('fruit', 1),\n",
       "  ('gang', 1),\n",
       "  ('giant', 1),\n",
       "  ('glare', 1),\n",
       "  ('handedly', 1),\n",
       "  ('market', 2),\n",
       "  ('mostly', 1),\n",
       "  ('notice', 1),\n",
       "  ('politician', 1),\n",
       "  ('possibly', 1),\n",
       "  ('proof', 1),\n",
       "  ('racketeering', 2),\n",
       "  ('real', 2),\n",
       "  ('recession', 1),\n",
       "  ('root', 2),\n",
       "  ('section', 1),\n",
       "  ('sector', 1),\n",
       "  ('singh', 1),\n",
       "  ('single', 1),\n",
       "  ('spin', 2),\n",
       "  ('stockpile', 1),\n",
       "  ('succeed', 1),\n",
       "  ('timeit', 1),\n",
       "  ('tough', 1),\n",
       "  ('ughhh', 1),\n",
       "  ('utha', 2)],\n",
       " [('support', 4), ('oppose', 2), ('uturne', 1)],\n",
       " [('man', 1),\n",
       "  ('respect', 1),\n",
       "  ('due', 1),\n",
       "  ('want', 1),\n",
       "  ('today', 1),\n",
       "  ('parlmnt', 1),\n",
       "  ('full', 1),\n",
       "  ('debate', 1),\n",
       "  ('true', 1),\n",
       "  ('biased', 1),\n",
       "  ('disruption', 1),\n",
       "  ('justice', 1),\n",
       "  ('justify', 1),\n",
       "  ('rajeev', 1),\n",
       "  ('stall', 1)],\n",
       " [('appreciate', 2),\n",
       "  ('call', 3),\n",
       "  ('currency', 11),\n",
       "  ('fun', 1),\n",
       "  ('good', 1),\n",
       "  ('leader', 1),\n",
       "  ('may', 2),\n",
       "  ('move', 2),\n",
       "  ('need', 1),\n",
       "  ('parliament', 1),\n",
       "  ('people', 3),\n",
       "  ('put', 1),\n",
       "  ('support', 1),\n",
       "  ('take', 6),\n",
       "  ('video', 1),\n",
       "  ('work', 1),\n",
       "  ('even', 2),\n",
       "  ('feel', 1),\n",
       "  ('first', 1),\n",
       "  ('government', 3),\n",
       "  ('happy', 1),\n",
       "  ('issue', 2),\n",
       "  ('many', 1),\n",
       "  ('modi', 2),\n",
       "  ('s', 5),\n",
       "  ('say', 3),\n",
       "  ('see', 2),\n",
       "  ('step', 2),\n",
       "  ('thank', 1),\n",
       "  ('article', 2),\n",
       "  ('better', 1),\n",
       "  ('find', 1),\n",
       "  ('look', 1),\n",
       "  ('reason', 1),\n",
       "  ('suffer', 1),\n",
       "  ('claim', 1),\n",
       "  ('go', 8),\n",
       "  ('terrorist', 2),\n",
       "  ('chopsyturvey', 1),\n",
       "  ('day', 3),\n",
       "  ('die', 1),\n",
       "  ('due', 2),\n",
       "  ('economy', 7),\n",
       "  ('get', 13),\n",
       "  ('give', 1),\n",
       "  ('impact', 1),\n",
       "  ('indian', 8),\n",
       "  ('long', 1),\n",
       "  ('money', 5),\n",
       "  ('much', 3),\n",
       "  ('release', 1),\n",
       "  ('save', 1),\n",
       "  ('think', 1),\n",
       "  ('tweet', 1),\n",
       "  ('would', 3),\n",
       "  ('join', 1),\n",
       "  ('public', 1),\n",
       "  ('share', 1),\n",
       "  ('today', 2),\n",
       "  ('fight', 1),\n",
       "  ('hour', 1),\n",
       "  ('retweete', 1),\n",
       "  ('attack', 1),\n",
       "  ('know', 1),\n",
       "  ('still', 5),\n",
       "  ('effect', 6),\n",
       "  ('hear', 2),\n",
       "  ('answer', 1),\n",
       "  ('cut', 3),\n",
       "  ('development', 1),\n",
       "  ('full', 3),\n",
       "  ('late', 6),\n",
       "  ('paytm', 1),\n",
       "  ('question', 2),\n",
       "  ('story', 1),\n",
       "  ('tell', 1),\n",
       "  ('youtube', 1),\n",
       "  ('farmer', 2),\n",
       "  ('help', 9),\n",
       "  ('cash', 2),\n",
       "  ('otherwise', 2),\n",
       "  ('test', 2),\n",
       "  ('become', 2),\n",
       "  ('lose', 1),\n",
       "  ('new', 23),\n",
       "  ('watch', 2),\n",
       "  ('way', 1),\n",
       "  ('system', 1),\n",
       "  ('bank', 7),\n",
       "  ('banking', 1),\n",
       "  ('fall', 1),\n",
       "  ('financial', 1),\n",
       "  ('must', 5),\n",
       "  ('payment', 6),\n",
       "  ('price', 2),\n",
       "  ('read', 5),\n",
       "  ('rise', 1),\n",
       "  ('write', 1),\n",
       "  ('report', 1),\n",
       "  ('shortage', 1),\n",
       "  ('staff', 1),\n",
       "  ('wait', 1),\n",
       "  ('let', 3),\n",
       "  ('rule', 1),\n",
       "  ('thing', 2),\n",
       "  ('can', 2),\n",
       "  ('change', 4),\n",
       "  ('datum', 2),\n",
       "  ('force', 1),\n",
       "  ('increase', 1),\n",
       "  ('line', 2),\n",
       "  ('mean', 2),\n",
       "  ('night', 4),\n",
       "  ('note', 39),\n",
       "  ('old', 20),\n",
       "  ('post', 2),\n",
       "  ('reach', 1),\n",
       "  ('recover', 3),\n",
       "  ('rupee', 1),\n",
       "  ('security', 2),\n",
       "  ('worth', 6),\n",
       "  ('corruption', 1),\n",
       "  ('daily', 4),\n",
       "  ('rate', 1),\n",
       "  ('ban', 2),\n",
       "  ('come', 2),\n",
       "  ('marriage', 1),\n",
       "  ('news', 4),\n",
       "  ('positive', 1),\n",
       "  ('rbi', 3),\n",
       "  ('hand', 1),\n",
       "  ('view', 2),\n",
       "  ('exactly', 1),\n",
       "  ('accept', 1),\n",
       "  ('big', 1),\n",
       "  ('deposit', 3),\n",
       "  ('doubt', 1),\n",
       "  ('ever', 2),\n",
       "  ('export', 1),\n",
       "  ('fast', 1),\n",
       "  ('geetv', 1),\n",
       "  ('high', 4),\n",
       "  ('industry', 1),\n",
       "  ('last', 3),\n",
       "  ('month', 2),\n",
       "  ('name', 1),\n",
       "  ('speak', 1),\n",
       "  ('tax', 1),\n",
       "  ('week', 1),\n",
       "  ('will', 2),\n",
       "  ('world', 1),\n",
       "  ('year', 1),\n",
       "  ('country', 1),\n",
       "  ('digitization', 2),\n",
       "  ('idea', 3),\n",
       "  ('license', 3),\n",
       "  ('negative', 1),\n",
       "  ('print', 6),\n",
       "  ('terror', 2),\n",
       "  ('dna', 1),\n",
       "  ('achieve', 1),\n",
       "  ('keep', 2),\n",
       "  ('continue', 1),\n",
       "  ('liquidity', 1),\n",
       "  ('naxal', 2),\n",
       "  ('well', 8),\n",
       "  ('update', 1),\n",
       "  ('great', 3),\n",
       "  ('important', 1),\n",
       "  ('live', 1),\n",
       "  ('loss', 1),\n",
       "  ('lot', 1),\n",
       "  ('scheme', 1),\n",
       "  ('sir', 2),\n",
       "  ('true', 2),\n",
       "  ('have', 1),\n",
       "  ('receive', 2),\n",
       "  ('announcement', 2),\n",
       "  ('sell', 1),\n",
       "  ('withdraw', 1),\n",
       "  ('hat', 1),\n",
       "  ('focus', 2),\n",
       "  ('analysis', 3),\n",
       "  ('lead', 1),\n",
       "  ('start', 1),\n",
       "  ('arrest', 2),\n",
       "  ('bring', 2),\n",
       "  ('design', 1),\n",
       "  ('ease', 1),\n",
       "  ('improve', 1),\n",
       "  ('incentivize', 2),\n",
       "  ('slay', 2),\n",
       "  ('slow', 2),\n",
       "  ('stock', 1),\n",
       "  ('corrupt', 1),\n",
       "  ('major', 1),\n",
       "  ('market', 1),\n",
       "  ('possibly', 1),\n",
       "  ('real', 1),\n",
       "  ('able', 4),\n",
       "  ('accommodate', 1),\n",
       "  ('account', 2),\n",
       "  ('acquire', 1),\n",
       "  ('act', 1),\n",
       "  ('acute', 1),\n",
       "  ('aftr', 1),\n",
       "  ('ajaymaken', 2),\n",
       "  ('almost', 1),\n",
       "  ('anilrai', 1),\n",
       "  ('approach', 1),\n",
       "  ('area', 1),\n",
       "  ('arrangement', 1),\n",
       "  ('ashokgehlot', 1),\n",
       "  ('asking', 1),\n",
       "  ('atleast', 1),\n",
       "  ('atm', 1),\n",
       "  ('auto', 1),\n",
       "  ('autotodaymag', 1),\n",
       "  ('bangalore', 1),\n",
       "  ('beautiful', 1),\n",
       "  ('best', 1),\n",
       "  ('blog', 1),\n",
       "  ('bose', 1),\n",
       "  ('bother', 1),\n",
       "  ('bra', 1),\n",
       "  ('bullish', 1),\n",
       "  ('buying', 1),\n",
       "  ('calm', 2),\n",
       "  ('caption', 1),\n",
       "  ('carry', 2),\n",
       "  ('cashcrisis', 1),\n",
       "  ('catch', 2),\n",
       "  ('cattle', 1),\n",
       "  ('caution', 1),\n",
       "  ('cheap', 1),\n",
       "  ('clap', 2),\n",
       "  ('clear', 2),\n",
       "  ('clusterfuck', 1),\n",
       "  ('colln', 1),\n",
       "  ('colossal', 1),\n",
       "  ('combat', 2),\n",
       "  ('commodity', 1),\n",
       "  ('compilation', 1),\n",
       "  ('concern', 2),\n",
       "  ('contest', 1),\n",
       "  ('contrary', 1),\n",
       "  ('convert', 2),\n",
       "  ('correction', 3),\n",
       "  ('correctly', 1),\n",
       "  ('corruptioncle', 1),\n",
       "  ('course', 2),\n",
       "  ('crucial', 1),\n",
       "  ('cue', 2),\n",
       "  ('curious', 1),\n",
       "  ('dah', 1),\n",
       "  ('dare', 1),\n",
       "  ('dattaamit', 1),\n",
       "  ('dayto', 1),\n",
       "  ('delay', 1),\n",
       "  ('delhincr', 1),\n",
       "  ('demonetizatio', 1),\n",
       "  ('den', 1),\n",
       "  ('denomination', 1),\n",
       "  ('devduttmyth', 1),\n",
       "  ('develop', 1),\n",
       "  ('devoid', 1),\n",
       "  ('dharmicfundoo', 1),\n",
       "  ('direct', 1),\n",
       "  ('direction', 2),\n",
       "  ('directly', 6),\n",
       "  ('dispense', 3),\n",
       "  ('distribute', 1),\n",
       "  ('doomsday', 1),\n",
       "  ('dra', 1),\n",
       "  ('eligible', 1),\n",
       "  ('elsewhere', 1),\n",
       "  ('essential', 1),\n",
       "  ('everyday', 1),\n",
       "  ('exch', 1),\n",
       "  ('exchange', 5),\n",
       "  ('exist', 1),\n",
       "  ('exle', 1),\n",
       "  ('faith', 1),\n",
       "  ('false', 1),\n",
       "  ('fertilizer', 1),\n",
       "  ('fill', 1),\n",
       "  ('fodder', 1),\n",
       "  ('foremost', 1),\n",
       "  ('free', 4),\n",
       "  ('fresh', 2),\n",
       "  ('gaganagrawal', 1),\n",
       "  ('gain', 2),\n",
       "  ('gem', 3),\n",
       "  ('guideline', 1),\n",
       "  ('headline', 1),\n",
       "  ('hnis', 2),\n",
       "  ('hoarder', 1),\n",
       "  ('hobbit', 1),\n",
       "  ('hospital', 1),\n",
       "  ('improvement', 2),\n",
       "  ('improvise', 2),\n",
       "  ('include', 3),\n",
       "  ('income', 1),\n",
       "  ('inquiry', 1),\n",
       "  ('instead', 1),\n",
       "  ('institution', 1),\n",
       "  ('kick', 1),\n",
       "  ('lady', 1),\n",
       "  ('large', 1),\n",
       "  ('later', 1),\n",
       "  ('leave', 1),\n",
       "  ('leve', 1),\n",
       "  ('liberal', 1),\n",
       "  ('limit', 2),\n",
       "  ('literacy', 1),\n",
       "  ('logic', 1),\n",
       "  ('mastership', 1),\n",
       "  ('member', 1),\n",
       "  ('merchant', 1),\n",
       "  ('militant', 2),\n",
       "  ('milk', 6),\n",
       "  ('miss', 4),\n",
       "  ('mnth', 1),\n",
       "  ('modern', 1),\n",
       "  ('modibhakt', 1),\n",
       "  ('movie', 1),\n",
       "  ('ndtv', 1),\n",
       "  ('noncommittal', 1),\n",
       "  ('office', 1),\n",
       "  ('patient', 1),\n",
       "  ('perform', 1),\n",
       "  ('person', 1),\n",
       "  ('pesticide', 1),\n",
       "  ('physical', 2),\n",
       "  ('picture', 2),\n",
       "  ('place', 2),\n",
       "  ('planet', 1),\n",
       "  ('popular', 1),\n",
       "  ('portal', 1),\n",
       "  ('poster', 1),\n",
       "  ('presently', 1),\n",
       "  ('private', 1),\n",
       "  ('producer', 6),\n",
       "  ('promise', 1),\n",
       "  ('property', 1),\n",
       "  ('publish', 1),\n",
       "  ('pull', 1),\n",
       "  ('rachitsharm', 1),\n",
       "  ('realize', 1),\n",
       "  ('rebound', 2),\n",
       "  ('recalibrate', 3),\n",
       "  ('recent', 1),\n",
       "  ('reform', 2),\n",
       "  ('reluctance', 1),\n",
       "  ('right', 3),\n",
       "  ('safety', 2),\n",
       "  ('sanjay', 1),\n",
       "  ('sari', 1),\n",
       "  ('seed', 1),\n",
       "  ('sharemarket', 1),\n",
       "  ('situation', 1),\n",
       "  ('size', 1),\n",
       "  ('slightly', 1),\n",
       "  ('sluggish', 1),\n",
       "  ('snaking', 1),\n",
       "  ('so', 1),\n",
       "  ('soil', 1),\n",
       "  ('soiled', 1),\n",
       "  ('speech', 1),\n",
       "  ('spiral', 1),\n",
       "  ('spit', 1),\n",
       "  ('sponsorship', 1),\n",
       "  ('spouse', 1),\n",
       "  ('sricharan', 1),\n",
       "  ('srinagartime', 1),\n",
       "  ('steep', 1),\n",
       "  ('strongly', 2),\n",
       "  ('supplyside', 2),\n",
       "  ('supporter', 2),\n",
       "  ('sure', 2),\n",
       "  ('tariff', 1),\n",
       "  ('taxmannindia', 1),\n",
       "  ('temporary', 2),\n",
       "  ('terriorism', 1),\n",
       "  ('thoughtful', 2),\n",
       "  ('thundiyil', 1),\n",
       "  ('timesnow', 1),\n",
       "  ('timesofindia', 1),\n",
       "  ('toll', 1),\n",
       "  ('tonight', 2),\n",
       "  ('topic', 1),\n",
       "  ('trackmany', 1),\n",
       "  ('transition', 1),\n",
       "  ('trial', 1),\n",
       "  ('tripura', 2),\n",
       "  ('tumble', 1),\n",
       "  ('turbulent', 1),\n",
       "  ('tutor', 1),\n",
       "  ('uncha', 1),\n",
       "  ('unplanne', 1),\n",
       "  ('utility', 1),\n",
       "  ('value', 1),\n",
       "  ('vigor', 1),\n",
       "  ('visit', 1),\n",
       "  ('wage', 1),\n",
       "  ('wear', 1),\n",
       "  ('webinar', 2),\n",
       "  ('whole', 1),\n",
       "  ('wonder', 4)]]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# human-readable format of corpus (term-frequency)\n",
    "\n",
    "[[(id2word[id],freq) for id, freq in cp] for cp in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class LdaModel in module gensim.models.ldamodel:\n",
      "\n",
      "class LdaModel(gensim.interfaces.TransformationABC, gensim.models.basemodel.BaseTopicModel)\n",
      " |  LdaModel(corpus=None, num_topics=100, id2word=None, distributed=False, chunksize=2000, passes=1, update_every=1, alpha='symmetric', eta=None, decay=0.5, offset=1.0, eval_every=10, iterations=50, gamma_threshold=0.001, minimum_probability=0.01, random_state=None, ns_conf=None, minimum_phi_value=0.01, per_word_topics=False, callbacks=None, dtype=<class 'numpy.float32'>)\n",
      " |  \n",
      " |  Train and use Online Latent Dirichlet Allocation (OLDA) models as presented in\n",
      " |  `Hoffman et al. :\"Online Learning for Latent Dirichlet Allocation\" <https://www.di.ens.fr/~fbach/mdhnips2010.pdf>`_.\n",
      " |  \n",
      " |  Examples\n",
      " |  -------\n",
      " |  Initialize a model using a Gensim corpus\n",
      " |  \n",
      " |  .. sourcecode:: pycon\n",
      " |  \n",
      " |      >>> from gensim.test.utils import common_corpus\n",
      " |      >>>\n",
      " |      >>> lda = LdaModel(common_corpus, num_topics=10)\n",
      " |  \n",
      " |  You can then infer topic distributions on new, unseen documents.\n",
      " |  \n",
      " |  .. sourcecode:: pycon\n",
      " |  \n",
      " |      >>> doc_bow = [(1, 0.3), (2, 0.1), (0, 0.09)]\n",
      " |      >>> doc_lda = lda[doc_bow]\n",
      " |  \n",
      " |  The model can be updated (trained) with new documents.\n",
      " |  \n",
      " |  .. sourcecode:: pycon\n",
      " |  \n",
      " |      >>> # In practice (corpus =/= initial training corpus), but we use the same here for simplicity.\n",
      " |      >>> other_corpus = common_corpus\n",
      " |      >>>\n",
      " |      >>> lda.update(other_corpus)\n",
      " |  \n",
      " |  Model persistency is achieved through :meth:`~gensim.models.ldamodel.LdaModel.load` and\n",
      " |  :meth:`~gensim.models.ldamodel.LdaModel.save` methods.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      LdaModel\n",
      " |      gensim.interfaces.TransformationABC\n",
      " |      gensim.utils.SaveLoad\n",
      " |      gensim.models.basemodel.BaseTopicModel\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, bow, eps=None)\n",
      " |      Get the topic distribution for the given document.\n",
      " |      \n",
      " |      Wraps :meth:`~gensim.models.ldamodel.LdaModel.get_document_topics` to support an operator style call.\n",
      " |      Uses the model's current state (set using constructor arguments) to fill in the additional arguments of the\n",
      " |      wrapper method.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ---------\n",
      " |      bow : list of (int, float)\n",
      " |          The document in BOW format.\n",
      " |      eps : float, optional\n",
      " |          Topics with an assigned probability lower than this threshold will be discarded.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          Topic distribution for the given document. Each topic is represented as a pair of its ID and the probability\n",
      " |          assigned to it.\n",
      " |  \n",
      " |  __init__(self, corpus=None, num_topics=100, id2word=None, distributed=False, chunksize=2000, passes=1, update_every=1, alpha='symmetric', eta=None, decay=0.5, offset=1.0, eval_every=10, iterations=50, gamma_threshold=0.001, minimum_probability=0.01, random_state=None, ns_conf=None, minimum_phi_value=0.01, per_word_topics=False, callbacks=None, dtype=<class 'numpy.float32'>)\n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : {iterable of list of (int, float), scipy.sparse.csc}, optional\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_terms`, `num_documents`).\n",
      " |          If not given, the model is left untrained (presumably because you want to call\n",
      " |          :meth:`~gensim.models.ldamodel.LdaModel.update` manually).\n",
      " |      num_topics : int, optional\n",
      " |          The number of requested latent topics to be extracted from the training corpus.\n",
      " |      id2word : {dict of (int, str), :class:`gensim.corpora.dictionary.Dictionary`}\n",
      " |          Mapping from word IDs to words. It is used to determine the vocabulary size, as well as for\n",
      " |          debugging and topic printing.\n",
      " |      distributed : bool, optional\n",
      " |          Whether distributed computing should be used to accelerate training.\n",
      " |      chunksize :  int, optional\n",
      " |          Number of documents to be used in each training chunk.\n",
      " |      passes : int, optional\n",
      " |          Number of passes through the corpus during training.\n",
      " |      update_every : int, optional\n",
      " |          Number of documents to be iterated through for each update.\n",
      " |          Set to 0 for batch learning, > 1 for online iterative learning.\n",
      " |      alpha : {numpy.ndarray, str}, optional\n",
      " |          Can be set to an 1D array of length equal to the number of expected topics that expresses\n",
      " |          our a-priori belief for the each topics' probability.\n",
      " |          Alternatively default prior selecting strategies can be employed by supplying a string:\n",
      " |      \n",
      " |              * 'asymmetric': Uses a fixed normalized asymmetric prior of `1.0 / topicno`.\n",
      " |              * 'auto': Learns an asymmetric prior from the corpus (not available if `distributed==True`).\n",
      " |      eta : {float, np.array, str}, optional\n",
      " |          A-priori belief on word probability, this can be:\n",
      " |      \n",
      " |              * scalar for a symmetric prior over topic/word probability,\n",
      " |              * vector of length num_words to denote an asymmetric user defined probability for each word,\n",
      " |              * matrix of shape (num_topics, num_words) to assign a probability for each word-topic combination,\n",
      " |              * the string 'auto' to learn the asymmetric prior from the data.\n",
      " |      decay : float, optional\n",
      " |          A number between (0.5, 1] to weight what percentage of the previous lambda value is forgotten\n",
      " |          when each new document is examined. Corresponds to Kappa from\n",
      " |          `Matthew D. Hoffman, David M. Blei, Francis Bach:\n",
      " |          \"Online Learning for Latent Dirichlet Allocation NIPS'10\" <https://www.di.ens.fr/~fbach/mdhnips2010.pdf>`_.\n",
      " |      offset : float, optional\n",
      " |          Hyper-parameter that controls how much we will slow down the first steps the first few iterations.\n",
      " |          Corresponds to Tau_0 from `Matthew D. Hoffman, David M. Blei, Francis Bach:\n",
      " |          \"Online Learning for Latent Dirichlet Allocation NIPS'10\" <https://www.di.ens.fr/~fbach/mdhnips2010.pdf>`_.\n",
      " |      eval_every : int, optional\n",
      " |          Log perplexity is estimated every that many updates. Setting this to one slows down training by ~2x.\n",
      " |      iterations : int, optional\n",
      " |          Maximum number of iterations through the corpus when inferring the topic distribution of a corpus.\n",
      " |      gamma_threshold : float, optional\n",
      " |          Minimum change in the value of the gamma parameters to continue iterating.\n",
      " |      minimum_probability : float, optional\n",
      " |          Topics with a probability lower than this threshold will be filtered out.\n",
      " |      random_state : {np.random.RandomState, int}, optional\n",
      " |          Either a randomState object or a seed to generate one. Useful for reproducibility.\n",
      " |      ns_conf : dict of (str, object), optional\n",
      " |          Key word parameters propagated to :func:`gensim.utils.getNS` to get a Pyro4 Nameserved.\n",
      " |          Only used if `distributed` is set to True.\n",
      " |      minimum_phi_value : float, optional\n",
      " |          if `per_word_topics` is True, this represents a lower bound on the term probabilities.\n",
      " |      per_word_topics : bool\n",
      " |          If True, the model also computes a list of topics, sorted in descending order of most likely topics for\n",
      " |          each word, along with their phi values multiplied by the feature length (i.e. word count).\n",
      " |      callbacks : list of :class:`~gensim.models.callbacks.Callback`\n",
      " |          Metric callbacks to log and visualize evaluation metrics of the model during training.\n",
      " |      dtype : {numpy.float16, numpy.float32, numpy.float64}, optional\n",
      " |          Data-type to use during calculations inside model. All inputs are also converted.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Get a string representation of the current object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          Human readable representation of the most important model parameters.\n",
      " |  \n",
      " |  bound(self, corpus, gamma=None, subsample_ratio=1.0)\n",
      " |      Estimate the variational bound of documents from the corpus as E_q[log p(corpus)] - E_q[log q(corpus)].\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : {iterable of list of (int, float), scipy.sparse.csc}, optional\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_terms`, `num_documents`) used to estimate the\n",
      " |          variational bounds.\n",
      " |      gamma : numpy.ndarray, optional\n",
      " |          Topic weight variational parameters for each document. If not supplied, it will be inferred from the model.\n",
      " |      subsample_ratio : float, optional\n",
      " |          Percentage of the whole corpus represented by the passed `corpus` argument (in case this was a sample).\n",
      " |          Set to 1.0 if the whole corpus was passed.This is used as a multiplicative factor to scale the likelihood\n",
      " |          appropriately.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The variational bound score calculated for each document.\n",
      " |  \n",
      " |  clear(self)\n",
      " |      Clear the model's state to free some memory. Used in the distributed implementation.\n",
      " |  \n",
      " |  diff(self, other, distance='kullback_leibler', num_words=100, n_ann_terms=10, diagonal=False, annotation=True, normed=True)\n",
      " |      Calculate the difference in topic distributions between two models: `self` and `other`.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      other : :class:`~gensim.models.ldamodel.LdaModel`\n",
      " |          The model which will be compared against the current object.\n",
      " |      distance : {'kullback_leibler', 'hellinger', 'jaccard', 'jensen_shannon'}\n",
      " |          The distance metric to calculate the difference with.\n",
      " |      num_words : int, optional\n",
      " |          The number of most relevant words used if `distance == 'jaccard'`. Also used for annotating topics.\n",
      " |      n_ann_terms : int, optional\n",
      " |          Max number of words in intersection/symmetric difference between topics. Used for annotation.\n",
      " |      diagonal : bool, optional\n",
      " |          Whether we need the difference between identical topics (the diagonal of the difference matrix).\n",
      " |      annotation : bool, optional\n",
      " |          Whether the intersection or difference of words between two topics should be returned.\n",
      " |      normed : bool, optional\n",
      " |          Whether the matrix should be normalized or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          A difference matrix. Each element corresponds to the difference between the two topics,\n",
      " |          shape (`self.num_topics`, `other.num_topics`)\n",
      " |      numpy.ndarray, optional\n",
      " |          Annotation matrix where for each pair we include the word from the intersection of the two topics,\n",
      " |          and the word from the symmetric difference of the two topics. Only included if `annotation == True`.\n",
      " |          Shape (`self.num_topics`, `other_model.num_topics`, 2).\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Get the differences between each pair of topics inferred by two models\n",
      " |      \n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.models.ldamulticore import LdaMulticore\n",
      " |          >>> from gensim.test.utils import datapath\n",
      " |          >>>\n",
      " |          >>> m1 = LdaMulticore.load(datapath(\"lda_3_0_1_model\"))\n",
      " |          >>> m2 = LdaMulticore.load(datapath(\"ldamodel_python_3_5\"))\n",
      " |          >>> mdiff, annotation = m1.diff(m2)\n",
      " |          >>> topic_diff = mdiff  # get matrix with difference for each topic pair from `m1` and `m2`\n",
      " |  \n",
      " |  do_estep(self, chunk, state=None)\n",
      " |      Perform inference on a chunk of documents, and accumulate the collected sufficient statistics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      chunk : {list of list of (int, float), scipy.sparse.csc}\n",
      " |          The corpus chunk on which the inference step will be performed.\n",
      " |      state : :class:`~gensim.models.ldamodel.LdaState`, optional\n",
      " |          The state to be updated with the newly accumulated sufficient statistics. If none, the models\n",
      " |          `self.state` is updated.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          Gamma parameters controlling the topic weights, shape (`len(chunk)`, `self.num_topics`).\n",
      " |  \n",
      " |  do_mstep(self, rho, other, extra_pass=False)\n",
      " |      Maximization step: use linear interpolation between the existing topics and\n",
      " |      collected sufficient statistics in `other` to update the topics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      rho : float\n",
      " |          Learning rate.\n",
      " |      other : :class:`~gensim.models.ldamodel.LdaModel`\n",
      " |          The model whose sufficient statistics will be used to update the topics.\n",
      " |      extra_pass : bool, optional\n",
      " |          Whether this step required an additional pass over the corpus.\n",
      " |  \n",
      " |  get_document_topics(self, bow, minimum_probability=None, minimum_phi_value=None, per_word_topics=False)\n",
      " |      Get the topic distribution for the given document.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      bow : corpus : list of (int, float)\n",
      " |          The document in BOW format.\n",
      " |      minimum_probability : float\n",
      " |          Topics with an assigned probability lower than this threshold will be discarded.\n",
      " |      minimum_phi_value : float\n",
      " |          If `per_word_topics` is True, this represents a lower bound on the term probabilities that are included.\n",
      " |           If set to None, a value of 1e-8 is used to prevent 0s.\n",
      " |      per_word_topics : bool\n",
      " |          If True, this function will also return two extra lists as explained in the \"Returns\" section.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          Topic distribution for the whole document. Each element in the list is a pair of a topic's id, and\n",
      " |          the probability that was assigned to it.\n",
      " |      list of (int, list of (int, float), optional\n",
      " |          Most probable topics per word. Each element in the list is a pair of a word's id, and a list of\n",
      " |          topics sorted by their relevance to this word. Only returned if `per_word_topics` was set to True.\n",
      " |      list of (int, list of float), optional\n",
      " |          Phi relevance values, multiplied by the feature length, for each word-topic combination.\n",
      " |          Each element in the list is a pair of a word's id and a list of the phi values between this word and\n",
      " |          each topic. Only returned if `per_word_topics` was set to True.\n",
      " |  \n",
      " |  get_term_topics(self, word_id, minimum_probability=None)\n",
      " |      Get the most relevant topics to the given word.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      word_id : int\n",
      " |          The word for which the topic distribution will be computed.\n",
      " |      minimum_probability : float, optional\n",
      " |          Topics with an assigned probability below this threshold will be discarded.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          The relevant topics represented as pairs of their ID and their assigned probability, sorted\n",
      " |          by relevance to the given word.\n",
      " |  \n",
      " |  get_topic_terms(self, topicid, topn=10)\n",
      " |      Get the representation for a single topic. Words the integer IDs, in constrast to\n",
      " |      :meth:`~gensim.models.ldamodel.LdaModel.show_topic` that represents words by the actual strings.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicid : int\n",
      " |          The ID of the topic to be returned\n",
      " |      topn : int, optional\n",
      " |          Number of the most significant words that are associated with the topic.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, float)\n",
      " |          Word ID - probability pairs for the most relevant words generated by the topic.\n",
      " |  \n",
      " |  get_topics(self)\n",
      " |      Get the term-topic matrix learned during inference.\n",
      " |      \n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The probability for each word in each topic, shape (`num_topics`, `vocabulary_size`).\n",
      " |  \n",
      " |  inference(self, chunk, collect_sstats=False)\n",
      " |      Given a chunk of sparse document vectors, estimate gamma (parameters controlling the topic weights)\n",
      " |      for each document in the chunk.\n",
      " |      \n",
      " |      This function does not modify the model The whole input chunk of document is assumed to fit in RAM;\n",
      " |      chunking of a large corpus must be done earlier in the pipeline. Avoids computing the `phi` variational\n",
      " |      parameter directly using the optimization presented in\n",
      " |      `Lee, Seung: Algorithms for non-negative matrix factorization\"\n",
      " |      <https://papers.nips.cc/paper/1861-algorithms-for-non-negative-matrix-factorization.pdf>`_.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      chunk : {list of list of (int, float), scipy.sparse.csc}\n",
      " |          The corpus chunk on which the inference step will be performed.\n",
      " |      collect_sstats : bool, optional\n",
      " |          If set to True, also collect (and return) sufficient statistics needed to update the model's topic-word\n",
      " |          distributions.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      (numpy.ndarray, {numpy.ndarray, None})\n",
      " |          The first element is always returned and it corresponds to the states gamma matrix. The second element is\n",
      " |          only returned if `collect_sstats` == True and corresponds to the sufficient statistics for the M step.\n",
      " |  \n",
      " |  init_dir_prior(self, prior, name)\n",
      " |      Initialize priors for the Dirichlet distribution.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      prior : {str, list of float, numpy.ndarray of float, float}\n",
      " |          A-priori belief on word probability. If `name` == 'eta' then the prior can be:\n",
      " |      \n",
      " |              * scalar for a symmetric prior over topic/word probability,\n",
      " |              * vector of length num_words to denote an asymmetric user defined probability for each word,\n",
      " |              * matrix of shape (num_topics, num_words) to assign a probability for each word-topic combination,\n",
      " |              * the string 'auto' to learn the asymmetric prior from the data.\n",
      " |      \n",
      " |          If `name` == 'alpha', then the prior can be:\n",
      " |      \n",
      " |              * an 1D array of length equal to the number of expected topics,\n",
      " |              * 'asymmetric': Uses a fixed normalized asymmetric prior of `1.0 / topicno`.\n",
      " |              * 'auto': Learns an asymmetric prior from the corpus.\n",
      " |      name : {'alpha', 'eta'}\n",
      " |          Whether the `prior` is parameterized by the alpha vector (1 parameter per topic)\n",
      " |          or by the eta (1 parameter per unique term in the vocabulary).\n",
      " |  \n",
      " |  log_perplexity(self, chunk, total_docs=None)\n",
      " |      Calculate and return per-word likelihood bound, using a chunk of documents as evaluation corpus.\n",
      " |      \n",
      " |      Also output the calculated statistics, including the perplexity=2^(-bound), to log at INFO level.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      chunk : {list of list of (int, float), scipy.sparse.csc}\n",
      " |          The corpus chunk on which the inference step will be performed.\n",
      " |      total_docs : int, optional\n",
      " |          Number of docs used for evaluation of the perplexity.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The variational bound score calculated for each word.\n",
      " |  \n",
      " |  save(self, fname, ignore=('state', 'dispatcher'), separately=None, *args, **kwargs)\n",
      " |      Save the model to a file.\n",
      " |      \n",
      " |      Large internal arrays may be stored into separate files, with `fname` as prefix.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      If you intend to use models across Python 2/3 versions there are a few things to\n",
      " |      keep in mind:\n",
      " |      \n",
      " |        1. The pickled Python dictionaries will not work across Python versions\n",
      " |        2. The `save` method does not automatically save all numpy arrays separately, only\n",
      " |           those ones that exceed `sep_limit` set in :meth:`~gensim.utils.SaveLoad.save`. The main\n",
      " |           concern here is the `alpha` array if for instance using `alpha='auto'`.\n",
      " |      \n",
      " |      Please refer to the `wiki recipes section\n",
      " |      <https://github.com/RaRe-Technologies/gensim/wiki/\n",
      " |      Recipes-&-FAQ#q9-how-do-i-load-a-model-in-python-3-that-was-trained-and-saved-using-python-2>`_\n",
      " |      for an example on how to work around these issues.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.ldamodel.LdaModel.load`\n",
      " |          Load model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to the system file where the model will be persisted.\n",
      " |      ignore : tuple of str, optional\n",
      " |          The named attributes in the tuple will be left out of the pickled model. The reason why\n",
      " |          the internal `state` is ignored by default is that it uses its own serialisation rather than the one\n",
      " |          provided by this method.\n",
      " |      separately : {list of str, None}, optional\n",
      " |          If None -  automatically detect large numpy/scipy.sparse arrays in the object being stored, and store\n",
      " |          them into separate files. This avoids pickle memory errors and allows `mmap`'ing large arrays\n",
      " |          back on load efficiently. If list of str - this attributes will be stored in separate files,\n",
      " |          the automatic check is not performed in this case.\n",
      " |      *args\n",
      " |          Positional arguments propagated to :meth:`~gensim.utils.SaveLoad.save`.\n",
      " |      **kwargs\n",
      " |          Key word arguments propagated to :meth:`~gensim.utils.SaveLoad.save`.\n",
      " |  \n",
      " |  show_topic(self, topicid, topn=10)\n",
      " |      Get the representation for a single topic. Words here are the actual strings, in constrast to\n",
      " |      :meth:`~gensim.models.ldamodel.LdaModel.get_topic_terms` that represents words by their vocabulary ID.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicid : int\n",
      " |          The ID of the topic to be returned\n",
      " |      topn : int, optional\n",
      " |          Number of the most significant words that are associated with the topic.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (str, float)\n",
      " |          Word - probability pairs for the most relevant words generated by the topic.\n",
      " |  \n",
      " |  show_topics(self, num_topics=10, num_words=10, log=False, formatted=True)\n",
      " |      Get a representation for selected topics.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          Number of topics to be returned. Unlike LSA, there is no natural ordering between the topics in LDA.\n",
      " |          The returned topics subset of all topics is therefore arbitrary and may change between two LDA\n",
      " |          training runs.\n",
      " |      num_words : int, optional\n",
      " |          Number of words to be presented for each topic. These will be the most relevant words (assigned the highest\n",
      " |          probability for each topic).\n",
      " |      log : bool, optional\n",
      " |          Whether the output is also logged, besides being returned.\n",
      " |      formatted : bool, optional\n",
      " |          Whether the topic representations should be formatted as strings. If False, they are returned as\n",
      " |          2 tuples of (word, probability).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of {str, tuple of (str, float)}\n",
      " |          a list of topics, each represented either as a string (when `formatted` == True) or word-probability\n",
      " |          pairs.\n",
      " |  \n",
      " |  sync_state(self, current_Elogbeta=None)\n",
      " |      Propagate the states topic probabilities to the inner object's attribute.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      current_Elogbeta: numpy.ndarray\n",
      " |          Posterior probabilities for each topic, optional.\n",
      " |          If omitted, it will get Elogbeta from state.\n",
      " |  \n",
      " |  top_topics(self, corpus=None, texts=None, dictionary=None, window_size=None, coherence='u_mass', topn=20, processes=-1)\n",
      " |      Get the topics with the highest coherence score the coherence for each topic.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : iterable of list of (int, float), optional\n",
      " |          Corpus in BoW format.\n",
      " |      texts : list of list of str, optional\n",
      " |          Tokenized texts, needed for coherence models that use sliding window based (i.e. coherence=`c_something`)\n",
      " |          probability estimator .\n",
      " |      dictionary : :class:`~gensim.corpora.dictionary.Dictionary`, optional\n",
      " |          Gensim dictionary mapping of id word to create corpus.\n",
      " |          If `model.id2word` is present, this is not needed. If both are provided, passed `dictionary` will be used.\n",
      " |      window_size : int, optional\n",
      " |          Is the size of the window to be used for coherence measures using boolean sliding window as their\n",
      " |          probability estimator. For 'u_mass' this doesn't matter.\n",
      " |          If None - the default window sizes are used which are: 'c_v' - 110, 'c_uci' - 10, 'c_npmi' - 10.\n",
      " |      coherence : {'u_mass', 'c_v', 'c_uci', 'c_npmi'}, optional\n",
      " |          Coherence measure to be used.\n",
      " |          Fastest method - 'u_mass', 'c_uci' also known as `c_pmi`.\n",
      " |          For 'u_mass' corpus should be provided, if texts is provided, it will be converted to corpus\n",
      " |          using the dictionary. For 'c_v', 'c_uci' and 'c_npmi' `texts` should be provided (`corpus` isn't needed)\n",
      " |      topn : int, optional\n",
      " |          Integer corresponding to the number of top words to be extracted from each topic.\n",
      " |      processes : int, optional\n",
      " |          Number of processes to use for probability estimation phase, any value less than 1 will be interpreted as\n",
      " |          num_cpus - 1.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (list of (int, str), float)\n",
      " |          Each element in the list is a pair of a topic representation and its coherence score. Topic representations\n",
      " |          are distributions of words, represented as a list of pairs of word IDs and their probabilities.\n",
      " |  \n",
      " |  update(self, corpus, chunksize=None, decay=None, offset=None, passes=None, update_every=None, eval_every=None, iterations=None, gamma_threshold=None, chunks_as_numpy=False)\n",
      " |      Train the model with new documents, by EM-iterating over the corpus until the topics converge, or until\n",
      " |      the maximum number of allowed iterations is reached. `corpus` must be an iterable.\n",
      " |      \n",
      " |      In distributed mode, the E step is distributed over a cluster of machines.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      This update also supports updating an already trained model with new documents; the two models are then merged\n",
      " |      in proportion to the number of old vs. new documents. This feature is still experimental for non-stationary\n",
      " |      input streams. For stationary input (no topic drift in new documents), on the other hand, this equals the\n",
      " |      online update of `Matthew D. Hoffman, David M. Blei, Francis Bach:\n",
      " |      \"Online Learning for Latent Dirichlet Allocation NIPS'10\" <https://www.di.ens.fr/~fbach/mdhnips2010.pdf>`_.\n",
      " |      and is guaranteed to converge for any `decay` in (0.5, 1.0). Additionally, for smaller corpus sizes, an\n",
      " |      increasing `offset` may be beneficial (see Table 1 in the same paper).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      corpus : {iterable of list of (int, float), scipy.sparse.csc}, optional\n",
      " |          Stream of document vectors or sparse matrix of shape (`num_terms`, `num_documents`) used to update the\n",
      " |          model.\n",
      " |      chunksize :  int, optional\n",
      " |          Number of documents to be used in each training chunk.\n",
      " |      decay : float, optional\n",
      " |          A number between (0.5, 1] to weight what percentage of the previous lambda value is forgotten\n",
      " |          when each new document is examined. Corresponds to Kappa from\n",
      " |          `Matthew D. Hoffman, David M. Blei, Francis Bach:\n",
      " |          \"Online Learning for Latent Dirichlet Allocation NIPS'10\" <https://www.di.ens.fr/~fbach/mdhnips2010.pdf>`_.\n",
      " |      offset : float, optional\n",
      " |          Hyper-parameter that controls how much we will slow down the first steps the first few iterations.\n",
      " |          Corresponds to Tau_0 from `Matthew D. Hoffman, David M. Blei, Francis Bach:\n",
      " |          \"Online Learning for Latent Dirichlet Allocation NIPS'10\" <https://www.di.ens.fr/~fbach/mdhnips2010.pdf>`_.\n",
      " |      passes : int, optional\n",
      " |          Number of passes through the corpus during training.\n",
      " |      update_every : int, optional\n",
      " |          Number of documents to be iterated through for each update.\n",
      " |          Set to 0 for batch learning, > 1 for online iterative learning.\n",
      " |      eval_every : int, optional\n",
      " |          Log perplexity is estimated every that many updates. Setting this to one slows down training by ~2x.\n",
      " |      iterations : int, optional\n",
      " |          Maximum number of iterations through the corpus when inferring the topic distribution of a corpus.\n",
      " |      gamma_threshold : float, optional\n",
      " |          Minimum change in the value of the gamma parameters to continue iterating.\n",
      " |      chunks_as_numpy : bool, optional\n",
      " |          Whether each chunk passed to the inference step should be a numpy.ndarray or not. Numpy can in some settings\n",
      " |          turn the term IDs into floats, these will be converted back into integers in inference, which incurs a\n",
      " |          performance hit. For distributed computing it may be desirable to keep the chunks as `numpy.ndarray`.\n",
      " |  \n",
      " |  update_alpha(self, gammat, rho)\n",
      " |      Update parameters for the Dirichlet prior on the per-document topic weights.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      gammat : numpy.ndarray\n",
      " |          Previous topic weight parameters.\n",
      " |      rho : float\n",
      " |          Learning rate.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          Sequence of alpha parameters.\n",
      " |  \n",
      " |  update_eta(self, lambdat, rho)\n",
      " |      Update parameters for the Dirichlet prior on the per-topic word weights.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      lambdat : numpy.ndarray\n",
      " |          Previous lambda parameters.\n",
      " |      rho : float\n",
      " |          Learning rate.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      numpy.ndarray\n",
      " |          The updated eta parameters.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  load(fname, *args, **kwargs) from builtins.type\n",
      " |      Load a previously saved :class:`gensim.models.ldamodel.LdaModel` from file.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      :meth:`~gensim.models.ldamodel.LdaModel.save`\n",
      " |          Save model.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      fname : str\n",
      " |          Path to the file where the model is stored.\n",
      " |      *args\n",
      " |          Positional arguments propagated to :meth:`~gensim.utils.SaveLoad.load`.\n",
      " |      **kwargs\n",
      " |          Key word arguments propagated to :meth:`~gensim.utils.SaveLoad.load`.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      Large arrays can be memmap'ed back as read-only (shared memory) by setting `mmap='r'`:\n",
      " |      \n",
      " |      .. sourcecode:: pycon\n",
      " |      \n",
      " |          >>> from gensim.test.utils import datapath\n",
      " |          >>>\n",
      " |          >>> fname = datapath(\"lda_3_0_1_model\")\n",
      " |          >>> lda = LdaModel.load(fname, mmap='r')\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from gensim.utils.SaveLoad:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from gensim.models.basemodel.BaseTopicModel:\n",
      " |  \n",
      " |  print_topic(self, topicno, topn=10)\n",
      " |      Get a single topic as a formatted string.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      topicno : int\n",
      " |          Topic id.\n",
      " |      topn : int\n",
      " |          Number of words from topic that will be used.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      str\n",
      " |          String representation of topic, like '-0.340 * \"category\" + 0.298 * \"$M$\" + 0.183 * \"algebra\" + ... '.\n",
      " |  \n",
      " |  print_topics(self, num_topics=20, num_words=10)\n",
      " |      Get the most significant topics (alias for `show_topics()` method).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      num_topics : int, optional\n",
      " |          The number of topics to be selected, if -1 - all topics will be in result (ordered by significance).\n",
      " |      num_words : int, optional\n",
      " |          The number of words to be included per topics (ordered by significance).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      list of (int, list of (str, float))\n",
      " |          Sequence with (topic_id, [(word, value), ... ]).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Build the topic model\n",
    "\n",
    "help(gensim.models.ldamodel.LdaModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute coherence value at various values of alpha and num_topics\n",
    "def compute_coherence_values(dictionary, corpus, texts, num_topics_range, alpha_range):\n",
    "    \n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for alpha in alpha_range:\n",
    "        for num_topics in num_topics_range:\n",
    "            lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                               id2word=dictionary,\n",
    "                                               num_topics=num_topics, \n",
    "                                               alpha=alpha,\n",
    "                                               per_word_topics=True)\n",
    "            model_list.append(lda_model)\n",
    "            coherencemodel = CoherenceModel(model=lda_model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "            coherence_values.append((alpha, num_topics, coherencemodel.get_coherence()))\n",
    "        \n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>coherence_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>0.414524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001</td>\n",
       "      <td>3</td>\n",
       "      <td>0.354362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>0.337387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>0.382856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001</td>\n",
       "      <td>6</td>\n",
       "      <td>0.372520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   alpha  num_topics  coherence_value\n",
       "0  0.001           2         0.414524\n",
       "1  0.001           3         0.354362\n",
       "2  0.001           4         0.337387\n",
       "3  0.001           5         0.382856\n",
       "4  0.001           6         0.372520"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build models across a range of num_topics and alpha\n",
    "\n",
    "num_topics_range = [2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "alpha_range = [0.001, 0.01, 0.1, 1]\n",
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary = id2word, corpus = corpus, texts = data_lemmatized,\n",
    "                                                       num_topics_range = num_topics_range, alpha_range = alpha_range)\n",
    "\n",
    "coherence_df = pd.DataFrame(coherence_values, columns=['alpha', 'num_topics', 'coherence_value'])\n",
    "\n",
    "coherence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "def plot_coherence(coherence_df, alpha_range, num_topics_range):\n",
    "    plt.figure(figsize=(16,6))\n",
    "    plt.grid('darkgrid')\n",
    "    for i, val in enumerate(alpha_range):\n",
    "\n",
    "        # subplot 1/3/i\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        alpha_subset = coherence_df[coherence_df['alpha']==val]\n",
    "\n",
    "        plt.plot(alpha_subset[\"num_topics\"], alpha_subset[\"coherence_value\"])\n",
    "        plt.xlabel('num_topics')\n",
    "        plt.ylabel('Coherence Value')\n",
    "        plt.title(\"alpha={0}\".format(val))\n",
    "        plt.ylim([0.20, 1])\n",
    "        plt.legend('coherence value', loc='upper left')\n",
    "        plt.xticks(num_topics_range)\n",
    "        plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "\n",
    "\n",
    "plot_coherence(coherence_df, alpha_range, num_topics_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LDA Model\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus, id2word = id2word, num_topics = 5, random_state =100,\n",
    "                                           update_every = 1, chunksize = 100, passes = 10, alpha = 1, per_word_topics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.026*\"get\" + 0.022*\"note\" + 0.015*\"say\" + 0.014*\"good\" + 0.014*\"fake\" + '\n",
      "  '0.013*\"money\" + 0.013*\"people\" + 0.011*\"due\" + 0.010*\"modi\" + '\n",
      "  '0.009*\"video\"'),\n",
      " (1,\n",
      "  '0.037*\"find\" + 0.033*\"implement\" + 0.031*\"modi\" + 0.031*\"actually\" + '\n",
      "  '0.029*\"poor\" + 0.022*\"dear\" + 0.016*\"effect\" + 0.014*\"question\" + '\n",
      "  '0.013*\"watch\" + 0.013*\"rich\"'),\n",
      " (2,\n",
      "  '0.041*\"impact\" + 0.030*\"system\" + 0.030*\"note\" + 0.028*\"overall\" + '\n",
      "  '0.028*\"education\" + 0.016*\"late\" + 0.015*\"price\" + 0.014*\"rise\" + '\n",
      "  '0.014*\"daily\" + 0.014*\"fall\"'),\n",
      " (3,\n",
      "  '0.051*\"people\" + 0.044*\"support\" + 0.017*\"cash\" + 0.016*\"nation\" + '\n",
      "  '0.014*\"move\" + 0.013*\"back\" + 0.013*\"run\" + 0.013*\"mode\" + 0.012*\"huge\" + '\n",
      "  '0.010*\"create\"'),\n",
      " (4,\n",
      "  '0.050*\"like\" + 0.032*\"digital\" + 0.025*\"payment\" + 0.023*\"growth\" + '\n",
      "  '0.020*\"impact\" + 0.016*\"turn\" + 0.016*\"transaction\" + 0.016*\"catalyze\" + '\n",
      "  '0.014*\"voucher\" + 0.014*\"food\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Topic 0: impact,system, education, cash, price, fall and gold\n",
    "* Topic 1: old, fake, note, ban and paytm\n",
    "* Topic 2: Modi, support, people and poor\n",
    "* Topic 3: Shortage, fund, daughter and mallyas\n",
    "* Topic 4: Video, youtube, telangana, help, support and oppose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el985225134325541848557335767\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el985225134325541848557335767_data = {\"mdsDat\": {\"x\": [-0.10967547523377788, 0.16905090337088993, -0.17459122001135072, 0.02798230890232273, 0.08723348297191595], \"y\": [0.15349330815491286, -0.06954204671294432, -0.15251046713387, 0.06779696015473136, 0.0007622455371700481], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [31.955825805664062, 21.052677154541016, 19.34722137451172, 15.24045181274414, 12.403827667236328]}, \"tinfo\": {\"Term\": [\"like\", \"find\", \"people\", \"impact\", \"actually\", \"support\", \"implement\", \"digital\", \"system\", \"overall\", \"note\", \"education\", \"growth\", \"dear\", \"poor\", \"payment\", \"modi\", \"get\", \"turn\", \"catalyze\", \"transaction\", \"rise\", \"daily\", \"voucher\", \"gold\", \"cash\", \"nation\", \"food\", \"question\", \"late\", \"rise\", \"gold\", \"overall\", \"daily\", \"system\", \"education\", \"financial\", \"announcement\", \"print\", \"late\", \"price\", \"milk\", \"producer\", \"directly\", \"bank\", \"sell\", \"evident\", \"exchange\", \"technology\", \"worldbank\", \"swift\", \"deployment\", \"fall\", \"sharesclearly\", \"miss\", \"ncbn\", \"heritage\", \"free\", \"analysis\", \"license\", \"currency\", \"positive\", \"old\", \"impact\", \"new\", \"note\", \"well\", \"service\", \"worth\", \"call\", \"go\", \"s\", \"help\", \"ban\", \"read\", \"must\", \"get\", \"economy\", \"payment\", \"take\", \"say\", \"actually\", \"dear\", \"find\", \"shrink\", \"snapchat\", \"inform\", \"telangana\", \"edict\", \"implement\", \"oil\", \"fishy\", \"rich\", \"third\", \"trailer\", \"question\", \"solution\", \"innovative\", \"govts\", \"require\", \"surrender\", \"double\", \"consumer\", \"critical\", \"industrial\", \"clearly\", \"paytm\", \"seem\", \"drag\", \"teacher\", \"hilarious\", \"hate\", \"poor\", \"watch\", \"modi\", \"demand\", \"effect\", \"survey\", \"month\", \"index\", \"come\", \"result\", \"bypoll\", \"video\", \"vote\", \"take\", \"help\", \"support\", \"like\", \"growth\", \"catalyze\", \"turn\", \"fold\", \"voucher\", \"ahead\", \"transaction\", \"daughter\", \"digital\", \"charge\", \"food\", \"shortage\", \"vision\", \"mobile\", \"round\", \"table\", \"nitishkumar\", \"fund\", \"end\", \"maintain\", \"silence\", \"turk\", \"forecast\", \"annual\", \"trim\", \"increase\", \"advise\", \"cashless\", \"organize\", \"online\", \"partner\", \"payment\", \"term\", \"short\", \"hear\", \"youtube\", \"impact\", \"video\", \"service\", \"long\", \"put\", \"waive\", \"make\", \"people\", \"economy\", \"support\", \"moderate\", \"believe\", \"owner\", \"mallyas\", \"add\", \"demonstrate\", \"loan\", \"stuff\", \"happiness\", \"shop\", \"underlying\", \"blame\", \"politicsit\", \"solidarity\", \"solve\", \"reflect\", \"transparent\", \"teach\", \"inspire\", \"fake\", \"medium\", \"linger\", \"ahmedabad\", \"laud\", \"nationalist\", \"tue\", \"definitely\", \"queue\", \"sound\", \"flat\", \"true\", \"good\", \"join\", \"bail\", \"due\", \"get\", \"stop\", \"say\", \"money\", \"day\", \"note\", \"story\", \"black\", \"benefit\", \"action\", \"youtube\", \"people\", \"video\", \"economic\", \"modi\", \"line\", \"can\", \"first\", \"contract\", \"effect\", \"survey\", \"make\", \"create\", \"nation\", \"run\", \"huge\", \"panic\", \"understand\", \"advice\", \"ensure\", \"modibharosa\", \"duty\", \"mount\", \"historic\", \"misery\", \"retain\", \"indifferent\", \"stunt\", \"parlmnt\", \"bibi\", \"prove\", \"mode\", \"ruption\", \"explain\", \"anandkamal\", \"acid\", \"loosen\", \"unrest\", \"frankly\", \"restriction\", \"vindicated\", \"running\", \"support\", \"move\", \"cash\", \"narendramodi\", \"people\", \"back\", \"parliament\", \"party\", \"supply\", \"claim\", \"think\", \"vote\", \"bypoll\", \"see\", \"take\", \"want\", \"oppose\", \"go\", \"say\", \"modi\", \"get\", \"still\", \"give\", \"poor\", \"implement\", \"money\"], \"Freq\": [54.0, 45.0, 60.0, 96.0, 37.0, 46.0, 44.0, 38.0, 56.0, 51.0, 73.0, 51.0, 25.0, 26.0, 42.0, 38.0, 57.0, 44.0, 18.0, 17.0, 18.0, 25.0, 25.0, 16.0, 24.0, 18.0, 12.0, 17.0, 19.0, 30.0, 25.22438621520996, 23.539716720581055, 49.5639533996582, 24.95480728149414, 54.05494689941406, 49.52470397949219, 12.297185897827148, 7.9606523513793945, 7.0876851081848145, 28.243486404418945, 26.626880645751953, 5.362679481506348, 5.360848426818848, 5.35999870300293, 9.749927520751953, 4.499239921569824, 4.498615741729736, 4.497131824493408, 4.485408782958984, 4.484893321990967, 4.483201026916504, 4.476110935211182, 24.724960327148438, 3.6358907222747803, 3.6331870555877686, 3.6325933933258057, 3.6325714588165283, 3.6317479610443115, 3.6305060386657715, 3.6305086612701416, 11.624895095825195, 13.82938003540039, 18.572811126708984, 73.38641357421875, 23.015806198120117, 52.867244720458984, 7.5195841789245605, 22.722715377807617, 7.1210832595825195, 8.81710147857666, 10.841072082519531, 8.02254867553711, 10.573079109191895, 7.947793006896973, 8.03554630279541, 8.028666496276855, 13.358144760131836, 9.089405059814453, 10.532167434692383, 8.843714714050293, 8.581910133361816, 36.52987289428711, 26.30743408203125, 43.71511459350586, 8.07719612121582, 7.2957682609558105, 7.252089500427246, 5.6905670166015625, 5.666281700134277, 39.164852142333984, 11.254287719726562, 4.885396957397461, 15.1613187789917, 4.116774082183838, 4.11117696762085, 16.574926376342773, 4.1101861000061035, 4.1088643074035645, 4.107635498046875, 4.098368167877197, 4.097988605499268, 4.0978193283081055, 4.096189022064209, 4.09598445892334, 4.095682144165039, 8.08460521697998, 11.530679702758789, 5.362194061279297, 3.324075222015381, 3.3172037601470947, 7.309206485748291, 7.248629093170166, 33.64618682861328, 15.190308570861816, 36.93336486816406, 8.205843925476074, 18.73326873779297, 8.681812286376953, 8.079769134521484, 5.6573896408081055, 9.686991691589355, 7.781626224517822, 6.933237552642822, 10.413272857666016, 6.75879430770874, 7.15225887298584, 6.608516216278076, 5.86519193649292, 54.12153244018555, 25.075580596923828, 17.02532196044922, 17.52627182006836, 10.613282203674316, 15.121659278869629, 8.986809730529785, 17.120195388793945, 7.407876968383789, 35.0855598449707, 11.49908447265625, 14.930665969848633, 10.644946098327637, 7.731662273406982, 4.181951522827148, 4.17994499206543, 4.179715633392334, 4.170848846435547, 7.441763401031494, 7.455587387084961, 3.3835270404815674, 3.3827943801879883, 3.382560968399048, 3.377169370651245, 3.3771910667419434, 3.3746113777160645, 11.489954948425293, 2.5730390548706055, 2.5728516578674316, 2.571970224380493, 5.807412147521973, 10.248799324035645, 27.559906005859375, 7.703733921051025, 4.227200508117676, 5.4141693115234375, 8.647272109985352, 21.872241973876953, 10.980209350585938, 10.641827583312988, 6.970378875732422, 5.833651065826416, 5.059406280517578, 6.049255847930908, 7.8387956619262695, 6.079681396484375, 6.421773910522461, 6.183282852172852, 6.166791915893555, 6.151844501495361, 5.413864612579346, 6.342716217041016, 3.1618754863739014, 3.1557488441467285, 3.1555118560791016, 3.152883529663086, 6.2854533195495605, 2.412332057952881, 2.4079642295837402, 2.406751871109009, 2.406066417694092, 2.405902624130249, 2.4051787853240967, 2.404979944229126, 2.400963306427002, 4.777491569519043, 11.604408264160156, 3.404360055923462, 3.3854618072509766, 3.383650779724121, 1.6584317684173584, 1.6582268476486206, 1.6569931507110596, 1.6568783521652222, 1.6567838191986084, 1.6567308902740479, 1.6557196378707886, 6.077502250671387, 12.297808647155762, 6.178525447845459, 3.1707873344421387, 9.129234313964844, 21.893442153930664, 3.9553489685058594, 12.369405746459961, 11.257930755615234, 6.763868808746338, 18.5978946685791, 5.611918926239014, 4.981789588928223, 5.898853778839111, 4.830334186553955, 6.509926795959473, 11.182990074157715, 7.447795867919922, 4.877790451049805, 8.252224922180176, 3.9119250774383545, 4.18103551864624, 4.6264848709106445, 4.180435657501221, 5.006921768188477, 4.247669219970703, 4.183363914489746, 6.656936168670654, 11.098949432373047, 9.099010467529297, 8.34600830078125, 4.487677097320557, 3.0421206951141357, 3.039203405380249, 3.01741361618042, 3.4995062351226807, 2.3166277408599854, 2.3166611194610596, 2.3163368701934814, 2.3159754276275635, 2.3140456676483154, 2.3131022453308105, 2.3112590312957764, 2.875210762023926, 2.284106969833374, 5.0455803871154785, 8.836708068847656, 2.1728057861328125, 3.7452611923217773, 1.5943695306777954, 1.593950629234314, 1.5937246084213257, 1.5933842658996582, 1.5933377742767334, 1.5933547019958496, 1.5931838750839233, 1.5932132005691528, 30.58800506591797, 9.731675148010254, 11.563698768615723, 3.0461251735687256, 35.35822677612305, 9.240253448486328, 2.9198110103607178, 4.263776779174805, 3.5447897911071777, 4.398611068725586, 4.37029504776001, 5.2401957511901855, 4.813819885253906, 4.9783616065979, 6.103863716125488, 3.8137779235839844, 3.3573100566864014, 4.904665470123291, 5.703311920166016, 6.445623397827148, 5.471857070922852, 3.791196346282959, 3.5973665714263916, 4.710580348968506, 4.356222629547119, 3.9364237785339355], \"Total\": [54.0, 45.0, 60.0, 96.0, 37.0, 46.0, 44.0, 38.0, 56.0, 51.0, 73.0, 51.0, 25.0, 26.0, 42.0, 38.0, 57.0, 44.0, 18.0, 17.0, 18.0, 25.0, 25.0, 16.0, 24.0, 18.0, 12.0, 17.0, 19.0, 30.0, 25.979248046875, 24.245803833007812, 51.118709564208984, 25.955854415893555, 56.24250793457031, 51.92316818237305, 12.953316688537598, 8.608642578125, 7.739241123199463, 30.973445892333984, 29.20905876159668, 6.002734661102295, 6.002423286437988, 6.0025153160095215, 11.109832763671875, 5.133884906768799, 5.133701324462891, 5.133838653564453, 5.131978511810303, 5.1316609382629395, 5.131575584411621, 5.130465984344482, 28.3585262298584, 4.2653703689575195, 4.265298366546631, 4.2649617195129395, 4.264963626861572, 4.265076160430908, 4.264821529388428, 4.265018463134766, 13.667098999023438, 16.290302276611328, 22.875471115112305, 96.38333892822266, 29.70185089111328, 73.49299621582031, 9.295592308044434, 33.88275146484375, 9.255690574645996, 13.414046287536621, 19.521818161010742, 12.444626808166504, 19.134902954101562, 12.344331741333008, 13.376361846923828, 13.39040756225586, 44.86071014404297, 19.772815704345703, 38.67697525024414, 24.70941925048828, 30.574844360351562, 37.306556701660156, 26.980623245239258, 45.311424255371094, 8.727348327636719, 7.933774471282959, 7.9346537590026855, 6.347463607788086, 6.346885681152344, 44.06201171875, 12.709538459777832, 5.553304672241211, 17.38299560546875, 4.758974075317383, 4.759191513061523, 19.18954849243164, 4.7596940994262695, 4.759949207305908, 4.759702205657959, 4.759868144989014, 4.759693622589111, 4.7598466873168945, 4.759825706481934, 4.759594440460205, 4.759624004364014, 9.488055229187012, 13.541685104370117, 6.370855331420898, 3.965397596359253, 3.9649906158447266, 8.741472244262695, 8.68935489654541, 42.75737762451172, 20.09398078918457, 57.43278503417969, 11.810234069824219, 35.29351806640625, 14.03036117553711, 12.88686466217041, 7.963895797729492, 19.222326278686523, 14.760965347290039, 12.273775100708008, 30.05958366394043, 13.842081069946289, 24.70941925048828, 19.134902954101562, 46.505435943603516, 54.92656707763672, 25.836624145507812, 17.75750160217285, 18.58915901184082, 11.294045448303223, 16.163898468017578, 9.674874305725098, 18.518932342529297, 8.061948776245117, 38.88405227661133, 12.896565437316895, 17.047725677490234, 12.160441398620605, 8.904420852661133, 4.83058500289917, 4.830606937408447, 4.830402851104736, 4.829456806182861, 8.820446968078613, 8.856500625610352, 4.0226359367370605, 4.022828578948975, 4.022822856903076, 4.0225324630737305, 4.022984981536865, 4.02276611328125, 13.728147506713867, 3.21460223197937, 3.2145495414733887, 3.2147421836853027, 7.313554286956787, 13.057889938354492, 38.67697525024414, 10.463411331176758, 5.589560031890869, 8.168111801147461, 19.736446380615234, 96.38333892822266, 30.05958366394043, 33.88275146484375, 14.946910858154297, 12.827239990234375, 8.667914390563965, 15.759225845336914, 60.957340240478516, 19.772815704345703, 46.505435943603516, 6.84096097946167, 6.840835094451904, 6.844020366668701, 6.085089206695557, 7.62716817855835, 3.8158998489379883, 3.816269874572754, 3.8163955211639404, 3.816641330718994, 7.692563533782959, 3.0596935749053955, 3.059886932373047, 3.059587001800537, 3.0595195293426514, 3.0600268840789795, 3.0597097873687744, 3.059628486633301, 3.060192823410034, 6.180925369262695, 15.307266235351562, 4.648565769195557, 4.65169095993042, 4.651524066925049, 2.3033370971679688, 2.303429365158081, 2.3034422397613525, 2.303485631942749, 2.3034603595733643, 2.3034658432006836, 2.303462505340576, 8.5871000289917, 17.652359008789062, 9.446314811706543, 4.62302827835083, 15.507275581359863, 44.86071014404297, 6.891810417175293, 30.574844360351562, 28.280181884765625, 14.450173377990723, 73.49299621582031, 11.990009307861328, 10.069134712219238, 13.89075756072998, 10.081046104431152, 19.736446380615234, 60.957340240478516, 30.05958366394043, 12.043575286865234, 57.43278503417969, 7.117241859436035, 8.7996826171875, 14.642754554748535, 10.248180389404297, 35.29351806640625, 14.03036117553711, 15.759225845336914, 7.346194744110107, 12.504850387573242, 10.27591323852539, 9.548803329467773, 5.1610107421875, 3.7037761211395264, 3.7040183544158936, 3.7063302993774414, 4.457798004150391, 2.9757115840911865, 2.9758148193359375, 2.975668430328369, 2.975964069366455, 2.9755945205688477, 2.9764065742492676, 2.9763240814208984, 3.718690872192383, 2.9784224033355713, 6.765077590942383, 11.95398998260498, 2.9913721084594727, 5.2276291847229, 2.247288942337036, 2.2473998069763184, 2.2473902702331543, 2.247365951538086, 2.247398853302002, 2.2475271224975586, 2.2473385334014893, 2.2474703788757324, 46.505435943603516, 15.01138687133789, 18.40237808227539, 4.465703010559082, 60.957340240478516, 15.32840347290039, 4.58603572845459, 7.508066654205322, 6.127480506896973, 8.527032852172852, 9.812457084655762, 13.842081069946289, 12.273775100708008, 14.07307243347168, 24.70941925048828, 9.156570434570312, 6.9006452560424805, 19.521818161010742, 30.574844360351562, 57.43278503417969, 44.86071014404297, 11.08602523803711, 9.198278427124023, 42.75737762451172, 44.06201171875, 28.280181884765625], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -4.260499954223633, -4.329599857330322, -3.5850000381469727, -4.271200180053711, -3.498300075531006, -3.5857999324798584, -4.978899955749512, -5.41379976272583, -5.529900074005127, -4.14739990234375, -4.206399917602539, -5.808800220489502, -5.809199810028076, -5.809299945831299, -5.210999965667725, -5.984399795532227, -5.984499931335449, -5.984799861907959, -5.987400054931641, -5.987599849700928, -5.9878997802734375, -5.989500045776367, -4.2804999351501465, -6.197400093078613, -6.198200225830078, -6.198299884796143, -6.198299884796143, -6.198599815368652, -6.19890022277832, -6.19890022277832, -5.035099983215332, -4.861499786376953, -4.5665998458862305, -3.192500114440918, -4.352099895477295, -3.5204999446868896, -5.470799922943115, -4.3649001121521, -5.525199890136719, -5.311600208282471, -5.104899883270264, -5.406000137329102, -5.130000114440918, -5.41540002822876, -5.404399871826172, -5.405300140380859, -4.896200180053711, -5.281199932098389, -5.133800029754639, -5.308599948883057, -5.338600158691406, -3.4728000164031982, -3.801100015640259, -3.293299913406372, -4.981900215148926, -5.083700180053711, -5.089700222015381, -5.332099914550781, -5.336400032043457, -3.4031999111175537, -4.650199890136719, -5.4847002029418945, -4.352200031280518, -5.655900001525879, -5.657199859619141, -4.2631001472473145, -5.65749979019165, -5.657800197601318, -5.658100128173828, -5.660399913787842, -5.6605000495910645, -5.6605000495910645, -5.660900115966797, -5.660900115966797, -5.660999774932861, -4.980999946594238, -4.625899791717529, -5.391600131988525, -5.869800090789795, -5.871799945831299, -5.0817999839782715, -5.090099811553955, -3.555000066757202, -4.350299835205078, -3.4618000984191895, -4.966100215911865, -4.140600204467773, -4.9096999168396, -4.981599807739258, -5.3379998207092285, -4.80019998550415, -5.019199848175049, -5.1346001625061035, -4.72790002822876, -5.160099983215332, -5.103499889373779, -5.182600021362305, -5.3018999099731445, -2.9951999187469482, -3.7646000385284424, -4.151800155639648, -4.122799873352051, -4.6244001388549805, -4.270299911499023, -4.7906999588012695, -4.146200180053711, -4.98390007019043, -3.4286999702453613, -4.5441999435424805, -4.283100128173828, -4.621399879455566, -4.941100120544434, -5.555699825286865, -5.55620002746582, -5.55620002746582, -5.5584001541137695, -4.979400157928467, -4.977499961853027, -5.767600059509277, -5.7677998542785645, -5.7677998542785645, -5.769400119781494, -5.769400119781494, -5.770199775695801, -4.545000076293945, -6.041399955749512, -6.041500091552734, -6.041800022125244, -5.22730016708374, -4.659299850463867, -3.670099973678589, -4.944799900054932, -5.544899940490723, -5.297500133514404, -4.82919979095459, -3.9012999534606934, -4.590400218963623, -4.621699810028076, -5.0447998046875, -5.222799777984619, -5.365200042724609, -5.186500072479248, -4.9274001121521, -5.18149995803833, -5.126800060272217, -4.926000118255615, -4.928699970245361, -4.931099891662598, -5.058899879455566, -4.900599956512451, -5.596700191497803, -5.598599910736084, -5.598700046539307, -5.599599838256836, -4.909599781036377, -5.867300033569336, -5.869100093841553, -5.86959981918335, -5.869900226593018, -5.869999885559082, -5.870299816131592, -5.870299816131592, -5.872000217437744, -5.184000015258789, -4.296500205993652, -5.522799968719482, -5.52839994430542, -5.528900146484375, -6.242000102996826, -6.242099761962891, -6.2428998947143555, -6.2428998947143555, -6.243000030517578, -6.243000030517578, -6.243599891662598, -4.943299770355225, -4.238500118255615, -4.926799774169922, -5.593900203704834, -4.536399841308594, -3.6617000102996826, -5.372799873352051, -4.232600212097168, -4.3267998695373535, -4.836299896240234, -3.8248000144958496, -5.0229997634887695, -5.142099857330322, -4.973100185394287, -5.172999858856201, -4.874499797821045, -4.333499908447266, -4.739999771118164, -5.1631999015808105, -4.637400150299072, -5.383800029754639, -5.317299842834473, -5.216100215911865, -5.317500114440918, -5.1371002197265625, -5.301499843597412, -5.316800117492676, -4.646299839019775, -4.1350998878479, -4.333799839019775, -4.420100212097168, -5.040599822998047, -5.4293999671936035, -5.430300235748291, -5.4375, -5.289299964904785, -5.7017998695373535, -5.7017998695373535, -5.701900005340576, -5.702099800109863, -5.702899932861328, -5.7032999992370605, -5.704100131988525, -5.485799789428711, -5.716000080108643, -4.923399925231934, -4.36299991607666, -5.765900135040283, -5.221399784088135, -6.075399875640869, -6.075699806213379, -6.075900077819824, -6.076099872589111, -6.076099872589111, -6.076099872589111, -6.076200008392334, -6.076200008392334, -3.121299982070923, -4.266499996185303, -4.094099998474121, -5.428100109100342, -2.9763998985290527, -4.318399906158447, -5.470399856567383, -5.091800212860107, -5.276400089263916, -5.0605998039245605, -5.0671000480651855, -4.8856000900268555, -4.970399856567383, -4.936800003051758, -4.732999801635742, -5.2032999992370605, -5.3308000564575195, -4.951700210571289, -4.800899982452393, -4.678500175476074, -4.842299938201904, -5.209199905395508, -5.26170015335083, -4.992099761962891, -5.070300102233887, -5.1717000007629395], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.111299991607666, 1.111299991607666, 1.1098999977111816, 1.1015000343322754, 1.101099967956543, 1.093500018119812, 1.0887999534606934, 1.062600016593933, 1.052899956703186, 1.0484999418258667, 1.04830002784729, 1.0281000137329102, 1.0277999639511108, 1.0276000499725342, 1.010200023651123, 1.0089000463485718, 1.0088000297546387, 1.0083999633789062, 1.0061999559402466, 1.006100058555603, 1.0056999921798706, 1.0044000148773193, 1.0037000179290771, 0.9811000227928162, 0.980400025844574, 0.9803000092506409, 0.9803000092506409, 0.9800999760627747, 0.9797999858856201, 0.9797000288963318, 0.9789999723434448, 0.9769999980926514, 0.9323999881744385, 0.8682000041007996, 0.8858000040054321, 0.8113999962806702, 0.9287999868392944, 0.7412999868392944, 0.878600001335144, 0.7211999893188477, 0.5526000261306763, 0.7017999887466431, 0.5475999712944031, 0.7005000114440918, 0.6312000155448914, 0.6292999982833862, -0.0706000030040741, 0.3635999858379364, -0.1599999964237213, 0.11330000311136246, -0.12970000505447388, 1.5370999574661255, 1.5328999757766724, 1.5223000049591064, 1.4807000160217285, 1.4743000268936157, 1.4681999683380127, 1.4488999843597412, 1.444700002670288, 1.4402999877929688, 1.4364999532699585, 1.4299999475479126, 1.4213999509811401, 1.4132000207901, 1.4118000268936157, 1.4117000102996826, 1.4113999605178833, 1.4111000299453735, 1.4107999801635742, 1.4084999561309814, 1.4084999561309814, 1.408400058746338, 1.4079999923706055, 1.4079999923706055, 1.4078999757766724, 1.3981000185012817, 1.3974000215530396, 1.3858000040054321, 1.381700038909912, 1.3797999620437622, 1.3791999816894531, 1.3768999576568604, 1.31850004196167, 1.27839994430542, 1.1166000366210938, 1.194000005722046, 0.9247000217437744, 1.0780999660491943, 1.0913000106811523, 1.2161999940872192, 0.8729000091552734, 0.917900025844574, 0.9869999885559082, 0.49799999594688416, 0.8413000106811523, 0.31839999556541443, 0.4950000047683716, -0.5123999714851379, 1.6279000043869019, 1.6126999855041504, 1.6004999876022339, 1.5836999416351318, 1.5805000066757202, 1.5759999752044678, 1.5687999725341797, 1.5641000270843506, 1.5579999685287476, 1.5398000478744507, 1.527899980545044, 1.5099999904632568, 1.5095000267028809, 1.5013999938964844, 1.4983999729156494, 1.4979000091552734, 1.4979000091552734, 1.496000051498413, 1.4726999998092651, 1.4703999757766724, 1.469599962234497, 1.4693000316619873, 1.4693000316619873, 1.4677000045776367, 1.4675999879837036, 1.4668999910354614, 1.4645999670028687, 1.4199999570846558, 1.4198999404907227, 1.4194999933242798, 1.4119999408721924, 1.4004000425338745, 1.3036999702453613, 1.336400032043457, 1.3632999658584595, 1.2314000129699707, 0.8173999786376953, 0.15950000286102295, 0.6355000138282776, 0.484499990940094, 0.879800021648407, 0.8547000288963318, 1.104200005531311, 0.6851000189781189, -0.40849998593330383, 0.4632999897003174, -0.33730000257492065, 1.7800999879837036, 1.777500033378601, 1.7746000289916992, 1.764299988746643, 1.6967999935150146, 1.6931999921798706, 1.6912000179290771, 1.691100001335144, 1.6901999711990356, 1.6792000532150269, 1.6434999704360962, 1.6416000127792358, 1.6411999464035034, 1.6410000324249268, 1.6406999826431274, 1.6404999494552612, 1.6404999494552612, 1.6385999917984009, 1.6237000226974487, 1.6043000221252441, 1.569700002670288, 1.5635000467300415, 1.562999963760376, 1.5527000427246094, 1.5526000261306763, 1.551800012588501, 1.5516999959945679, 1.5516999959945679, 1.5515999794006348, 1.5509999990463257, 1.5355000495910645, 1.5197999477386475, 1.4566999673843384, 1.50409996509552, 1.3514000177383423, 1.1638000011444092, 1.3259999752044678, 0.9763000011444092, 0.960099995136261, 1.1220999956130981, 0.507099986076355, 1.121999979019165, 1.1775000095367432, 1.0247999429702759, 1.1454999446868896, 0.7720999717712402, 0.18539999425411224, 0.4860000014305115, 0.977400004863739, -0.05889999866485596, 1.2826999425888062, 1.1370999813079834, 0.7290999889373779, 0.984499990940094, -0.07169999927282333, 0.6863999962806702, 0.5548999905586243, 1.9886000156402588, 1.967900037765503, 1.965499997138977, 1.9524999856948853, 1.9473999738693237, 1.8904000520706177, 1.889299988746643, 1.881500005722046, 1.8451000452041626, 1.8367999792099, 1.8367999792099, 1.8366999626159668, 1.836400032043457, 1.8357000350952148, 1.8350000381469727, 1.8343000411987305, 1.8299000263214111, 1.8216999769210815, 1.7939000129699707, 1.784999966621399, 1.7675000429153442, 1.7537000179290771, 1.743899941444397, 1.7436000108718872, 1.743499994277954, 1.743299961090088, 1.7431999444961548, 1.7431999444961548, 1.7431999444961548, 1.7431000471115112, 1.6682000160217285, 1.6536999940872192, 1.6225999593734741, 1.7045999765396118, 1.5425000190734863, 1.5809999704360962, 1.635699987411499, 1.521299958229065, 1.5398999452590942, 1.4251999855041504, 1.2783000469207764, 1.1158000230789185, 1.1512000560760498, 1.0479999780654907, 0.6888999938964844, 1.211300015449524, 1.3667000532150269, 0.7057999968528748, 0.40799999237060547, -0.10000000149011612, -0.01679999940097332, 1.01419997215271, 1.1483999490737915, -0.11860000342130661, -0.22679999470710754, 0.1152999997138977]}, \"token.table\": {\"Topic\": [5, 2, 4, 2, 2, 4, 5, 3, 3, 1, 4, 1, 5, 1, 3, 1, 4, 5, 3, 4, 1, 4, 5, 1, 4, 4, 1, 2, 3, 4, 5, 5, 2, 3, 4, 5, 4, 2, 5, 1, 3, 4, 1, 4, 5, 1, 3, 5, 3, 3, 2, 3, 1, 4, 5, 2, 4, 1, 2, 3, 4, 5, 2, 1, 2, 4, 5, 2, 1, 3, 4, 1, 3, 1, 2, 4, 5, 2, 4, 2, 3, 4, 4, 1, 1, 3, 4, 1, 2, 2, 1, 2, 4, 5, 5, 1, 3, 4, 1, 2, 3, 4, 5, 2, 1, 3, 1, 2, 3, 4, 2, 3, 5, 1, 1, 2, 5, 1, 3, 4, 5, 1, 2, 3, 1, 1, 2, 1, 2, 4, 5, 2, 4, 3, 1, 3, 3, 5, 1, 3, 4, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 3, 4, 5, 2, 3, 4, 2, 4, 1, 3, 1, 2, 3, 4, 1, 2, 3, 5, 4, 5, 1, 3, 4, 2, 5, 1, 3, 4, 2, 3, 5, 2, 2, 2, 1, 4, 1, 4, 1, 2, 4, 4, 1, 3, 1, 3, 4, 1, 4, 4, 1, 3, 4, 5, 3, 2, 3, 4, 5, 4, 1, 4, 1, 5, 1, 3, 3, 5, 4, 1, 2, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 1, 4, 5, 1, 2, 3, 4, 5, 2, 5, 4, 1, 1, 2, 3, 4, 3, 1, 2, 4, 2, 3, 1, 2, 4, 1, 3, 3, 5, 3, 1, 3, 4, 5, 1, 5, 5, 1, 3, 3, 4, 5, 1, 3, 1, 2, 4, 1, 2, 3, 4, 5, 4, 1, 2, 5, 1, 3, 1, 2, 4, 1, 1, 1, 5, 1, 2, 3, 4, 1, 2, 4, 1, 2, 4, 2, 5, 1, 2, 4, 5, 5, 2, 4, 1, 3, 4, 5, 5, 5, 1, 2, 4, 5, 1, 2, 4, 5, 1, 2, 3, 4, 5, 2, 1, 1, 3, 1, 1, 4, 3, 4, 1, 3, 2, 3, 2, 4, 2, 4, 4, 1, 2, 4, 5, 1, 2, 4, 5, 1, 2, 4, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 2, 2, 4, 5, 1, 1, 3, 4, 3, 1, 2, 4, 5, 4, 2, 1, 2, 1, 2, 3, 4, 1, 4, 5, 2, 2, 3, 4, 4, 3, 1, 4, 4, 3, 1, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 4, 5, 1, 3, 3, 4, 2, 4, 5, 1, 2, 3, 1, 4, 1, 1, 4, 1, 2, 3, 4], \"Freq\": [0.8899173140525818, 0.49598026275634766, 0.49598026275634766, 0.9917827844619751, 0.1311102658510208, 0.7866615653038025, 0.809931218624115, 0.9332414269447327, 0.9302446246147156, 0.21498329937458038, 0.6449499130249023, 0.9379056096076965, 0.8899612426757812, 0.9292986392974854, 0.7457149624824524, 0.26095345616340637, 0.13047672808170319, 0.5871452689170837, 0.21630842983722687, 0.6489253044128418, 0.648070752620697, 0.2430265247821808, 0.08100884407758713, 0.9001035690307617, 0.09001035243272781, 0.8770859241485596, 0.14398062229156494, 0.07199031114578247, 0.14398062229156494, 0.4319418966770172, 0.2159709483385086, 0.6714964509010315, 0.0993134006857872, 0.297940194606781, 0.4965670108795166, 0.0993134006857872, 0.6536189317703247, 0.5703216791152954, 0.4073726236820221, 0.6709384918212891, 0.2236461639404297, 0.14909744262695312, 0.45456185936927795, 0.45456185936927795, 0.11364046484231949, 0.21736320853233337, 0.10868160426616669, 0.6520896553993225, 0.9332567453384399, 0.9573419094085693, 0.07754002511501312, 0.8529402613639832, 0.35182225704193115, 0.11727409064769745, 0.4690963625907898, 0.843165397644043, 0.10539567470550537, 0.2601141929626465, 0.520228385925293, 0.10404568165540695, 0.052022840827703476, 0.10404568165540695, 0.8403668999671936, 0.19515658915042877, 0.39031317830085754, 0.39031317830085754, 0.9528743028640747, 0.8404077291488647, 0.8780210018157959, 0.07316841930150986, 0.07316841930150986, 0.9631738662719727, 0.8682764172554016, 0.4152199327945709, 0.06920332461595535, 0.4844232499599457, 0.06920332461595535, 0.9636545181274414, 0.8682494163513184, 0.6773785948753357, 0.08467232435941696, 0.16934464871883392, 0.7861841320991516, 0.7796562910079956, 0.07715245336294174, 0.900111973285675, 0.025717483833432198, 0.8329841494560242, 0.8403632044792175, 0.7565445899963379, 0.12897172570228577, 0.19345757365226746, 0.5803727507591248, 0.06448586285114288, 0.6721081733703613, 0.33212730288505554, 0.24909546971321106, 0.41515910625457764, 0.4551703631877899, 0.10114897042512894, 0.3034469187259674, 0.1517234593629837, 0.05057448521256447, 0.9453455209732056, 0.9629612565040588, 0.038518451154232025, 0.19833670556545258, 0.5383424758911133, 0.14166907966136932, 0.14166907966136932, 0.1129114106297493, 0.7903798818588257, 0.809425950050354, 0.7791649103164673, 0.7791441082954407, 0.19129130244255066, 0.7651652097702026, 0.065328449010849, 0.065328449010849, 0.7839414477348328, 0.065328449010849, 0.8815690875053406, 0.03526276350021362, 0.10578829050064087, 0.9264036417007446, 0.02206948958337307, 0.9710575342178345, 0.06829316169023514, 0.3414658010005951, 0.3414658010005951, 0.20487947762012482, 0.9003648161888123, 0.8682581186294556, 0.9739645719528198, 0.11731769889593124, 0.8798827528953552, 0.7457988262176514, 0.8899176716804504, 0.9378495812416077, 0.7936105728149414, 0.11337293684482574, 0.28978586196899414, 0.044582441449165344, 0.06687366217374802, 0.49040687084198, 0.11145610362291336, 0.10871599614620209, 0.21743199229240417, 0.21743199229240417, 0.43486398458480835, 0.5634720921516418, 0.051224738359451294, 0.10244947671890259, 0.051224738359451294, 0.25612369179725647, 0.9898620247840881, 0.11329930275678635, 0.05664965137839317, 0.6797958016395569, 0.11329930275678635, 0.8403887152671814, 0.9676187038421631, 0.7860314249992371, 0.8055834174156189, 0.11508334428071976, 0.2448546290397644, 0.6121366024017334, 0.5748657584190369, 0.3658236563205719, 0.05226052179932594, 0.05226052179932594, 0.9378743767738342, 0.8007804155349731, 0.11439720541238785, 0.6721178889274597, 0.10472516715526581, 0.8378013372421265, 0.7573922872543335, 0.22825521230697632, 0.010375237092375755, 0.8851162195205688, 0.09078114479780197, 0.072843037545681, 0.8012734651565552, 0.072843037545681, 0.7534000873565674, 0.25113338232040405, 0.6719512343406677, 0.8404025435447693, 0.8822060823440552, 0.8403450846672058, 0.16178807616233826, 0.8089403510093689, 0.31758415699005127, 0.6351683139801025, 0.9040001630783081, 0.06457144021987915, 0.032285720109939575, 0.8683053851127625, 0.9378622770309448, 0.9831308126449585, 0.2810077369213104, 0.1405038684606552, 0.5620154738426208, 0.21497559547424316, 0.6449267864227295, 0.7861078977584839, 0.4683241844177246, 0.4683241844177246, 0.06690345704555511, 0.8899210691452026, 0.7457796335220337, 0.2538195848464966, 0.3807293474674225, 0.2538195848464966, 0.06345489621162415, 0.8216806650161743, 0.2151201069355011, 0.6453603506088257, 0.832953691482544, 0.6720511317253113, 0.9378007650375366, 0.828057050704956, 0.2509622275829315, 0.7528867125511169, 0.8770697712898254, 0.10446994751691818, 0.6442313194274902, 0.13929326832294464, 0.10446994751691818, 0.6729779839515686, 0.21216270327568054, 0.07072090357542038, 0.17680226266384125, 0.388964980840683, 0.14144180715084076, 0.15519678592681885, 0.6207871437072754, 0.23279517889022827, 0.6720848083496094, 0.13323219120502472, 0.19984829425811768, 0.6661609411239624, 0.597442626953125, 0.2987213134765625, 0.07468032836914062, 0.22392891347408295, 0.6717867255210876, 0.07996896654367447, 0.8796586394309998, 0.8682705760002136, 0.9378747940063477, 0.7743625044822693, 0.03366793692111969, 0.10100380331277847, 0.06733587384223938, 0.8282504677772522, 0.7211571335792542, 0.027213476598262787, 0.2585280239582062, 0.8654916882514954, 0.07868106663227081, 0.8305839896202087, 0.04371494799852371, 0.13114483654499054, 0.13673242926597595, 0.8203945159912109, 0.43474194407463074, 0.43474194407463074, 0.9332008361816406, 0.978115439414978, 0.019562309607863426, 0.8766776919364929, 0.7750419974327087, 0.21805325150489807, 0.6541597247123718, 0.8067355155944824, 0.1531641036272049, 0.7658205032348633, 0.1331900805234909, 0.2663801610469818, 0.5327603220939636, 0.2844069302082062, 0.723944902420044, 0.07384604960680008, 0.8861526250839233, 0.07384604960680008, 0.04921474680304527, 0.04921474680304527, 0.13123932480812073, 0.1804540604352951, 0.5741720199584961, 0.6536830067634583, 0.09355110675096512, 0.7951844334602356, 0.11693888157606125, 0.8594070076942444, 0.12277243286371231, 0.9243707656860352, 0.03423595428466797, 0.03423595428466797, 0.9044814705848694, 0.8329969048500061, 0.1478179693222046, 0.739089846611023, 0.0779590904712677, 0.3897954523563385, 0.4677545726299286, 0.0779590904712677, 0.10422340035438538, 0.8858988881111145, 0.8682588934898376, 0.598069965839386, 0.37379372119903564, 0.6536567807197571, 0.8403593897819519, 0.8898668885231018, 0.06774624437093735, 0.5419699549674988, 0.20323874056339264, 0.1354924887418747, 0.6721345782279968, 0.8629122376441956, 0.11505496501922607, 0.9623064994812012, 0.8280532956123352, 0.09731495380401611, 0.875834584236145, 0.8898893594741821, 0.6685895323753357, 0.6428477168083191, 0.16071192920207977, 0.16071192920207977, 0.08035596460103989, 0.29435962438583374, 0.13082650303840637, 0.3924795091152191, 0.19623975455760956, 0.2842307686805725, 0.2131730616092682, 0.07105769217014313, 0.14211538434028625, 0.35528844594955444, 0.7848239541053772, 0.7791370749473572, 0.6788114309310913, 0.3246489465236664, 0.9377849102020264, 0.1299956738948822, 0.7799740433692932, 0.7156198024749756, 0.1789049506187439, 0.08223385363817215, 0.9045724272727966, 0.9166586995124817, 0.7457439303398132, 0.8823038935661316, 0.6536974310874939, 0.840390145778656, 0.6535890102386475, 0.8682568669319153, 0.4510182738304138, 0.090203657746315, 0.18040731549263, 0.36081463098526, 0.14509975910186768, 0.14509975910186768, 0.5803990364074707, 0.14509975910186768, 0.33361107110977173, 0.16680553555488586, 0.50041663646698, 0.7860820293426514, 0.6719698309898376, 0.16319921612739563, 0.16319921612739563, 0.6527968645095825, 0.021502861753106117, 0.129017174243927, 0.129017174243927, 0.0645085871219635, 0.6665887236595154, 0.8403902053833008, 0.6414660215377808, 0.28509601950645447, 0.07127400487661362, 0.779487669467926, 0.9601278901100159, 0.01778014563024044, 0.01778014563024044, 0.8280882835388184, 0.3642335832118988, 0.2832927703857422, 0.08094079047441483, 0.24282237887382507, 0.6535536050796509, 0.7566221952438354, 0.7794265151023865, 0.9452594518661499, 0.0955711230635643, 0.0955711230635643, 0.7645689845085144, 0.0955711230635643, 0.1019112765789032, 0.4076451063156128, 0.4076451063156128, 0.8405172824859619, 0.8404788970947266, 0.9179794788360596, 0.05399879440665245, 0.6536741256713867, 0.7457554936408997, 0.2329075038433075, 0.6987224817276001, 0.8682657480239868, 0.7457450032234192, 0.05379479378461838, 0.968306303024292, 0.653660237789154, 0.8099841475486755, 0.8899307250976562, 0.03326725959777832, 0.3326725959777832, 0.3659398555755615, 0.23287081718444824, 0.8899415731430054, 0.11230376362800598, 0.8984301090240479, 0.07224347442388535, 0.5057042837142944, 0.07224347442388535, 0.36121734976768494, 0.061866264790296555, 0.9279939532279968, 0.5768400430679321, 0.3461040258407593, 0.43684476613998413, 0.10921119153499603, 0.43684476613998413, 0.14929844439029694, 0.7464922070503235, 0.09953229129314423, 0.8606229424476624, 0.1075778678059578, 0.7794747352600098, 0.7562915086746216, 0.21608328819274902, 0.05066768079996109, 0.15200304985046387, 0.4560091495513916, 0.3546737730503082], \"Term\": [\"acid\", \"action\", \"action\", \"actually\", \"add\", \"add\", \"advice\", \"advise\", \"ahead\", \"ahmedabad\", \"ahmedabad\", \"analysis\", \"anandkamal\", \"announcement\", \"annual\", \"back\", \"back\", \"back\", \"bail\", \"bail\", \"ban\", \"ban\", \"ban\", \"bank\", \"bank\", \"believe\", \"benefit\", \"benefit\", \"benefit\", \"benefit\", \"benefit\", \"bibi\", \"black\", \"black\", \"black\", \"black\", \"blame\", \"bypoll\", \"bypoll\", \"call\", \"call\", \"call\", \"can\", \"can\", \"can\", \"cash\", \"cash\", \"cash\", \"cashless\", \"catalyze\", \"charge\", \"charge\", \"claim\", \"claim\", \"claim\", \"clearly\", \"clearly\", \"come\", \"come\", \"come\", \"come\", \"come\", \"consumer\", \"contract\", \"contract\", \"contract\", \"create\", \"critical\", \"currency\", \"currency\", \"currency\", \"daily\", \"daughter\", \"day\", \"day\", \"day\", \"day\", \"dear\", \"definitely\", \"demand\", \"demand\", \"demand\", \"demonstrate\", \"deployment\", \"digital\", \"digital\", \"digital\", \"directly\", \"double\", \"drag\", \"due\", \"due\", \"due\", \"due\", \"duty\", \"economic\", \"economic\", \"economic\", \"economy\", \"economy\", \"economy\", \"economy\", \"economy\", \"edict\", \"education\", \"education\", \"effect\", \"effect\", \"effect\", \"effect\", \"end\", \"end\", \"ensure\", \"evident\", \"exchange\", \"explain\", \"explain\", \"fake\", \"fake\", \"fake\", \"fake\", \"fall\", \"fall\", \"fall\", \"financial\", \"find\", \"find\", \"first\", \"first\", \"first\", \"first\", \"fishy\", \"flat\", \"fold\", \"food\", \"food\", \"forecast\", \"frankly\", \"free\", \"fund\", \"fund\", \"get\", \"get\", \"get\", \"get\", \"get\", \"give\", \"give\", \"give\", \"give\", \"go\", \"go\", \"go\", \"go\", \"go\", \"gold\", \"good\", \"good\", \"good\", \"good\", \"govts\", \"growth\", \"happiness\", \"hate\", \"hate\", \"hear\", \"hear\", \"help\", \"help\", \"help\", \"help\", \"heritage\", \"hilarious\", \"hilarious\", \"historic\", \"huge\", \"huge\", \"impact\", \"impact\", \"impact\", \"implement\", \"implement\", \"increase\", \"increase\", \"increase\", \"index\", \"index\", \"indifferent\", \"industrial\", \"inform\", \"innovative\", \"inspire\", \"inspire\", \"join\", \"join\", \"late\", \"late\", \"late\", \"laud\", \"license\", \"like\", \"line\", \"line\", \"line\", \"linger\", \"linger\", \"loan\", \"long\", \"long\", \"long\", \"loosen\", \"maintain\", \"make\", \"make\", \"make\", \"make\", \"mallyas\", \"medium\", \"medium\", \"milk\", \"misery\", \"miss\", \"mobile\", \"mode\", \"mode\", \"moderate\", \"modi\", \"modi\", \"modi\", \"modi\", \"modibharosa\", \"money\", \"money\", \"money\", \"money\", \"money\", \"month\", \"month\", \"month\", \"mount\", \"move\", \"move\", \"move\", \"must\", \"must\", \"must\", \"narendramodi\", \"narendramodi\", \"nation\", \"nation\", \"nationalist\", \"ncbn\", \"new\", \"new\", \"new\", \"new\", \"nitishkumar\", \"note\", \"note\", \"note\", \"oil\", \"oil\", \"old\", \"old\", \"old\", \"online\", \"online\", \"oppose\", \"oppose\", \"organize\", \"overall\", \"overall\", \"owner\", \"panic\", \"parliament\", \"parliament\", \"parlmnt\", \"partner\", \"partner\", \"party\", \"party\", \"party\", \"payment\", \"payment\", \"paytm\", \"paytm\", \"paytm\", \"people\", \"people\", \"people\", \"people\", \"people\", \"politicsit\", \"poor\", \"poor\", \"poor\", \"positive\", \"positive\", \"price\", \"price\", \"price\", \"print\", \"producer\", \"prove\", \"prove\", \"put\", \"put\", \"put\", \"put\", \"question\", \"question\", \"queue\", \"read\", \"read\", \"reflect\", \"require\", \"restriction\", \"result\", \"result\", \"result\", \"result\", \"retain\", \"rich\", \"rich\", \"rise\", \"round\", \"run\", \"run\", \"running\", \"ruption\", \"s\", \"s\", \"s\", \"s\", \"say\", \"say\", \"say\", \"say\", \"see\", \"see\", \"see\", \"see\", \"see\", \"seem\", \"sell\", \"service\", \"service\", \"sharesclearly\", \"shop\", \"shop\", \"short\", \"short\", \"shortage\", \"shortage\", \"shrink\", \"silence\", \"snapchat\", \"solidarity\", \"solution\", \"solve\", \"sound\", \"still\", \"still\", \"still\", \"still\", \"stop\", \"stop\", \"stop\", \"stop\", \"story\", \"story\", \"story\", \"stuff\", \"stunt\", \"supply\", \"supply\", \"supply\", \"support\", \"support\", \"support\", \"support\", \"support\", \"surrender\", \"survey\", \"survey\", \"survey\", \"swift\", \"system\", \"system\", \"system\", \"table\", \"take\", \"take\", \"take\", \"take\", \"teach\", \"teacher\", \"technology\", \"telangana\", \"term\", \"term\", \"term\", \"term\", \"think\", \"think\", \"think\", \"third\", \"trailer\", \"transaction\", \"transaction\", \"transparent\", \"trim\", \"true\", \"true\", \"tue\", \"turk\", \"turn\", \"turn\", \"underlying\", \"understand\", \"unrest\", \"video\", \"video\", \"video\", \"video\", \"vindicated\", \"vision\", \"vision\", \"vote\", \"vote\", \"vote\", \"vote\", \"voucher\", \"voucher\", \"waive\", \"waive\", \"want\", \"want\", \"want\", \"watch\", \"watch\", \"watch\", \"well\", \"well\", \"worldbank\", \"worth\", \"worth\", \"youtube\", \"youtube\", \"youtube\", \"youtube\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 2, 5, 1, 4]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el985225134325541848557335767\", ldavis_el985225134325541848557335767_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el985225134325541848557335767\", ldavis_el985225134325541848557335767_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el985225134325541848557335767\", ldavis_el985225134325541848557335767_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2     -0.109675  0.153493       1        1  31.955826\n",
       "1      0.169051 -0.069542       2        1  21.052677\n",
       "4     -0.174591 -0.152510       3        1  19.347221\n",
       "0      0.027982  0.067797       4        1  15.240452\n",
       "3      0.087233  0.000762       5        1  12.403828, topic_info=          Term       Freq      Total Category  logprob  loglift\n",
       "341       like  54.000000  54.000000  Default  30.0000  30.0000\n",
       "110       find  45.000000  45.000000  Default  29.0000  29.0000\n",
       "39      people  60.000000  60.000000  Default  28.0000  28.0000\n",
       "159     impact  96.000000  96.000000  Default  27.0000  27.0000\n",
       "104   actually  37.000000  37.000000  Default  26.0000  26.0000\n",
       "..         ...        ...        ...      ...      ...      ...\n",
       "252      still   3.791196  11.086025   Topic5  -5.2092   1.0142\n",
       "154       give   3.597367   9.198278   Topic5  -5.2617   1.1484\n",
       "41        poor   4.710580  42.757378   Topic5  -4.9921  -0.1186\n",
       "79   implement   4.356223  44.062012   Topic5  -5.0703  -0.2268\n",
       "168      money   3.936424  28.280182   Topic5  -5.1717   0.1153\n",
       "\n",
       "[288 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "304       5  0.889917      acid\n",
       "792       2  0.495980    action\n",
       "792       4  0.495980    action\n",
       "104       2  0.991783  actually\n",
       "358       2  0.131110       add\n",
       "...     ...       ...       ...\n",
       "488       4  0.216083     worth\n",
       "296       1  0.050668   youtube\n",
       "296       2  0.152003   youtube\n",
       "296       3  0.456009   youtube\n",
       "296       4  0.354674   youtube\n",
       "\n",
       "[451 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 2, 5, 1, 4])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
